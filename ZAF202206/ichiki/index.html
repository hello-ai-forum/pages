<!doctype html>
<html>
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta charset="UTF-8" />
    <title>ZENKEI AI FORUM (2022/06/29)</title>
    <link href="https://fonts.googleapis.com/css?family=M+PLUS+1p:100,400,700&display=swap&subset=japanese" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="../../bright-M_PLUS_1p.css" />

    <link rel="stylesheet"
	  href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.2.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.2.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="text/javascript" id="MathJax-script" async
	    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  </head>

<body style="font-size: 20px;">

<header>
<center><h1>ZENKEI AI FORUM 2022/06/29</h1></center>
</header>

<article>

<section id="main">

  <center>
    <a href="ZENKEI_AI_FORUM_zoom_20220629-2488x1400.jpg"><!-- 2488x1400 -->
      <img src="ZENKEI_AI_FORUM_zoom_20220629-2488x1400_thumb.jpg" width="800" height="450" style="border: 2px #ccc solid;" /></a>
  </center>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center>
    <div style="font-size: 60px; font-weight: bold;">
      ZAF ï¼’ï¼ï¼’ï¼’å¹´ï¼–æœˆï¼’ï¼™æ—¥
    </div>
    <div style="font-size: 40px;">ï¼œæœ¬æ—¥ã®ãƒ†ãƒ¼ãƒï¼</div>
    <div style="font-size: 80px;">
      æŠ€è¡“æ›¸å…¸ï¼‘ï¼“ä¼ç”»ä¼šè­°
    </div>
    <div style="font-size: 60px;">ã»ã‹</div>
  </center>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <hr />

  <h2>ç›®æ¬¡</h2>
  <ul>
    <li>[6:30 - 7:00]
      <b>å‰åº§</b>
      <ul>
	<li><a href="#part0-twitch">æœ€è¿‘ã®ç§ï¼ˆã„ã¡ãï¼‰ã¯ã©ã“ã«å‘ã‹ã£ã¦ã„ã‚‹ã®ã‹ï¼Ÿ</a></li>
	<li><a href="#part0-dance">è¸Šã£ã¦ã¿ãŸ-ãã®å¾Œ</a></li>
      </ul>
    </li>

    <li>[7:00 - 8:00]
      <b>ãƒ‘ãƒ¼ãƒˆï¼‘</b>
      <a href="#part1">æœ€è¿‘ã® AI ã¯æœ¬å½“ã™ã”ã„ã­</a>
      <ul>
	<li><a href="#part1-community-oriented-life">ï¼ˆå‰åº§ï¼‰ä»¤å’Œæ™‚ä»£ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å¿—å‘ãªç”Ÿãæ–¹</a></li>
	<li><a href="#part1-portrait">é¡”ã® 3D å†æ§‹æˆ</a></li>
	<li><a href="#part1-NeRF">3D å†æ§‹æˆã€ NeRF é–¢ä¿‚</a></li>
	<li><a href="#part1-photogrammetry">ãƒ•ã‚©ãƒˆã‚°ãƒ©ãƒ¡ãƒˆãƒªã€LiDAR é–¢ä¿‚</a></li>
	<li><a href="#part1-text-to-image">Text to Image ãªã©</a></li>
	<li><a href="#part1-super-resolution">è¶…è§£åƒãªã©</a></li>
	<li><a href="#part1-demos">ãƒ‡ãƒ¢</a></li>
	<li><a href="#part1-pose">å§¿å‹¢æ¨å®š</a></li>
	<li><a href="#part1-misc">ãã®ä»–</a></li>
      </ul>
    </li>

    <li>[8:00 - 9:00]
      <b>ãƒ‘ãƒ¼ãƒˆï¼’</b>
      <a href="#part2">æŠ€è¡“æ›¸å…¸ï¼‘ï¼“ä¼ç”»ä¼šè­°ï¼</a>
      <ul>
	<li><a href="#part2-invitation">æŠ€è¡“æ›¸å…¸ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆï¼‰ã¸ã®ãŠèª˜ã„</a></li>
	<li><a href="#part2-mission-statement">ZENKEI AI FORUM ã® Mission Statement</a></li>
	<li><a href="#part2-fandom-economy">åŒäººèªŒæ´»å‹•ã¯ä»Šã®ãƒ“ã‚¸ãƒã‚¹ã®æœ€å…ˆç«¯ï¼</a></li>
	<li><a href="#part2-line-up">ã“ã‚Œã¾ã§ã®ãƒ©ã‚¤ãƒ³ãƒŠãƒƒãƒ—</a></li>
        <li><a href="#part2-my-personal-project">ã„ã¡ãã®ã‚½ãƒ­ä¼ç”»</a></li>
	<li><a href="#part2-as-a-circle">ZAF ã®ã‚µãƒ¼ã‚¯ãƒ«ä¼ç”»</a></li>
	<li><a href="#part2-lets-discuss">ä¼ç”»ä¼šè­°ï¼</a></li>
      </ul>
    </li>

    <li><a href="#epilogue">ä»Šæ—¥ã®ãŠã‚ã‚Šã«</a></li>

    <li><a href="#detailed-toc">ç·åˆç›®æ¬¡</a></li>
  </ul>

  <hr />

  <center>
    <br />
    <div style="font-size: 30px;">
      YouTube ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ»ãƒ“ãƒ‡ã‚ªã¯ã“ã¡ã‚‰
    </div>
    (<a href="https://youtube.com/live/3BmmpshE2eI">
      https://youtube.com/live/3BmmpshE2eI</a>)
    <br /><br />
    <a href="https://youtube.com/live/3BmmpshE2eI">
      <img src="Screen Shot 2023-03-31 at 10.46.54_thumb.jpg" width="500" height="282" style="border: 2px #ccc solid;" /></a>
    <br /><br />
  </center>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <hr />

  <center id="part0-twitch">
    <div style="font-size: 50px; font-weight: bolder;">
      å‰åº§ã€ãã®ï¼‘
      <br />
      æœ€è¿‘ã®ç§ï¼ˆã„ã¡ãï¼‰ã¯ã©ã“ã«å‘ã‹ã£ã¦ã„ã‚‹ã®ã‹ï¼Ÿ
    </div>
  </center>

  <ul>
    <li>ã“ã‚Œã¾ã§ã®ã€ã€Œæœ€è¿‘ã€ã©ã“ã«å‘ã‹ã£ã¦ã„ãŸã®ã‹ï¼Ÿã€</li>
    <li>ä»Šå¹´ã® ZAF ã®å‰åº§ã‚’æŒ¯ã‚Šè¿”ã£ã¦ã¿ã‚‹ã¨ã€
      <ul>
	<li><a href="https://hello-ai-forum.github.io/pages/ZAF202201/ichiki/">ZAF-2201</a> åŒäººã®æ–¹å‘ã€èŠ­è•‰ã¨ã‹ã«å¼•ã£ã‹ã‹ã£ãŸã‚Š
	  <center>
	    <a href="Screen Shot 2022-06-28 at 23.41.20.png"><!-- 2650x655 -->
	      <img src="Screen Shot 2022-06-28 at 23.41.20_thumb.jpg" width="800" height="198" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li><a href="https://hello-ai-forum.github.io/pages/ZAF202202/ichiki/">ZAF-2202</a> ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã®æ–¹å‘ã€ AUDIUS ãƒ‡ãƒ“ãƒ¥ãƒ¼
	  <center>
	    <a href="Screen Shot 2022-06-28 at 23.43.12.png"><!-- 2669x739 -->
	      <img src="Screen Shot 2022-06-28 at 23.43.12_thumb.jpg" width="800" height="222" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <ul>
	    <li>ï¼ˆ2016~2017 ã‚ãŸã‚Šã«ä¸€åº¦ã€ä½œæ›²ãƒ–ãƒ¼ãƒ æ¥ã¦ãŸï¼‰</li>
	  </ul>
	</li>
	<li><a href="https://hello-ai-forum.github.io/pages/ZAF202203/ichiki/">ZAF-2203</a> ã‚¸ãƒ£ã‚ºã¯ã€ãã¡ã‚“ã¨ã¿ã‚‹ã¨ã€ç·»å¯†ã ã£ãŸï¼ˆãƒ”ã‚¢ãƒã®æ–¹å‘ï¼‰
	  <center>
	    <a href="Screen Shot 2022-06-28 at 23.46.11.png"><!-- 2678x1066 -->
	      <img src="Screen Shot 2022-06-28 at 23.46.11_thumb.jpg" width="800" height="318" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li><a href="https://hello-ai-forum.github.io/pages/ZAF202204/ichiki/">ZAF-2204</a> éŸ³æ¥½ã¨æ•°ç†ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ - è‡ªåˆ†è‡ªèº«ã‚’ã¾ãªæ¿ã®ä¸Šã«ã®ã›ã‚‹
	  <center>
	    <a href="Screen Shot 2022-06-28 at 23.48.15.png"><!-- 2677x1073 -->
	      <img src="Screen Shot 2022-06-28 at 23.48.15_thumb.jpg" width="800" height="321" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li><a href="https://hello-ai-forum.github.io/pages/ZAF202205/ichiki/">ZAF-2205</a> éŸ³æ¥½ã¨æ•°ç†ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ - è‡ªåˆ†ã®å¯èƒ½æ€§ã‚’æ¨¡ç´¢ã€
	  ãƒ”ã‚¢ãƒã‚’æ™’ã—ã€è‹±èªã§èªã‚Šã‹ã‘ãŸ
	  <center>
	    <a href="Screen Shot 2022-06-28 at 23.50.08.png"><!-- 2680x588 -->
	      <img src="Screen Shot 2022-06-28 at 23.50.08_thumb.jpg" width="800" height="176" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-06-28 at 23.50.11.png"><!-- 2677x602 -->
	      <img src="Screen Shot 2022-06-28 at 23.50.11_thumb.jpg" width="800" height="180" style="border: 2px #ccc solid;" /></a>
	  </center>
	  ã§ã€è¸Šã£ãŸ
	  <center>
	    <a href="Screen Shot 2022-06-28 at 23.53.30.png"><!-- 2675x654 -->
	      <img src="Screen Shot 2022-06-28 at 23.53.30_thumb.jpg" width="800" height="196" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li>ãã—ã¦ã€å…ˆæ—¥ã€æ­Œã£ã¦ã¿ãŸ (<a href="https://youtube.com/shorts/LuK4loO4ffM">https://youtube.com/shorts/LuK4loO4ffM</a>)
	  <center>
	    <a href="Screen Shot 2022-06-28 at 23.56.18.png"><!-- 2278x1206 -->
	      <img src="Screen Shot 2022-06-28 at 23.56.18_thumb.jpg" width="800" height="424" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-06-29 at 0.00.14.png"><!-- 2313x464 -->
	      <img src="Screen Shot 2022-06-29 at 0.00.14_thumb.jpg" width="800" height="160" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>
    <li>ã¾ã¨ã‚ã‚‹ã¨ã€
      <ul>
	<li>ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å¿—å‘ï¼ˆä¸€äººã§ã§ãã‚‹ã“ã¨ã€ã¿ã‚“ãªã§ã§ãã‚‹ã“ã¨ï¼‰</li>
	<li>è‡ªåˆ†è‡ªèº«ã‚’æ™’ã™ï¼ˆä¸–é–“ã«å•ã†ã€ã¨åŒæ™‚ã«ã€ä¿¡é ¼ã—ã¦ã‚‚ã‚‰ã†ï¼‰</li>
	<li>è‡ªåˆ†ã‚’é«˜ã‚ã‚‹ï¼ˆæˆé•·ã™ã‚‹ã€æ¥½ã—ã‚€ï¼‰</li>
	<li>è‡ªåˆ†ã®é™ç•Œã‚’è¶…ãˆã‚‹</li>
      </ul>
    </li>

    <li>ã“ã®æµã‚Œã®ã€ã‚ã‚‹æ„å‘³ã€å½“ç„¶ã®å¸°çµã¨ã—ã¦ã€
      <center>
	<div style="font-size: 50px; font-weight: bolder;">
	  ã„ã¡ãã€ Twitch ã‚’ã¯ã˜ã‚ã¾ã—ãŸï¼
	</div>
      </center>
    </li>
    <li><a href="https://www.twitch.tv/kengoichiki">https://www.twitch.tv/kengoichiki</a>
  </ul>

  <center>
    <a href="Screen Shot 2022-06-26 at 13.25.22.png"><!-- 2341x1157 -->
      <img src="Screen Shot 2022-06-26 at 13.25.22_thumb.jpg" width="1000" height="494" style="border: 2px #ccc solid;" /></a>
    <a href="Screen Shot 2022-06-26 at 13.25.32.png"><!-- 2343x820 -->
      <img src="Screen Shot 2022-06-26 at 13.25.32_thumb.jpg" width="1000" height="350" style="border: 2px #ccc solid;" /></a>
  </center>

  <ul>
    <li>ã£ã¦ã“ã¨ã§ã€</li>
  </ul>

  <center>
    <div style="font-size: 50px; font-weight: bolder;">
      ä»Šå¾Œã¨ã‚‚ã€ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ï¼
    </div>
  </center>
  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <hr />

  <center id="part0-dance">
    <div style="font-size: 50px; font-weight: bolder;">
      å‰åº§ã€ãã®ï¼’
      <br />
      è¸Šã£ã¦ã¿ãŸ-ãã®å¾Œ
    </div>
  </center>

  <ul>
    <li>å‰å› (<a href="https://hello-ai-forum.github.io/pages/ZAF202205/ichiki/">ZAF-2205</a>)
      <center>
	<a href="ZENKEI_AI_FORUM_zoom_20220525-2488x1400.jpg"><!-- 2488x1400 -->
	  <img src="ZENKEI_AI_FORUM_zoom_20220525-2488x1400_thumb.jpg" width="800" height="450" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>
    <li>è¸Šã£ãŸãƒ“ãƒ‡ã‚ªã‚’ YouTube ã«ã‚¢ãƒƒãƒ—
      <center>
	<a href="https://youtu.be/AJi6SzSCDXA">
	  <img src="Screen Shot 2022-06-26 at 14.20.11_thumb.jpg" width="1000" height="575" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>
    <li>
      <center>
	<div style="font-size: 50px; font-weight: bolder;">
	  ãã®å¾Œã€ã™ã”ã„ã“ã¨ã«ãªã‚Šã¾ã—ãŸ
	  <br />
	  ï¼ˆã‚ãã¾ã§ã€å½“ç¤¾æ¯”ã£ã¦ã“ã¨ãªã‚“ã§ã™ãŒï¼‰
	</div>
      </center>
    </li>

    <li>
      <center>
	<a href="Screen Shot 2022-06-26 at 14.10.46.png"><!-- 2067x1188 -->
	  <img src="Screen Shot 2022-06-26 at 14.10.46_thumb.jpg" width="800" height="460" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-06-26 at 14.11.18.png"><!-- 2015x1348 -->
	  <img src="Screen Shot 2022-06-26 at 14.11.18_thumb.jpg" width="800" height="535" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-06-26 at 14.11.34.png"><!-- 2772x1259 -->
	  <img src="Screen Shot 2022-06-26 at 14.11.34_thumb.jpg" width="800" height="363" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-06-26 at 14.11.44.png"><!-- 2766x1198 -->
	  <img src="Screen Shot 2022-06-26 at 14.11.44_thumb.jpg" width="800" height="346" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-06-26 at 14.13.02.png"><!-- 777x520 -->
	  <img src="Screen Shot 2022-06-26 at 14.13.02_thumb.jpg" width="800" height="535" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>
  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <hr />

  <center id="part1">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      ãƒ‘ãƒ¼ãƒˆï¼‘
      æœ€è¿‘ã® AI ã¯æœ¬å½“ã™ã”ã„ã­
    </div>
  </center>

  <ul>
    <li>å…ˆæ—¥ã¾ã§ã€ã¡ã‚‡ã†ã© <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>
      (computer vision and pattern recognition)
      ãŒ New Orleans ã§é–‹å‚¬ã•ã‚Œã¦ã„ãŸ
      <center>
	<a href="Screen Shot 2022-06-27 at 21.22.21.png"><!-- 2687x979 -->
	  <img src="Screen Shot 2022-06-27 at 21.22.21_thumb.jpg" width="1000" height="364" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <ul>
    <li>ã¨ã€ãã®å‰ã«ã€ã¡ã‚‡ã£ã¨ï¼ˆã“ã‚Œã¯ã€å‰åº§ãƒã‚¿ã‹ãªï¼Ÿï¼‰</li>
  </ul>

  <center id="part1-community-oriented-life">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      ä»¤å’Œæ™‚ä»£ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å¿—å‘ãªç”Ÿãæ–¹
    </div>
  </center>

  <ul>
    <li>æœ€è¿‘ã€æ³¨ç›®ã—ã¦ã„ã‚‹ï¼ˆæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ï¼‰äººç‰©ãŒï¼’äºº</li>

    <li>ãã®ï¼‘ï¼š AK ã•ã‚“
      <center>
	<a href="Screen Shot 2022-06-27 at 12.07.26.png"><!-- 1319x637 -->
	  <img src="Screen Shot 2022-06-27 at 12.07.26_thumb.jpg" width="600" height="290" style="border: 2px #ccc solid;" /></a>
      </center>
      <ul>
	<li>ã“ã®äºº AI ã®ç ”ç©¶è€…ã®ç•Œéšˆã§ã€ã“ã‚Œã¾ã§ã‚‚ Twitter ã§ã„ã‚ã„ã‚è©±é¡Œã«ãªã£ã¦ãŸ
	  <ul>
	    <li>ã»ã¼æ¯æ—¥ã®ã‚ˆã†ã«ã€å¤§é‡ã®ã‚ã‚‹ arxiv ã«æŠ•ç¨¿ã•ã‚Œã‚‹
	      AI ã®ãƒ—ãƒ¬ãƒ—ãƒªãƒ³ãƒˆã«ç›®ã‚’é€šã—ã¦ã„ã¦ã€<br />
	      é‡è¦ãã†ãªè«–æ–‡ã‚’ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¦ãƒ„ã‚¤ãƒ¼ãƒˆã—ã¦ã„ãŸã€‚
	    </li>
	    <li>ãã‚ŒãŒã€ãã‚‹æ—¥ã‚‚æ¥ã‚‹æ—¥ã‚‚ãªã®ã§ã€
	      ä¸€éƒ¨ã«ã€Œã‚ã‚Œã¯ AI ã§ä½œã‚‰ã‚ŒãŸ bot ã«é•ã„ãªã„ã€ã¨ã‹ã€<br />
	      ã€ŒAK ã£ã¦ Andrej Karpathy ã˜ã‚ƒã­ï¼Ÿã€ã¨ã‹ã€<br />
	      ãã‚“ãªè©±é¡ŒãŒã‚ãŒã£ã¦ãŸã€‚ï¼ˆãƒã‚¿ã€ã§ã™ã­ï¼‰
	    </li>
	  </ul>
	</li>
	<li>ãã®äººãŒã€ä»Šå›ã€ covid æ˜ã‘ã® CVPR ã®ãƒªã‚¢ãƒ«ã®ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã«è¡Œãã€
	  ã¨ã„ã†ã®ã§ã€è©±é¡Œã«ãªã£ã¦ãŸã€ã¨ã€‚
	  <center>
	    <a href="Screen Shot 2022-06-27 at 12.29.34.png"><!-- 1315x937 -->
	      <img src="Screen Shot 2022-06-27 at 12.29.34_thumb.jpg" width="600" height="428" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>

	<li>ä¼šå ´ã§ã®åå¿œ - ã€Œæœ¬ç‰©ã ã£ãŸï¼ã€ã€Œãƒœãƒƒãƒˆã˜ã‚ƒãªã‹ã£ãŸï¼ã€ã¨
	  <center>
	    <table border="0">
	      <tr>
		<td valign="top">
		  <a href="Screen Shot 2022-06-27 at 12.14.49.png"><!-- 1306x435 -->
		    <img src="Screen Shot 2022-06-27 at 12.14.49_thumb.jpg" width="600" height="200" style="border: 2px #ccc solid;" /></a>
		</td>
		<td valign="top">		
		  <a href="Screen Shot 2022-06-27 at 12.11.59.png"><!-- 1313x1156 -->
		    <img src="Screen Shot 2022-06-27 at 12.11.59_thumb.jpg" width="600" height="528" style="border: 2px #ccc solid;" /></a>
		</td>
	      </tr>
	    </table>
	  </center>
	</li>
	<li>ä¼šå ´ã§ã®åå¿œã€ãã®ï¼’ - ã©ã†ã‚‚ä½•ã‚‰ã‹ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã‚ˆã†ã 
	  <center>
	    <table border="0">
	      <tr>
		<td valign="top">
		  <a href="Screen Shot 2022-06-27 at 12.13.58.png"><!-- 1345x556 -->
		    <img src="Screen Shot 2022-06-27 at 12.13.58_thumb.jpg" width="600" height="248" style="border: 2px #ccc solid;" /></a>
		</td>
		<td valign="top">		
		  <a href="Screen Shot 2022-06-27 at 12.10.46.png"><!-- 1319x929 -->
		    <img src="Screen Shot 2022-06-27 at 12.10.46_thumb.jpg" width="600" height="423" style="border: 2px #ccc solid;" /></a>
		</td>
	      </tr>
	      <tr>
		<td valign="top">
		  <a href="Screen Shot 2022-06-27 at 12.10.41.png"><!-- 1344x819 -->
		    <img src="Screen Shot 2022-06-27 at 12.10.41_thumb.jpg" width="600" height="366" style="border: 2px #ccc solid;" /></a>
		</td>
		<td valign="top">		
		  <a href="Screen Shot 2022-06-27 at 12.10.38.png"><!-- 1311x660 -->
		    <img src="Screen Shot 2022-06-27 at 12.10.38_thumb.jpg" width="600" height="302" style="border: 2px #ccc solid;" /></a>
		</td>
	      </tr>
	    </table>
	  </center>
	</li>

      </ul>
    </li>

    <li>ãã®ï¼’ï¼š iwama ã•ã‚“
      <ul>
	<li><a href="https://twitter.com/iwamah1/status/1540223070321152001">https://twitter.com/iwamah1/status/1540223070321152001</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 12.48.45.png"><!-- 1317x1006 -->
	      <img src="Screen Shot 2022-06-27 at 12.48.45_thumb.jpg" width="600" height="458" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <pre>
ç™»å£‡DONE
Nianticã®Lightship Summit Tokyo 2022ã«iPhone 3Dã‚¹ã‚­ãƒ£ãƒ³ã§ç™»å£‡ã—ãŸç”·ã®å®Ÿç¸¾è§£é™¤ã§ã™
ç™»å£‡ä¸­ãšã£ã¨æ‰‹ãŒéœ‡ãˆã¦ã„ã¾ã—ãŸ
çš†ã•ã‚“ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼ï¼ï¼
#Lightship #Niantic
	  </pre>
	</li>

	<li><a href="https://twitter.com/ShogoNu/status/1540248857551917056">https://twitter.com/ShogoNu/status/1540248857551917056</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 12.49.09.png"><!-- 1297x778 -->
	      <img src="Screen Shot 2022-06-27 at 12.49.09_thumb.jpg" width="600" height="360" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <pre>
iPhone LiDARã‚’å«ã‚“ã ç”·ãŒãƒ†ãƒƒã‚¯æ¥­ç•Œã®ã©çœŸã‚“ä¸­ã«ãã¦ã‚‹ã®æ§ãˆã‚ã«è¨€ã£ã¦ã‚¹ã‚´ã‚¤ã€‚å«ã³ç¶šã‘ã‚‹ã®å¤§äº‹ï¼
	  </pre>
	</li>

      </ul>
    </li><!-- ãã®ï¼’ï¼š iwama ã•ã‚“ -->

  </ul>


  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <ul>
    <li>ã¨ã„ã†ã“ã¨ã§ã€æœ¬é¡Œã«æˆ»ã‚Šã¾ã—ã‚‡ã†</li>
  </ul>

  <center>
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      æœ€è¿‘ã® AI ã¯æœ¬å½“ã™ã”ã„ã­ï¼
    </div>
  </center>

  <ul>
    <li>ãƒ—ãƒ¬ãƒ—ãƒªã‚„ã‚³ãƒ¼ãƒ‰ã®æ™‚ä»£ã¯çµ‚ã‚ã£ã¦ã€
      <center>
	<div style="font-size: 40px; font-weight: bolder;">
	  <br />
	  ãƒ‡ãƒ¢ã‚’ç™ºè¡¨ã—ãªã„ã¨æ³¨ç›®ã•ã‚Œãªã„æ™‚ä»£
	  <br /><br />
	</div>
      </center>
      ã«ãªã£ãŸï¼ˆã¿ãŸã„ï¼‰
      <ul>
	<li><a href="https://twitter.com/abidlabs/status/1539618131139772416">https://twitter.com/abidlabs/status/1539618131139772416</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 12.20.19.png"><!-- 1316x984 -->
	      <img src="Screen Shot 2022-06-27 at 12.20.19_thumb.jpg" width="600" height="449" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <pre>
Slides for my @CVPR 2022 talk: 

"Papers and Code Aren't Enough: Why Demos are Critical to ML Research and How to Build Them"

Thank you to @humphrey_shi and #CVPR2022 for organizing!
<a href="https://docs.google.com/presentation/d/1TXw48MjZFvkVur6rE0tUrEECf76SgUrglTjv0Kb0SWQ/edit#slide=id.g10d8aca05c4_0_10">https://docs.google.com/presentation/d/1TXw...</a>
	  </pre>
	</li>
	<li>ã¨ã„ã†ã“ã¨ã§ã€ä»Šæ—¥ã¯ã€ã™ãå‹•ããƒ‡ãƒ¢ã‚’ä¸­å¿ƒã«ã€ç´¹ä»‹ã—ã¦ã„ãã¾ã—ã‚‡ã†</li>
      </ul>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part1-portrait">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      é¡”ã® 3D å†æ§‹æˆ
    </div>
  </center>

  <ul>
    <li><b>Thin-Plate Spline Motion Model for Image Animation</b> (<a href="https://twitter.com/ak92501/status/1539066735965380608">https://twitter.com/ak92501/status/1539066735965380608</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.25.25.png"><!-- 1300x624 -->
	  <img src="Screen Shot 2022-06-27 at 12.25.25_thumb.jpg" width="600" height="288" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
a @Gradio Demo for Thin-Plate Spline Motion Model for Image Animation
 on @huggingface Spaces for @CVPR 2022 

demo: <a href="https://huggingface.co/spaces/CVPR/Image-Animation-using-Thin-Plate-Spline-Motion-Model">https://huggingface.co/spaces/CVPR/Image-Animation-using-Thin-Plate-Spline-Motion-Model</a>
      </pre>
      <ul>
	<li><a href="https://huggingface.co/spaces/CVPR/Image-Animation-using-Thin-Plate-Spline-Motion-Model">https://huggingface.co/spaces/CVPR/Image-Animation-using-Thin-Plate-Spline-Motion-Model</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 22.15.30.png"><!-- 2673x1057 -->
	      <img src="Screen Shot 2022-06-27 at 22.15.30_thumb.jpg" width="800" height="316" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li>
	  <center>
	    <div style="font-size: 50px; font-weight: bolder;">
	      ã‚„ã£ã¦ã¿ã‚ˆã†ï¼
	    </div>
	  </center>
	  <ul>
	    <li>æº–å‚™
	      <center>
		<a href="KI20220401.jpg"><!-- 1893x1070 -->
		  <img src="KI20220401_thumb.jpg" width="600" height="339" style="border: 2px #ccc solid;" /></a>
		<br />
		<a href="KI20220401-orig.jpg"><!-- 956x957 -->
		  <img src="KI20220401-orig_thumb.jpg" width="400" height="400" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	    <li>çµæœ
	      <center>
		<video controls autoplay muted loop
		       width="256" height="256" style="border: 2px #ccc solid;">
		  <source src="ThinPlateSplineMotionModel.mp4">
		</video>
		<img src="vox.gif" />
	      </center>
	    </li>
	  </ul>
	</li><!-- ã‚„ã£ã¦ã¿ã‚ˆã†ï¼ -->

      </ul>
    </li><!-- Thin-Plate Spline Motion Model for Image Animation -->

    <li><b>DaGAN</b> (<a href="https://twitter.com/danxuhk/status/1537785692201177088">https://twitter.com/danxuhk/status/1537785692201177088</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.33.08.png"><!-- 1298x943 -->
	  <img src="Screen Shot 2022-06-27 at 12.33.08_thumb.jpg" width="600" height="436" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Please check our paper and project for talking head video generation at the incoming CVPR 22 ğŸ˜ƒğŸ˜ƒğŸ˜ƒ
@harlan_hong
 
You may also try our model on the hugging face:
<a href="https://huggingface.co/spaces/HarlanHong/DaGAN">https://huggingface.co/spaces/HarlanHong/DaGAN</a>

Depth-Aware Generative Adversarial Network for Talking Head Video Generation
abs: <a href="https://arxiv.org/abs/2203.06605">https://arxiv.org/abs/2203.06605</a>
github: <a href="https://github.com/harlanhong/CVPR2022-DaGAN">https://github.com/harlanhong/CVPR2022-DaGAN</a>
      </pre>
      <ul>
	<li>DEMO:
	  <a href="https://huggingface.co/spaces/HarlanHong/DaGAN">https://huggingface.co/spaces/HarlanHong/DaGAN</a>
	  <center>
	    <a href="Screen Shot 2022-06-28 at 22.41.54.png"><!-- 2678x1037 -->
	      <img src="Screen Shot 2022-06-28 at 22.41.54_thumb.jpg" width="800" height="310" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li><!-- DaGAN -->

    <li>ä»˜è¨˜ï¼šã‚¤ãƒ™ãƒ³ãƒˆæ™‚ã«ã€ãã®å ´ã§
      <center id="part1-portrait-others">
	<div style="font-size: 50px; font-weight: bolder;">
	  <br />
	  ã‚„ã£ã¦ã¿ãŸ
	</div>
      </center>
      <ul>
	<li>DaGAN ã®ãƒ‡ãƒ¢ã«ã€å‰ã«çŸ¥ã£ã¦ãŸï¼ˆæµ®ä¸–çµµã®é¡”ã®ãƒ‡ãƒ¢ã§ä½¿ã‚ã‚Œã¦ãŸï¼‰
	  å¤‰é¡”ã®å¥³ã®å­ã®ãƒ“ãƒ‡ã‚ªãŒã‚ã£ãŸã®ã§ã€
	  <center id="part1-portrait-others">
	    <div style="font-size: 50px; font-weight: bolder;">
	      <br />
	      æ€¥é½ã€ä¼ç”»
	      <br />
	      ã„ã¡ãã€å¤‰é¡”ã—ã¦ã¿ãŸ
	    </div>
	  </center>
	</li>
	<li>driving video
	  <center>
	    <video controls autoplay muted loop
		   width="256" height="256" style="border: 2px #ccc solid;">
	      <source src="video2.mp4">
	    </video>
	  </center>
	</li>
	<li>çµæœ
	  <center>
	    <table border="0">
	      <tr>
		<th>DaGAN ã®çµæœ</th>
		<th>ThinPlateSpline</th>
	      </tr>
	      <tr>
		<td>
		  <video controls autoplay muted loop
			 width="1024" height="256" style="border: 2px #ccc solid;">
		    <source src="DaGAN-result.mp4">
		  </video>
		</td>
		<td>
		  <video controls autoplay muted loop
			 width="256" height="256" style="border: 2px #ccc solid;">
		    <source src="ThinPlateSpline-result.mp4">
		  </video>
		</td>
	      </tr>
	    </table>
	  </center>
	</li>
      </ul>

    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part1-portrait-others">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      é¡”ã® 3D å†æ§‹æˆã€ã¤ã¥ã
    </div>
  </center>

  <ul>
    <li><b>LIA (and FOMM)</b> (<a href="https://twitter.com/kym384/status/1540957782505320449">https://twitter.com/kym384/status/1540957782505320449</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.42.24.png"><!-- 1317x975 -->
	  <img src="Screen Shot 2022-06-27 at 12.42.24_thumb.jpg" width="600" height="444" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-06-27 at 12.42.48.png"><!-- 1312x1108 -->
	  <img src="Screen Shot 2022-06-27 at 12.42.48_thumb.jpg" width="600" height="507" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
ã‚³ãƒ¼ãƒ‰å…¬é–‹ã•ã‚ŒãŸã®ã§å‹•ã‹ã—ã¦ã¿ãŸ
<a href="https://github.com/wyhsirius/LIA">https://github.com/wyhsirius/LIA</a>

æ¯”è¼ƒã¨ã—ã¦First Order Motion Modelã®å‡ºåŠ›
Driving videoã®å‹•ããŒæ¿€ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã—ã¦ã¯FOMMã‚ˆã‚Šã‚‚è‡ªç„¶ãªå‹•ãã‚’ã—ã¦ã‚‹ã‚ˆã†ã«æ„Ÿã˜ã‚‹

<a href="https://github.com/AliaksandrSiarohin/first-order-model">https://github.com/AliaksandrSiarohin/first-order-model</a>
      </pre>
      <ul>
	<li><a href="https://github.com/wyhsirius/LIA">https://github.com/wyhsirius/LIA</a>
	  <center>
	    <a href="Screen Shot 2022-06-28 at 18.12.52.png"><!-- 2663x753 -->
	      <img src="Screen Shot 2022-06-28 at 18.12.52_thumb.jpg" width="800" height="226" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li><a href="https://github.com/AliaksandrSiarohin/first-order-model">https://github.com/AliaksandrSiarohin/first-order-model</a>
	  <center>
	    <a href="Screen Shot 2022-06-28 at 18.13.01.png"><!-- 2661x1014 -->
	      <img src="Screen Shot 2022-06-28 at 18.13.01_thumb.jpg" width="800" height="305" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li><!-- LIA (and FOMM) -->

    <li><b>GRAM-HD</b> (<a href="https://twitter.com/Buntworthy/status/1537810017449041920">https://twitter.com/Buntworthy/status/1537810017449041920</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 13.05.15.png"><!-- 1306x526 -->
	  <img src="Screen Shot 2022-06-27 at 13.05.15_thumb.jpg" width="600" height="242" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
A horrible nightmare of infinite people shaking their head at me:

GRAM-HD: 3D-Consistent Image Generation at High Resolution
with Generative Radiance Manifolds
abs: <a href="https://arxiv.org/abs/2206.07255">https://arxiv.org/abs/2206.07255</a>
project page: <a href="https://jeffreyxiang.github.io/GRAM-HD/">https://jeffreyxiang.github.io/GRAM-HD/</a>

3D-aware GAN that can generate high resolution images
while keeping strict 3D consistency as in volume rendering
      </pre>
    </li><!-- GRAM-HD -->

    <li><b>RigNeRF</b> (<a href="https://twitter.com/shahrukh_athar/status/1540218740461142022">https://twitter.com/shahrukh_athar/status/1540218740461142022</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.10.52.png"><!-- 1308x957 -->
	  <img src="Screen Shot 2022-06-27 at 12.10.52_thumb.jpg" width="600" height="439" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Really excited to present RigNeRF today at Poster Session 4.2 of #CVPR2022 (@CVPR)!!
Drop by PosterID 161b to discuss RigNeRF, human face modeling,
facial expressions and the future of human avatars!

RigNeRF: Fully Controllable Neural 3D Portraits
abs: <a href="https://arxiv.org/abs/2206.06481">https://arxiv.org/abs/2206.06481</a>
project page: <a href="http://shahrukhathar.github.io/2022/06/06/RigNeRF.html">http://shahrukhathar.github.io/2022/06/06/RigNeRF.html</a>

Using only a smartphone-captured short video of a subject for training,
demonstrate the effectiveness of method on free view synthesis
of a portrait scene
      </pre>
    </li><!-- RigNeRF -->

    <li><b>I M Avatar</b> (<a href="https://twitter.com/ak92501/status/1470971332062031880">https://twitter.com/ak92501/status/1470971332062031880</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.09.11.png"><!-- 1295x656 -->
	  <img src="Screen Shot 2022-06-27 at 12.09.11_thumb.jpg" width="600" height="304" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
I M Avatar: Implicit Morphable Head Avatars from Videos
abs: <a href="https://arxiv.org/abs/2112.07471">https://arxiv.org/abs/2112.07471</a>

github: <a href="https://github.com/zhengyuf/IMavatar">https://github.com/zhengyuf/IMavatar</a>
      </pre>
    </li><!-- I M Avatar -->

    <li>ä»¥ä¸‹ã¯ã€ã‚³ãƒ¼ãƒ‰ãŒã¾ã å…¬é–‹ã•ã‚Œã¦ã„ãªã„</li>

    <li><b>GAN2X</b> (<a href="https://twitter.com/ak92501/status/1539442569733718016">https://twitter.com/ak92501/status/1539442569733718016</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.22.52.png"><!-- 1317x794 -->
	  <img src="Screen Shot 2022-06-27 at 12.22.52_thumb.jpg" width="600" height="362" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
GAN2X: Non-Lambertian Inverse Rendering of Image GANs
abs: <a href="https://arxiv.org/abs/2206.09244">https://arxiv.org/abs/2206.09244</a>
project page: <a href="https://people.mpi-inf.mpg.de/~xpan/GAN2X/">https://people.mpi-inf.mpg.de/~xpan/GAN2X/</a>
      </pre>
      <ul>
	<li>ã‚³ãƒ¼ãƒ‰ã€ãƒ‡ãƒ¢ã¯ã€æœªå…¬é–‹</li>
      </ul>
    </li><!-- GAN2X -->

    <li><b>EpiGRAF</b> (<a href="https://twitter.com/ak92501/status/1539459120667021312">https://twitter.com/ak92501/status/1539459120667021312</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.22.19.png"><!-- 1322x659 -->
	  <img src="Screen Shot 2022-06-27 at 12.22.19_thumb.jpg" width="600" height="299" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
EpiGRAF: Rethinking training of 3D GANs
abs: <a href="https://arxiv.org/abs/2206.10535">https://arxiv.org/abs/2206.10535</a>
project page: <a href="https://universome.github.io/epigraf">https://universome.github.io/epigraf</a>
      </pre>
      <ul>
	<li>ã‚³ãƒ¼ãƒ‰ã¯è¿‘æ—¥å…¬é–‹ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿å‰ã®ã‚³ãƒ¼ãƒ‰ã¯ã‚ã‚‹ã¿ãŸã„ï¼‰</li>
      </ul>
    </li><!-- EpiGRAF -->

    <li><b>ROME</b> (<a href="https://twitter.com/ak92501/status/1537639309888610305">https://twitter.com/ak92501/status/1537639309888610305</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.34.30.png"><!-- 1301x633 -->
	  <img src="Screen Shot 2022-06-27 at 12.34.30_thumb.jpg" width="600" height="292" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Realistic One-shot Mesh-based Head Avatars
abs: <a href="https://arxiv.org/abs/2206.08343">https://arxiv.org/abs/2206.08343</a>
project page: <a href="https://samsunglabs.github.io/rome/">https://samsunglabs.github.io/rome/</a>
      </pre>
      <center>
	<a href="Screen Shot 2022-06-28 at 22.44.07.png"><!-- 2673x1027 -->
	  <img src="Screen Shot 2022-06-28 at 22.44.07_thumb.jpg" width="800" height="307" style="border: 2px #ccc solid;" /></a>
      </center>
      <ul>
	<li>ã‚³ãƒ¼ãƒ‰ã¯ã¾ã </li>
      </ul>
    </li><!-- ROME -->

    <li><b>VoxGRAF</b> (<a href="https://twitter.com/K_S_Schwarz/status/1537442208982237193">https://twitter.com/K_S_Schwarz/status/1537442208982237193</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.38.06.png"><!-- 1315x906 -->
	  <img src="Screen Shot 2022-06-27 at 12.38.06_thumb.jpg" width="600" height="413" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Sparse voxel grids have proven super useful for speeding up novel view synthesis.
Inspired by this, our latest work uses a sparse voxel grid representation
for fast and 3D-consistent generative modeling.

Paper: <a href="https://arxiv.org/abs/2206.07695">https://arxiv.org/abs/2206.07695</a>
Project page: <a href="https://katjaschwarz.github.io/voxgraf/">https://katjaschwarz.github.io/voxgraf/</a>


VoxGRAF: Fast 3D-Aware Image Synthesis with Sparse Voxel Grids
abs: <a href="https://arxiv.org/abs/2206.07695">https://arxiv.org/abs/2206.07695</a>
      </pre>
      <center>
	<a href="Screen Shot 2022-06-28 at 22.46.03.png"><!-- 2677x870 -->
	  <img src="Screen Shot 2022-06-28 at 22.46.03_thumb.jpg" width="800" height="260" style="border: 2px #ccc solid;" /></a>
      </center>
      <ul>
	<li>ã‚³ãƒ¼ãƒ‰ã¯ coming soon...</li>
      </ul>
    </li><!-- VoxGRAF -->

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part1-NeRF">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      3D å†æ§‹æˆã€ NeRF é–¢ä¿‚
    </div>
  </center>

  <ul>
    <li><b>Instant NGP</b> (<a href="https://twitter.com/smallfly/status/1540795797142372353">https://twitter.com/smallfly/status/1540795797142372353</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.43.26.png"><!-- 1332x744 -->
	  <img src="Screen Shot 2022-06-27 at 12.43.26_thumb.jpg" width="600" height="335" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Series of NeRF trained using drone-selfie datasets.
I've a bunch of those - one of the side effects of the social distancing
we went through. Synthesized using @NVIDIAAIDev 's Instant-ngp.â£â£â£â£â£â£â£â£

#selfportrait #AI #NeRF #nerfies #synthesis #neuralrendering #volumetric
      </pre>
      <ul>
	<li><a href="https://twitter.com/jonstephens85/status/1540384170412634112">https://twitter.com/jonstephens85/status/1540384170412634112</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 12.45.32.png"><!-- 1319x767 -->
	      <img src="Screen Shot 2022-06-27 at 12.45.32_thumb.jpg" width="600" height="349" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <pre>
Ferraris are cool, but there is something about American muscle
that always draws me in. I would LOVE to drive a car like this one day...
This was created with @NVIDIAAIDev 's instant NeRF!
Who's watching the @NASCAR Ally 400 this weekend?
#NeuralNetworks #3D
	  </pre>
	</li>
	<li><a href="https://twitter.com/gradeeterna/status/1540380257634631680">https://twitter.com/gradeeterna/status/1540380257634631680</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 12.45.57.png"><!-- 1315x750 -->
	      <img src="Screen Shot 2022-06-27 at 12.45.57_thumb.jpg" width="600" height="342" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <pre>
Trying out the 360 video to AnimeGAN to @NVIDIAAIDev
Instant NeRF workflow on a nature scene.
Turned out a bit fuzzy, but look at those trees and reflectionsğŸ˜
#InstantNeRFSweepstakes #NeRF #instantNGP #volumetric #synthesis
#AI #neuralrendering #neuralradiancefields
	  </pre>
	</li>
	<li><a href="https://twitter.com/jonstephens85/status/1539840525670354944">https://twitter.com/jonstephens85/status/1539840525670354944</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 12.47.38.png"><!-- 1317x840 -->
	      <img src="Screen Shot 2022-06-27 at 12.47.38_thumb.jpg" width="600" height="383" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <pre>
I think I just walked down a path I cannot come back from. 
@Luxottica / @RealityLabs Ray-Ban Stories plus @NVIDIAAIDev Instant-NeRFs.

Imagine me running around a @NASCAR event with these one @Scobleizer ğŸ˜

Notice the bounce is gone without cropping the scene. Get it now?

#3D #AI
	  </pre>
	</li>
	<li><a href="https://twitter.com/van_eng622/status/1540148501887488000">https://twitter.com/van_eng622/status/1540148501887488000</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 12.46.20.png"><!-- 1331x789 -->
	      <img src="Screen Shot 2022-06-27 at 12.46.20_thumb.jpg" width="600" height="356" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <pre>
Facebookã®ã‚¹ãƒãƒ¼ãƒˆã‚°ãƒ©ã‚¹ã€ŒRay-Ban Storiesã€ã§æ’®å½±ã—ãŸç§»å‹•ä¸­ã®å‹•ç”»ã‚’
Instant NeRFã§3DåŒ–ã—ãŸã‚‚ã®

ã“ã®å‹•ç”»ã‹ã‚‰ã€ã“ã“ã¾ã§ã®3Dã‚’ç”Ÿæˆã§ãã‚‹ã®ã‹...
Instant NeRFã‚„ã°ã„ãª

æ™‚ä»£ãŒå‹•ç”»ã‹ã‚‰3Dã«ç§»è¡Œã—ã¦ã„ãã“ã¨ãŒè‚Œã§æ„Ÿã˜ã‚‰ã‚Œã‚‹äº‹ä¾‹
	  </pre>
	</li>

	<li><a href="https://github.com/NVlabs/instant-ngp">https://github.com/NVlabs/instant-ngp</a>
	  <center>
	    <a href="Screen Shot 2022-06-28 at 18.16.26.png"><!-- 2672x787 -->
	      <img src="Screen Shot 2022-06-28 at 18.16.26_thumb.jpg" width="800" height="236" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li><a href="https://developer.nvidia.com/blog/getting-started-with-nvidia-instant-nerfs/">Getting Started with NVIDIA Instant NeRFs (By Jonathan Stephens May 12, 2022)</a>
	  <center>
	    <a href="Screen Shot 2022-06-28 at 18.19.27.png"><!-- 2677x986 -->
	      <img src="Screen Shot 2022-06-28 at 18.19.27_thumb.jpg" width="800" height="295" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li><a href="https://youtu.be/z3-fjYzd0BA">https://youtu.be/z3-fjYzd0BA</a>
	  <center>
	    <a href="Screen Shot 2022-06-28 at 18.21.52.png"><!-- 1777x902 -->
	      <img src="Screen Shot 2022-06-28 at 18.21.52_thumb.jpg" width="800" height="406" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>


	<li><a href="https://speakerdeck.com/itagakim/run-instant-nerf-on-docker">Run Instant NeRF on Docker (masa-ita April 26, 2022)</a>
	</li>

      </ul>
    </li><!-- Instant NGP -->


    <li><b>EyeNeRF</b> (<a href="https://twitter.com/ak92501/status/1538689482534309890">https://twitter.com/ak92501/status/1538689482534309890</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.27.53.png"><!-- 1318x654 -->
	  <img src="Screen Shot 2022-06-27 at 12.27.53_thumb.jpg" width="600" height="298" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
EyeNeRF: A Hybrid Representation for Photorealistic Synthesis, Animation and Relighting of Human Eyes
abs: <a href="https://arxiv.org/abs/2206.08428">https://arxiv.org/abs/2206.08428</a>
      </pre>
    </li><!-- EyeNeRF -->

    <li><b>IRON</b> (<a href="https://twitter.com/Jimantha/status/1539599469305643011">https://twitter.com/Jimantha/status/1539599469305643011</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.20.55.png"><!-- 1306x915 -->
	  <img src="Screen Shot 2022-06-27 at 12.20.55_thumb.jpg" width="600" height="420" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
To all the CVPR-heads out there -- check out @KaiZhang9546 's work on
inverse rendering in this morning's oral session!
Relightable 3D meshes from photos, with really beautiful results.

IRON: Inverse Rendering by Optimizing Neural SDFs and Materials from Photometric Images
abs: <a href="https://arxiv.org/abs/2204.02232">https://arxiv.org/abs/2204.02232</a>
project page: <a href="https://kai-46.github.io/IRON-website/">https://kai-46.github.io/IRON-website/</a>
      </pre>
      <ul>
	<li>github: <a href="https://github.com/Kai-46/IRON">https://github.com/Kai-46/IRON</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 22.03.05.png"><!-- 2673x1122 -->
	      <img src="Screen Shot 2022-06-27 at 22.03.05_thumb.jpg" width="800" height="336" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li><!-- IRON -->

    <li><b>EventNeRF</b> (<a href="https://twitter.com/ak92501/status/1540134704057294848">https://twitter.com/ak92501/status/1540134704057294848</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.14.28.png"><!-- 1294x619 -->
	  <img src="Screen Shot 2022-06-27 at 12.14.28_thumb.jpg" width="600" height="287" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
EventNeRF: Neural Radiance Fields from a Single Colour Event Camera
abs: <a href="https://arxiv.org/abs/2206.11896">https://arxiv.org/abs/2206.11896</a>
project page: <a href="https://4dqv.mpi-inf.mpg.de/EventNeRF/">https://4dqv.mpi-inf.mpg.de/EventNeRF/</a>
      </pre>
    </li><!-- EventNeRF -->

    <li><b>VBA</b> (<a href="https://twitter.com/ronnieclark__/status/1537789877265252352">https://twitter.com/ronnieclark__/status/1537789877265252352</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 13.04.47.png"><!-- 1319x639 -->
	  <img src="Screen Shot 2022-06-27 at 13.04.47_thumb.jpg" width="600" height="291" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Looking for super fast neural volume reconstruction and rendering? 

At #CVPR2022 I'll be presenting Volumetric Bundle Adjustment (VBA).
VBA enables fast and clean reconstruction for live 3D capture
while a video is being recorded.

Project page: <a href="https://r0nn13.github.io/volumetric-bundle-adjustment/">https://r0nn13.github.io/volumetric-bundle-adjustment/</a>
      </pre>
    </li><!-- VBA -->

    <li><b>Multimodal Colored Point Cloud to Image Alignment</b> (<a href="https://twitter.com/ak92501/status/1539820424376320000">https://twitter.com/ak92501/status/1539820424376320000</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.17.22.png"><!-- 1301x528 -->
	  <img src="Screen Shot 2022-06-27 at 12.17.22_thumb.jpg" width="600" height="244" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Multimodal Colored Point Cloud to Image Alignment
paper: <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Rotstein_Multimodal_Colored_Point_Cloud_to_Image_Alignment_CVPR_2022_paper.pdf">pdf</a>
colab: <a href="https://colab.research.google.com/drive/1M_FX4BNDZdSvyzG-htjs-g_IlSvn1mwM?usp=sharing">https://colab.research.google.com/...</a>
      </pre>
    </li><!-- Multimodal Colored Point Cloud to Image Alignment -->

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part1-photogrammetry">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      ãƒ•ã‚©ãƒˆã‚°ãƒ©ãƒ¡ãƒˆãƒªã€LiDAR é–¢ä¿‚
    </div>
  </center>

  <ul>
    <li><a href="https://twitter.com/DuckbillStudio/status/1537723495370858496">https://twitter.com/DuckbillStudio/status/1537723495370858496</a>
      <center>
	<a href="Screen Shot 2022-06-27 at 13.05.45.png"><!-- 1314x633 -->
	  <img src="Screen Shot 2022-06-27 at 13.05.45_thumb.jpg" width="600" height="289" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
æ„›åª›æ¾å±±ã®é‡è¦æ–‡åŒ–è²¡ã€Œè¬ç¿ è˜ã€ã®3DCGå‹•ç”»ã§ã™ã€‚
å®Ÿå†™ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ï¼ãƒ•ã‚©ãƒˆã‚°ãƒ©ãƒ¡ãƒˆãƒªã§åˆ¶ä½œã—ãŸ3Dãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
æ˜¯éYouTubeã®4Kå‹•ç”»ã‚‚è¦‹ã¦ãã ã•ã„ï½ã€‚
#EHIME3D #photogrammetry
      </pre>
    </li>

    <li><a href="https://twitter.com/view0608/status/1540557654262632448">https://twitter.com/view0608/status/1540557654262632448</a>
      <center>
	<a href="Screen Shot 2022-06-27 at 12.44.43.png"><!-- 1332x631 -->
	  <img src="Screen Shot 2022-06-27 at 12.44.43_thumb.jpg" width="600" height="284" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
JRä¸‰ãƒå®®é§…ã®åŒ—å£ã‹ã‚‰å—å£ã‚’æ•£æ­©ã—ãªãŒã‚‰iPhoneã§ã‚¹ã‚­ãƒ£ãƒ³ã€‚
é«˜æ¶ä¸‹ã¯é£²é£Ÿåº—ãŒä¸¦ã³ã€å—å£ã®åºƒå ´ã§ã¯ã‚­ãƒƒãƒãƒ³ã‚«ãƒ¼ã‚„ãƒ‘ãƒ¼ã‚¯ã‚¨ãƒªã‚¢ãŒ
åºƒãŒã‚Šã«ãã‚ã„ã®ã‚ã‚‹ã¾ã¡ã¥ãã‚ŠãŒé€²ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚
ã‚¢ãƒ—ãƒªã¯ @EveryPointIO ã‚’ä½¿ç”¨ã€‚
      </pre>
      <ul>
	<li><a href="https://twitter.com/jonstephens85/status/1540106031665033216">https://twitter.com/jonstephens85/status/1540106031665033216</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 12.47.15.png"><!-- 1316x644 -->
	      <img src="Screen Shot 2022-06-27 at 12.47.15_thumb.jpg" width="600" height="294" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <pre>
What is you could produce a 3d flythrough of a #concrete production plant
every 15 minutes, every hour, on demand?
No need to deploy cameras, they are already there.
When it happens, expect @EveryPointIO and @stockpilereport
to be blazing that trail!
#Mining #ComputerVision
	  </pre>
	</li>

	<li><a href="https://everypoint.io/">https://everypoint.io/</a>
	  <center>
	    <a href="Screen Shot 2022-06-28 at 18.25.36.png"><!-- 2674x665 -->
	      <img src="Screen Shot 2022-06-28 at 18.25.36_thumb.jpg" width="800" height="199" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part1-text-to-image">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      Text to Image ãªã©
    </div>
  </center>

  <ul>
    <li><b>CogView2</b>
      <ul>
	<li><a href="https://twitter.com/gclue_akira/status/1540088475113754624">https://twitter.com/gclue_akira/status/1540088475113754624</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 12.15.51.png"><!-- 1317x569 -->
	      <img src="Screen Shot 2022-06-27 at 12.15.51_thumb.jpg" width="600" height="259" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <pre>
CogView2ã®Webãƒ‡ãƒ¢
<a href="https://huggingface.co/spaces/THUDM/CogView2">https://huggingface.co/spaces/THUDM/CogView2</a>
	  </pre>
	</li>
	<li><a href="https://twitter.com/ak92501/status/1540033980128436226">https://twitter.com/ak92501/status/1540033980128436226</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 12.16.34.png"><!-- 1321x883 -->
	      <img src="Screen Shot 2022-06-27 at 12.16.34_thumb.jpg" width="600" height="401" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <pre>
a @Gradio Demo for CogView2: Faster and Better Text-to-Image Generation
via Hierarchical Transformers on @huggingface Spaces by
<a href="https://huggingface.co/hysts">https://huggingface.co/hysts</a>

demo: <a href="https://huggingface.co/spaces/THUDM/CogView2">https://huggingface.co/spaces/THUDM/CogView2</a>
	  </pre>
	</li>
	<li><a href="https://huggingface.co/spaces/THUDM/CogView2">https://huggingface.co/spaces/THUDM/CogView2</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 21.48.33.png"><!-- 2682x1254 -->
	      <img src="Screen Shot 2022-06-27 at 21.48.33_thumb.jpg" width="800" height="374" style="border: 2px #ccc solid;" /></a>
	    <br />
	    <a href="Screen Shot 2022-06-27 at 21.51.03.png"><!-- 2678x1271 -->
	      <img src="Screen Shot 2022-06-27 at 21.51.03_thumb.jpg" width="400" height="190" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-06-27 at 21.52.08.png"><!-- 2677x1274 -->
	      <img src="Screen Shot 2022-06-27 at 21.52.08_thumb.jpg" width="400" height="190" style="border: 2px #ccc solid;" /></a>
	    
	  </center>
	</li>
      </ul>
    </li><!-- CogView2 -->

    <li><b>RegionCLIP</b> (<a href="https://twitter.com/YiwuZhong/status/1540253720377667584">https://twitter.com/YiwuZhong/status/1540253720377667584</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.12.13.png"><!-- 1328x752 -->
	  <img src="Screen Shot 2022-06-27 at 12.12.13_thumb.jpg" width="600" height="340" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
#CVPR2022 We just released a web demo for RegionCLIP
(<a href="https://huggingface.co/spaces/CVPR/regionclip-demo">https://huggingface.co/spaces/CVPR/regionclip-demo</a>).
The pre-trained RegionCLIP demonstrates interesting results in zero-shot object detection.
Check it out!
If youâ€™re interested in our work, please stop by
our poster 77a on Friday morning!

a @Gradio Demo for RegionCLIP: Region-based Language-Image Pretraining
on @huggingface Spaces for @CVPR 2022 by @jw2yang4ai
      </pre>
      <ul>
	<li><a href="https://huggingface.co/spaces/CVPR/regionclip-demo">https://huggingface.co/spaces/CVPR/regionclip-demo</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 21.43.33.png"><!-- 2679x1257 -->
	      <img src="Screen Shot 2022-06-27 at 21.43.33_thumb.jpg" width="800" height="375" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li><!-- RegionCLIP -->

    <li><b>FLAVA</b> (<a href="https://twitter.com/ak92501/status/1539749459915149313">https://twitter.com/ak92501/status/1539749459915149313</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.18.41.png"><!-- 1316x641 -->
	  <img src="Screen Shot 2022-06-27 at 12.18.41_thumb.jpg" width="600" height="292" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
a @Gradio Demo for FLAVA: A Foundation Language And Vision Alignment Model on 
@huggingface Spaces for @CVPR 2022 by @apsdehal

demo: <a href="https://huggingface.co/spaces/CVPR/flava-multimodal-zero-shot">https://huggingface.co/spaces/CVPR/flava-multimodal-zero-shot</a>
      </pre>
      <ul>
	<li><a href="https://huggingface.co/spaces/CVPR/flava-multimodal-zero-shot">https://huggingface.co/spaces/CVPR/flava-multimodal-zero-shot</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 21.57.30.png"><!-- 2679x1246 -->
	      <img src="Screen Shot 2022-06-27 at 21.57.30_thumb.jpg" width="800" height="372" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li><!-- FLAVA -->

    <li><b>Parti</b> (<a href="https://twitter.com/ak92501/status/1539672920456298498">https://twitter.com/ak92501/status/1539672920456298498</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.19.16.png"><!-- 1319x891 -->
	  <img src="Screen Shot 2022-06-27 at 12.19.16_thumb.jpg" width="600" height="405" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Scaling Autoregressive Models for Content-Rich Text-to-Image Generation
paper: <a href="https://gweb-research-parti.web.app/parti_paper.pdf">https://gweb-research-parti.web.app/parti_paper.pdf</a>
project page: <a href="https://parti.research.google">https://parti.research.google</a>
github: <a href="https://github.com/google-research/parti">https://github.com/google-research/parti</a>

sota zero-shot FID score of 7.23 and finetuned FID score of 3.22 on MS-COCO
      </pre>
    </li><!-- Parti -->

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part1-super-resolution">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      è¶…è§£åƒãªã©
    </div>
  </center>

  <ul>
    <li><b>VideoINR</b> (<a href="https://twitter.com/xiaolonw/status/1537508196557811713">https://twitter.com/xiaolonw/status/1537508196557811713</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 13.06.26.png"><!-- 1317x781 -->
	  <img src="Screen Shot 2022-06-27 at 13.06.26_thumb.jpg" width="600" height="356" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
We are presenting VideoINR in #CVPR2022 ,
a new continuous Video Implicit Neural Representation,
that allows any scale super-resolution / interpolation in both space and time.

Paper: <a href="https://arxiv.org/abs/2206.04647">https://arxiv.org/abs/2206.04647</a>
Project page: <a href="http://zeyuan-chen.com/VideoINR/">http://zeyuan-chen.com/VideoINR/</a>
      </pre>
      <center>
	<a href="Screen Shot 2022-06-28 at 23.02.49.png"><!-- 2678x983 -->
	  <img src="Screen Shot 2022-06-28 at 23.02.49_thumb.jpg" width="800" height="294" style="border: 2px #ccc solid;" /></a>
      </center>
      <ul>
	<li><a href="https://github.com/Picsart-AI-Research/VideoINR-Continuous-Space-Time-Super-Resolution">https://github.com/Picsart-AI-Research/VideoINR-Continuous-Space-Time-Super-Resolution</a>
	  <center>
	    <a href="Screen Shot 2022-06-28 at 23.02.42.png"><!-- 2662x1150 -->
	      <img src="Screen Shot 2022-06-28 at 23.02.42_thumb.jpg" width="800" height="346" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li><!-- VideoINR -->

    <li><b>Come-Closer-Diffuse-Faster</b> (<a href="https://twitter.com/hyungjin_chung/status/1539983653186543616">https://twitter.com/hyungjin_chung/status/1539983653186543616</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.14.54.png"><!-- 1308x1010 -->
	  <img src="Screen Shot 2022-06-27 at 12.14.54_thumb.jpg" width="600" height="463" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
For those interested diffusion models and inverse problems,
come check out our poster on 174a #CVPR2022 ! Joint work with 
@Byeongsu9

Come-Closer-Diffuse-Faster:
Accelerating Conditional Diffusion Models for Inverse Problems through Stochastic Contraction
abs: <a href="https://arxiv.org/abs/2112.05146">https://arxiv.org/abs/2112.05146</a>

method can achieve sota reconstruction performance at significantly reduced sampling steps
      </pre>
    </li><!-- Come-Closer-Diffuse-Faster -->

    <li><b>Megapixel Image Generation...</b> (<a href="https://twitter.com/ak92501/status/1541219433259175937">https://twitter.com/ak92501/status/1541219433259175937</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.07.42.png"><!-- 1303x917 -->
	  <img src="Screen Shot 2022-06-27 at 12.07.42_thumb.jpg" width="600" height="422" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Megapixel Image Generation with Step-Unrolled Denoising Autoencoders
abs: <a href="https://arxiv.org/abs/2206.12351">https://arxiv.org/abs/2206.12351</a>

obtain FID scores of 10.56 on FFHQ256â€”close to the original VQ-GAN
in less than half the sampling stepsâ€”and 21.85 on FFHQ1024
in only 100 sampling steps
      </pre>
    </li><!-- Megapixel Image Generation... -->

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part1-demos">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      ãƒ‡ãƒ¢
    </div>
  </center>

  <ul>
    <li><b>SketchEdit</b> (<a href="https://twitter.com/zengxianyu18/status/1539471341266542593">https://twitter.com/zengxianyu18/status/1539471341266542593</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.21.34.png"><!-- 1315x984 -->
	  <img src="Screen Shot 2022-06-27 at 12.21.34_thumb.jpg" width="600" height="449" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Thanks for sharing our workğŸ˜€ I will be presenting SketchEdit @CVPR 2022.
If you are interested in our work or just want to discuss with me,
donâ€™t hesitate to come by on Wednesday to talk and play the demo,
I am happy to discuss with anyone and make new connections #CVPR2022

SketchEdit: Mask-Free Local Image Manipulation with Partial Sketches
abs: <a href="https://arxiv.org/abs/2111.15078">https://arxiv.org/abs/2111.15078</a>
project page: <a href="https://zengxianyu.github.io/sketchedit/">https://zengxianyu.github.io/sketchedit/</a>
github: <a href="https://github.com/zengxianyu/sketchedit">https://github.com/zengxianyu/sketchedit</a>
      </pre>
      <ul>
	<li><a href="https://github.com/zengxianyu/sketchedit">https://github.com/zengxianyu/sketchedit</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 22.06.50.png"><!-- 2664x1114 -->
	      <img src="Screen Shot 2022-06-27 at 22.06.50_thumb.jpg" width="800" height="335" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li>interactive demo (<a href="http://47.57.135.203:8001/">http://47.57.135.203:8001/</a>)
	  <center>
	    <a href="Screen Shot 2022-06-27 at 22.06.29.png"><!-- 2669x1026 -->
	      <img src="Screen Shot 2022-06-27 at 22.06.29_thumb.jpg" width="800" height="308" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li><!-- SketchEdit -->

    <li><b>Analog Clock Reading in the Wild</b> (<a href="https://twitter.com/ak92501/status/1537989713256099848">https://twitter.com/ak92501/status/1537989713256099848</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.32.00.png"><!-- 1304x865 -->
	  <img src="Screen Shot 2022-06-27 at 12.32.00_thumb.jpg" width="600" height="398" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
a @Gradio Demo for It's About Time: Analog Clock Reading in the Wild
on @huggingface Spaces for @CVPR 2022
 
demo: <a href="https://huggingface.co/spaces/CVPR/time">https://huggingface.co/spaces/CVPR/time</a>
      </pre>
      <ul>
	<li><a href="https://twitter.com/chaaarig/status/1537586593279909888">https://twitter.com/chaaarig/status/1537586593279909888</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 12.36.46.png"><!-- 1308x1014 -->
	      <img src="Screen Shot 2022-06-27 at 12.36.46_thumb.jpg" width="600" height="465" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <pre>
Also have a try at our demo on @Gradio/@huggingface !

Demo: <a href="https://huggingface.co/spaces/CVPR/time">https://huggingface.co/spaces/CVPR/time</a>

and do join the CVPR 2022 organization page to check out other demos
/ make one https://huggingface.co/CVPR
	  </pre>
	</li>
	<li>å®Ÿé¨“<br />
	  <a href="https://twitter.com/DearWatchLover/status/1541673141507829761">https://twitter.com/DearWatchLover/status/1541673141507829761</a>
	  <center>
	    <a href="Screen Shot 2022-06-28 at 23.20.19.png"><!-- 1305x845 -->
	      <img src="Screen Shot 2022-06-28 at 23.20.19_thumb.jpg" width="600" height="389" style="border: 2px #ccc solid;" /></a>
	    <br />
	    <a href="Screen Shot 2022-06-28 at 23.18.37.png"><!-- 2676x925 -->
	      <img src="Screen Shot 2022-06-28 at 23.18.37_thumb.jpg" width="800" height="277" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>

      </ul>
    </li><!-- Analog Clock Reading in the Wild -->

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part1-pose">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      å§¿å‹¢æ¨å®š
    </div>
  </center>

  <ul>
    <li><a href="https://twitter.com/goto_yuta_/status/1539472619585830912">https://twitter.com/goto_yuta_/status/1539472619585830912</a>
      <center>
	<a href="Screen Shot 2022-06-27 at 12.50.56.png"><!-- 1320x626 -->
	  <img src="Screen Shot 2022-06-27 at 12.50.56_thumb.jpg" width="600" height="285" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
NVIDIAãŒå§¿å‹¢æ¨å®šã§ãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ã‚’èµ·ã“ã—ãŸç†ç”±ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã¦ã‚‹è¨˜äº‹ã€‚
æ—¢å­˜ã®æŠ€è¡“ã ã¨ç‰©ç†æ³•å‰‡ã‚’ç„¡è¦–ã—ãŸæ¨å®šçµæœãŒå¤šã‹ã£ãŸã“ã¨ã‚’è¸ã¾ãˆã¦
æå¤±ã«ç‰©ç†åˆ¶ç´„ã‚’ç››ã‚Šè¾¼ã‚“ã§å®šå¼åŒ–ã—ã¦ç²¾åº¦ã‚’è·³ã­ä¸Šã’ãŸã‚‰ã—ã„ã€‚
<a href="https://medium.com/aiguys/pose-estimation-and-nvidias-breakthrough-16fb6263bd48">https://medium.com/aiguys/pose-estimation-and-nvidias-breakthrough-16fb6263bd48</a>
      </pre>
      <ul>
	<li><a href="https://medium.com/aiguys/pose-estimation-and-nvidias-breakthrough-16fb6263bd48">Pose estimation and NVIDIAâ€™s breakthrough (Vishal Rajput Jan 2)</a>
	  <center>
	    <a href="Screen Shot 2022-06-28 at 18.38.38.png"><!-- 2681x1147 -->
	      <img src="Screen Shot 2022-06-28 at 18.38.38_thumb.jpg" width="800" height="342" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><b>Strided Transformer for Pose 3D</b> (<a href="https://twitter.com/PINTO03091/status/1540937546792075264">https://twitter.com/PINTO03091/status/1540937546792075264</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.41.08.png"><!-- 1324x621 -->
	  <img src="Screen Shot 2022-06-27 at 12.41.08_thumb.jpg" width="600" height="281" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
å®Ÿéš›ã«å‹•ã‹ã—ã¦ã‹ãªã‚Šã‚­ãƒ¬ã‚¤ã«ä¸‰æ¬¡å…ƒæ¨å®šã§ããŸã®ã ã‘ã©ã€å‡¦ç†ã«æ™‚é–“æ›ã‹ã‚Šã™ãï½—
<a href="https://github.com/Vegetebird/StridedTransformer-Pose3D">https://github.com/Vegetebird/StridedTransformer-Pose3D</a>
      </pre>
      <ul>
	<li><a href="https://github.com/Vegetebird/StridedTransformer-Pose3D">https://github.com/Vegetebird/StridedTransformer-Pose3D</a>
	  <center>
	    <a href="Screen Shot 2022-06-28 at 18.09.50.png"><!-- 2854x776 -->
	      <img src="Screen Shot 2022-06-28 at 18.09.50_thumb.jpg" width="800" height="218" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><b>TAVA</b> (<a href="https://twitter.com/ak92501/status/1538719219818409994">https://twitter.com/ak92501/status/1538719219818409994</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.26.26.png"><!-- 1295x691 -->
	  <img src="Screen Shot 2022-06-27 at 12.26.26_thumb.jpg" width="600" height="320" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
TAVA: Template-free Animatable Volumetric Actors
abs: <a href="https://arxiv.org/abs/2206.08929">https://arxiv.org/abs/2206.08929</a>
project page: <a href="https://liruilong.cn/projects/tava/">https://liruilong.cn/projects/tava/</a>
      </pre>
    </li><!-- TAVA -->

    <li><b>MediaPipe</b> (<a href="https://twitter.com/yeemachine/status/1539639359657447424">https://twitter.com/yeemachine/status/1539639359657447424</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.46.43.png"><!-- 1322x1059 -->
	  <img src="Screen Shot 2022-06-27 at 12.46.43_thumb.jpg" width="600" height="481" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
It still feels like a dream. 
Yes, I am working on #Vtuber tech at Google AI! 
ğŸ’ªğŸ˜ğŸ’ª
Our new BlazePose GHUM Holistic model predicts full body
and hand joint rotations for 3D avatars.
Available soon at <a href="http://mediapipe.dev">http://mediapipe.dev</a>. ğŸğŸ’ƒğŸµ

Paper and live demo at @CVPR for #CVPR2022.
      </pre>
    </li><!-- MediaPipe -->

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part1-misc">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      ãã®ä»–
    </div>
  </center>

  <ul>
    <li><b>ShapeFormer</b> (<a href="https://twitter.com/yan_xg/status/1539109905743101952">https://twitter.com/yan_xg/status/1539109905743101952</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.24.24.png"><!-- 1310x911 -->
	  <img src="Screen Shot 2022-06-27 at 12.24.24_thumb.jpg" width="600" height="417" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Code/pretained model is released, please have a try! ğŸ˜
<a href="https://github.com/QhelDIV/ShapeFormer">https://github.com/QhelDIV/ShapeFormer</a>

ShapeFormer: Transformer-based Shape Completion via Sparse Representation
abs: <a href="https://arxiv.org/abs/2201.10326">https://arxiv.org/abs/2201.10326</a>
project page: <a href="https://shapeformer.github.io">https://shapeformer.github.io</a>
      </pre>
      <ul>
	<li><a href="https://github.com/QhelDIV/ShapeFormer">https://github.com/QhelDIV/ShapeFormer</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 22.13.12.png"><!-- 2675x1161 -->
	      <img src="Screen Shot 2022-06-27 at 22.13.12_thumb.jpg" width="800" height="347" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li><!-- ShapeFormer -->


    <li><b>iSEE</b> (<a href="https://twitter.com/ak92501/status/1538706936211951617">https://twitter.com/ak92501/status/1538706936211951617</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.27.14.png"><!-- 1310x762 -->
	  <img src="Screen Shot 2022-06-27 at 12.27.14_thumb.jpg" width="600" height="349" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
What do navigation agents learn about their environment?
abs: <a href="https://arxiv.org/abs/2206.08500">https://arxiv.org/abs/2206.08500</a>
github: <a href="https://github.com/allenai/iSEE">https://github.com/allenai/iSEE</a>
      </pre>
    </li><!-- iSEE -->

    <li><b>PlanarRecon</b> (<a href="https://twitter.com/gadelha_m/status/1537546360622157824">https://twitter.com/gadelha_m/status/1537546360622157824</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.37.19.png"><!-- 1312x859 -->
	  <img src="Screen Shot 2022-06-27 at 12.37.19_thumb.jpg" width="600" height="393" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Always nice to see the work in AKâ€™s feed! Congrats, @YimingXie4!

PlanarRecon: Real-time 3D Plane Detection and Reconstruction from Posed Monocular Videos
abs: <a href="https://arxiv.org/abs/2206.07710">https://arxiv.org/abs/2206.07710</a>
project page: <a href="https://neu-vi.github.io/planarrecon/">https://neu-vi.github.io/planarrecon/</a>
      </pre>
    </li><!-- PlanarRecon -->


    <li><b>NU-Wave 2</b> (<a href="https://twitter.com/ak92501/status/1538686489491648514">https://twitter.com/ak92501/status/1538686489491648514</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.28.29.png"><!-- 1324x826 -->
	  <img src="Screen Shot 2022-06-27 at 12.28.29_thumb.jpg" width="600" height="374" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates
abs: <a href="https://arxiv.org/abs/2206.08545">https://arxiv.org/abs/2206.08545</a>

a diffusion model for neural audio upsampling that enables the generation of
48 kHz audio signals from inputs of various sampling rates with a single model
      </pre>
    </li><!-- NU-Wave 2 -->

    <li><b>AI Song Contest 2022 - the finalists</b> (<a href="https://twitter.com/keunwoochoi/status/1537825500864839683">https://twitter.com/keunwoochoi/status/1537825500864839683</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.30.10.png"><!-- 1350x466 -->
	  <img src="Screen Shot 2022-06-27 at 12.30.10_thumb.jpg" width="600" height="207" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
<a href="https://aisongcontest.com/the-2022-finalists">https://aisongcontest.com/the-2022-finalists</a>

AI Song Contest 2022 - the finalists ğŸ”¥ğŸ”¥ğŸ”¥
      </pre>
      <ul>
	<li><a href="https://aisongcontest.com/the-2022-finalists">https://aisongcontest.com/the-2022-finalists</a>
	  <center>
	    <a href="Screen Shot 2022-06-28 at 17.55.13.png"><!-- 2681x778 -->
	      <img src="Screen Shot 2022-06-28 at 17.55.13_thumb.jpg" width="800" height="232" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li><!-- AI Song Contest 2022 - the finalists -->

    <li><b>Virtual Correspondences</b> (<a href="https://twitter.com/ShenlongWang/status/1537904063127224320">https://twitter.com/ShenlongWang/status/1537904063127224320</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 13.02.28.png"><!-- 1313x720 -->
	  <img src="Screen Shot 2022-06-27 at 13.02.28_thumb.jpg" width="600" height="329" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Excited to share our #CVPR2022 work on
associating images with extreme viewpoint differences!
We propose to find "virtual correspondences"
and use them to reason relative camera poses. 

Please check the project website for more details: 
<a href="https://virtual-correspondence.github.io">https://virtual-correspondence.github.io</a>
      </pre>
      <ul>
	<li><a href="https://twitter.com/weichiuma/status/1537875561745223680">https://twitter.com/weichiuma/status/1537875561745223680</a>
	  <center>
	    <a href="Screen Shot 2022-06-27 at 12.31.07.png"><!-- 1305x1221 -->
	      <img src="Screen Shot 2022-06-27 at 12.31.07_thumb.jpg" width="600" height="561" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <pre>
Can you match images with little or no overlaps?
 
Humans canğŸ§ but most existing methods failğŸ˜°
 
Our #CVPR2022 paper shoots camera rays through the scene to form
â€œvirtual correspondencesâ€ & uses epipolar geometry.
 
w/ @ajyang99 @ShenlongWang @RaquelUrtasun Antonio Torralba
	  </pre>
	</li>
      </ul>
    </li><!-- Virtual Correspondences -->


    <li><b>BYOL-Explore</b> (<a href="https://twitter.com/ak92501/status/1537621348339572736">https://twitter.com/ak92501/status/1537621348339572736</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.35.20.png"><!-- 1331x909 -->
	  <img src="Screen Shot 2022-06-27 at 12.35.20_thumb.jpg" width="600" height="410" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
BYOL-Explore: Exploration by Bootstrapped Prediction
abs: <a href="https://arxiv.org/abs/2206.08332">https://arxiv.org/abs/2206.08332</a>

BYOL-Explore achieves superhuman performance on
the ten hardest exploration games in Atari
while having a much simpler design than other competitive agents
      </pre>
    </li><!-- BYOL-Explore -->


    <li><b>HuggingFace Hub Client Library</b> (<a href="https://twitter.com/mervenoyann/status/1540470328111030274">https://twitter.com/mervenoyann/status/1540470328111030274</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.42.02.png"><!-- 1309x823 -->
	  <img src="Screen Shot 2022-06-27 at 12.42.02_thumb.jpg" width="600" height="377" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
automate your workflows with @huggingface Hub client library ğŸ˜
      </pre>
    </li><!-- HuggingFace Hub Client Library -->


    <li><b>Open-source large language models</b> (<a href="https://twitter.com/awnihannun/status/1540055549156372480">https://twitter.com/awnihannun/status/1540055549156372480</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 12.48.18.png"><!-- 1312x731 -->
	  <img src="Screen Shot 2022-06-27 at 12.48.18_thumb.jpg" width="600" height="334" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Open-source large language models is moving fast.
Just today, three big releases:
* Google's UL2 20B on HuggingFace <a href="https://huggingface.co/google/ul2">https://huggingface.co/google/ul2</a>
* Meta's OPT 65B <a href="https://github.com/facebookresearch/metaseq/tree/main/projects/OPT">https://github.com/facebookresearch/metaseq/tree/main/projects/OPT</a>
* Yandex 100B (!) LM <a href="https://github.com/yandex/YaLM-100B">https://github.com/yandex/YaLM-100B</a>
      </pre>
    </li><!-- Open-source large language models -->

    <li><a href="https://twitter.com/AlexandreDevaux/status/1539946052824055808">https://twitter.com/AlexandreDevaux/status/1539946052824055808</a>
      <center>
	<a href="Screen Shot 2022-06-27 at 12.49.33.png"><!-- 1315x665 -->
	  <img src="Screen Shot 2022-06-27 at 12.49.33_thumb.jpg" width="600" height="303" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Push your walls Ã  la Spike Jonze in #MixedReality ğŸ™‚
In #WebXR (hololens) :
  Detect Wall (Hit-Test)
+ Capture and project (UserMediaAPI)
+ Vertex displacement
@NYTimesRD #AR
      </pre>
    </li>

    <li><a href="https://twitter.com/jaguring1/status/1539913772063543296">https://twitter.com/jaguring1/status/1539913772063543296</a>
      <center>
	<a href="Screen Shot 2022-06-27 at 12.50.07.png"><!-- 1332x777 -->
	  <img src="Screen Shot 2022-06-27 at 12.50.07_thumb.jpg" width="600" height="350" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
2021å¹´
1æœˆï¼šDALL-Eã€CLIP
5æœˆï¼šLaMDA
6æœˆï¼šCodex
8æœˆï¼šJurassic-1
9æœˆï¼šFLAN
10æœˆï¼šMT-NLG
11æœˆï¼šFlorenceã€ExT5
12æœˆï¼šGopherã€GaLMã€GLIDE

2022å¹´
2æœˆï¼šAlphaCodeã€Perceiver AR
3æœˆï¼šChinchilla
4æœˆï¼šPaLMã€DALL-E2ã€Flamingo
5æœˆï¼šOPT-175Bã€CoCaã€UL2ã€Gatoã€Imagen
6æœˆï¼šUnified-IOã€Parti
      </pre>
    </li>

    <li><a href="https://twitter.com/ogawa_yutaro_22/status/1538661505000173568">https://twitter.com/ogawa_yutaro_22/status/1538661505000173568</a>
      <center>
	<a href="Screen Shot 2022-06-27 at 13.01.13.png"><!-- 1314x733 -->
	  <img src="Screen Shot 2022-06-27 at 13.01.13_thumb.jpg" width="600" height="335" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Googleå…¨ä½“ã¨ã—ã¦ã€TensorFlowã‹ã‚‰JAXã¸ã¨ç§»è¡Œã™ã‚‹æ°—é…ã§ã™ã€‚
ä»Šå¾Œã®TFã®ãƒ¡ãƒ³ãƒ†ã¯ã©ã†ãªã‚‹ã‚“ã ã‚ã†

ç¢ºã‹ã«JAXã¯ä½¿ã„ã‚„ã™ã„éƒ¨åˆ†ã‚‚ã‚ã‚Šã€PyTorchã‚‚JAXã®æ©Ÿèƒ½ã‚’å–ã‚Šè¾¼ã‚“ã§ã„ã¾ã™
ï¼ˆFUNCTORCHï¼š<a href="https://pytorch.org/functorch/stable/">https://pytorch.org/functorch/stable/</a>ï¼‰

2éšå¾®åˆ†ã®ãƒ˜ã‚·ã‚¢ãƒ³ã®è¨ˆç®—ã¨ã‹ä¸ä¾¿ãªã®ã§

ä»Šå¾Œã¯PyTorchã‹JAXã‹ã«ãªã‚Šãã†ã§ã™


After losing out to PyTorch, Google is quietly moving
to roll out a new AI framework internally called JAX.
It's expected to become the underpinning of Google's products,
fixing some of TensorFlow's biggest pain points
that frustrate Googlers internally
      </pre>
    </li>

    <li><b>Project Aria</b> (<a href="https://twitter.com/TweetEdMiller/status/1537495397509349378">https://twitter.com/TweetEdMiller/status/1537495397509349378</a>)
      <center>
	<a href="Screen Shot 2022-06-27 at 13.03.46.png"><!-- 1324x636 -->
	  <img src="Screen Shot 2022-06-27 at 13.03.46_thumb.jpg" width="600" height="288" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Ahead of #CVPR2022 ,
Iâ€™m excited to share the open dataset of Project Aria data
from Meta Reality Labs,
along with accompanying open research tools
designed to accelerate AI and ML research.
<a href="https://about.facebook.com/realitylabs/projectaria/datasets">https://about.facebook.com/realitylabs/projectaria/datasets</a>
A little about the dataset and why I think itâ€™s so excitingâ€¦
      </pre>
      <ul>
	<li><a href="https://about.facebook.com/realitylabs/projectaria/datasets">Project Aria Pilot Dataset</a>
	  <center>
	    <a href="Screen Shot 2022-06-28 at 18.43.23.png"><!-- 2678x1155 -->
	      <img src="Screen Shot 2022-06-28 at 18.43.23_thumb.jpg" width="800" height="345" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li><!-- Project Aria -->

    <li><a href="https://twitter.com/psi_ni_phi/status/1537784531553353729">https://twitter.com/psi_ni_phi/status/1537784531553353729</a>
      <center>
	<a href="Screen Shot 2022-06-27 at 13.03.09.png"><!-- 1323x723 -->
	  <img src="Screen Shot 2022-06-27 at 13.03.09_thumb.jpg" width="600" height="328" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
MeshDeformã§é¡”ã®ãƒ‘ãƒ¼ã‚¹è£œæ­£ã§ãã‚‹ã‹æ¤œè¨¼ã—ãŸã‚‰ã‚ã£ã•ã‚Šã¨ä¸Šæ‰‹ãã„ã£ã¦ãƒ“ãƒƒã‚¯ãƒªã€‚
ã‚«ãƒ¡ãƒ©ã®è¦–ç·šã«åˆã†ã‚ˆã†ç«‹æ–¹ä½“ã‚’ã‚¹ã‚¯ã‚·ãƒ§ã®ã‚ˆã†ã«æ‰‹å‰å´ã‚’çµã‚‹ã ã‘ã€‚
è¦ã¯ã€å¹³è¡ŒæŠ•å½±ã§è¨­å®šç”»ã‹ã‚‰3Dèµ·ã“ã™ã¨ã€
ãƒ‘ãƒ¼ã‚¹ãŒã‹ã‹ã£ãŸæ™‚ã«ä¸è‡ªç„¶ãªé¡”ã«ãªã‚‹ç¾è±¡ã‚’è£œæ­£ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚
ãŠè©¦ã—ã‚ã‚Œã€‚
#b3d #blender3d #ã‚†ã‚‹ã‚­ãƒ£ãƒ³Î”
      </pre>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <hr />

  <center id="part2">
    <div style="font-size: 50px; font-weight: bolder;">
      ãƒ‘ãƒ¼ãƒˆï¼’
      æŠ€è¡“æ›¸å…¸ï¼‘ï¼“ä¼ç”»ä¼šè­°ï¼
    </div>
  </center>

  <ul>
    <li>å‚åŠ ç”³ã—è¾¼ã¿ã‚’ã—ã¾ã—ãŸï¼ (<a href="https://twitter.com/zenkeiaif/status/1542038873936924672">https://twitter.com/zenkeiaif/status/1542038873936924672</a>)
      <center>
	<a href="Screen Shot 2022-06-29 at 15.55.00.png"><!-- 1319x930 -->
	  <img src="Screen Shot 2022-06-29 at 15.55.00_thumb.jpg" width="600" height="423" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>

    <li>ã“ã‚Œã¾ã§å‚åŠ ã—ãŸæŠ€è¡“æ›¸å…¸
      <center>
	<a href="Screen Shot 2022-06-29 at 16.02.14.png"><!-- 2780x919 -->
	  <img src="Screen Shot 2022-06-29 at 16.02.14_thumb.jpg" width="800" height="264" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-invitation">
    <div style="font-size: 50px; font-weight: bolder;">
      æŠ€è¡“æ›¸å…¸ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆï¼‰ã¸ã®ãŠèª˜ã„
    </div>
    <br /><br />
    <div style="font-size: 40px; font-weight: bolder;">
      åŒäººèªŒæ´»å‹•ã¯<br />
      ä»Šã®ãƒ“ã‚¸ãƒã‚¹ã®æœ€å…ˆç«¯ï¼
    </div>
  </center>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <ul>
    <li id="part2-mission-statement">ã‚³ãƒ­ãƒŠã§ ZOOM åŒ–ã—ãŸå¾Œã®
      <center>
	<div style="font-size: 50px; font-weight: bolder;">
	  ã€ŒZENKEI AI FORUM ã¨ã¯ä½•ã‹ï¼Ÿã€
	</div>
      </center>
      ã«ã¤ã„ã¦æ€ç´¢ã«è€½ã£ã¦ã„ãŸé ƒ
      <ul>
	<li><a href="https://youtu.be/tWvm7LmXKhE?t=2776">ZAF-2006</a> - ç€§æœ¬å“²å²</li>
	<li><a href="https://youtu.be/JzggEa_tPE4?t=659">ZAF-2008</a>ã€ŒZAF ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ãƒ»ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã€</li>
      </ul>
      <center>
	<a href="Screen Shot 2022-06-29 at 17.39.27.png"><!-- 1777x1120 -->
	  <img src="Screen Shot 2022-06-29 at 17.39.27_thumb.jpg" width="500" height="315" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-06-29 at 17.36.24.png"><!-- 1779x1117 -->
	  <img src="Screen Shot 2022-06-29 at 17.36.24_thumb.jpg" width="500" height="314" style="border: 2px #ccc solid;" /></a>
      </center>
      <center>
	<a href="Screen Shot 2022-06-29 at 17.21.41.png"><!-- 2546x743 -->
	  <img src="Screen Shot 2022-06-29 at 17.21.41_thumb.jpg" width="1000" height="292" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-06-29 at 17.22.04.png"><!-- 2547x1425 -->
	  <img src="Screen Shot 2022-06-29 at 17.22.04_thumb.jpg" width="1000" height="559" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-06-29 at 17.22.11.png"><!-- 2544x1419 -->
	  <img src="Screen Shot 2022-06-29 at 17.22.11_thumb.jpg" width="1000" height="558" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-fandom-economy">
    <div style="font-size: 50px; font-weight: bolder;">
      åŒäººèªŒæ´»å‹•ã¯<br />
      ä»Šã®ãƒ“ã‚¸ãƒã‚¹ã®æœ€å…ˆç«¯ï¼
    </div>
  </center>

  <ul>
    <li>è‹¥æ—æµã®æœ¬ã€<a href="https://www.amazon.co.jp/dp/499112607X">ã¯ã‚Šã¼ã¦ç‹å›½å¹´ä»£è¨˜ ã€é€±åˆŠã ãˆã‚“å•ç­” ç¬¬2é›†ã€‘</a>ã€ã‹ã‚‰
      <center>
	<a href="Screen Shot 2022-06-29 at 16.59.53.png"><!-- 2754x903 -->
	  <img src="Screen Shot 2022-06-29 at 16.59.53_thumb.jpg" width="1000" height="328" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-06-29 at 17.00.34.png"><!-- 2761x992 -->
	  <img src="Screen Shot 2022-06-29 at 17.00.34_thumb.jpg" width="1000" height="359" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>

    <li>ã“ã®è©±ã¯ã€å¤šåˆ†ã€ä»¥ä¸‹ã®æœ¬ã€<a href="https://www.amazon.co.jp/dp/4833441292">ãƒ•ã‚¡ãƒ³ãƒ€ãƒ ã‚¨ã‚³ãƒãƒŸãƒ¼å…¥é–€</a>ã€ã®å†…å®¹ã«ç¶šã„ã¦ã„ãã‚“ã ã¨æ€ã†
      <center>
	<a href="Screen Shot 2022-06-29 at 17.05.03.png"><!-- 1761x1193 -->
	  <img src="Screen Shot 2022-06-29 at 17.05.03_thumb.jpg" width="800" height="542" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <ul>
    <li id="part2-line-up">ã“ã‚Œã¾ã§ã®ãƒ©ã‚¤ãƒ³ãƒŠãƒƒãƒ—
      <center>
	<a href="Screen Shot 2022-06-29 at 16.26.31.png"><!-- 2784x511 -->
	  <img src="Screen Shot 2022-06-29 at 16.26.31_thumb.jpg" width="1000" height="184" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-06-29 at 16.26.39.png"><!-- 2772x1100 -->
	  <img src="Screen Shot 2022-06-29 at 16.26.39_thumb.jpg" width="1000" height="397" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-06-29 at 16.26.51.png"><!-- 2780x1016 -->
	  <img src="Screen Shot 2022-06-29 at 16.26.51_thumb.jpg" width="1000" height="365" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-06-29 at 16.27.03.png"><!-- 2789x942 -->
	  <img src="Screen Shot 2022-06-29 at 16.27.03_thumb.jpg" width="1000" height="338" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-06-29 at 16.27.13.png"><!-- 2784x1063 -->
	  <img src="Screen Shot 2022-06-29 at 16.27.13_thumb.jpg" width="1000" height="382" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-06-29 at 16.27.22.png"><!-- 2667x1419 -->
	  <img src="Screen Shot 2022-06-29 at 16.27.22_thumb.jpg" width="1000" height="532" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>
  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <ul>
    <li id="part2-my-personal-project">è‡ªåˆ†ã®ä¼ç”»
      <ul>
	<li>ä¸‰éƒ¨ä½œã®å‰æ—¥è­šã¨ã—ã¦ã®ãƒŠãƒ³ãƒãƒ¼ãƒ»ã‚¼ãƒ­
	  <ul>
	    <li>ã¾ãšã¯è¡¨ç´™ã‹ã‚‰ãƒ„ã‚¤ãƒ¼ãƒˆ (<a href="https://twitter.com/ichiki_k/status/1386981834223886339">https://twitter.com/ichiki_k/status/1386981834223886339</a>)
	      <center>
		<a href="Screen Shot 2022-06-29 at 16.15.11.png"><!-- 1238x1277 -->
		  <img src="Screen Shot 2022-06-29 at 16.15.11_thumb.jpg" width="582" height="600" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	    <li>å®£è¨€ãƒ„ã‚¤ãƒ¼ãƒˆ (<a href="https://twitter.com/ichiki_k/status/1388740363091726338">https://twitter.com/ichiki_k/status/1388740363091726338</a>)
	      <center>
		<a href="Screen Shot 2022-06-29 at 16.13.51.png"><!-- 1235x1332 -->
		  <img src="Screen Shot 2022-06-29 at 16.13.51_thumb.jpg" width="556" height="600" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	    <li>é€²ã‚“ã§ãªã„é€²æ—ã®æ‡ºæ‚”ãƒ„ã‚¤ãƒ¼ãƒˆ
	      (<a href="https://twitter.com/ichiki_k/status/1487400479110082560">https://twitter.com/ichiki_k/status/1487400479110082560</a>)
	      <center>
		<table border="0">
		  <tr>
		    <td valign="top">
		      <a href="Screen Shot 2022-06-29 at 16.09.32.png"><!-- 1223x497 -->
			<img src="Screen Shot 2022-06-29 at 16.09.32_thumb.jpg" width="600" height="244" style="border: 2px #ccc solid;" /></a>
		    </td>
		    <td valign="top">
		      <a href="Screen Shot 2022-06-29 at 16.09.41.png"><!-- 1220x1291 -->
			<img src="Screen Shot 2022-06-29 at 16.09.41_thumb.jpg" width="567" height="600" style="border: 2px #ccc solid;" /></a>
		    </td>
		  </tr>
		</table>
	      </center>
	    </li>
	  </ul>
	</li>

      </ul>
    </li><!-- è‡ªåˆ†ã®ä¼ç”» -->
  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <ul>
    <li id="part2-as-a-circle">ã‚µãƒ¼ã‚¯ãƒ«ã®ä¼ç”»
      <ul>
	<li>ZAM æ§‹æƒ³ï¼ˆæ—¢åˆŠ - å°åˆ·ç‰ˆã¯ <a href="https://zenkei.booth.pm/">BOOTH</a> ã§é ’å¸ƒä¸­ï¼‰
	  <center>
	    <a href="Screen Shot 2022-06-29 at 16.47.20.png"><!-- 2789x699 -->
	      <img src="Screen Shot 2022-06-29 at 16.47.20_thumb.jpg" width="1000" height="251" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-06-29 at 16.47.23.png"><!-- 2792x804 -->
	      <img src="Screen Shot 2022-06-29 at 16.47.23_thumb.jpg" width="1000" height="288" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-06-29 at 16.47.29.png"><!-- 2762x791 -->
	      <img src="Screen Shot 2022-06-29 at 16.47.29_thumb.jpg" width="1000" height="286" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li>æœªå®Œã®æœˆåˆŠ ZAM ã©ã†ãªã£ã¦ã‚‹ã®ã‹ï¼Ÿ
	  (cf. <a href="https://hello-ai-forum.github.io/pages/ZAF202205/ichiki/">ZAF-2205</a>)
	  <center>
	    <a href="Screen Shot 2022-06-29 at 16.40.43.png"><!-- 2671x704 -->
	      <img src="Screen Shot 2022-06-29 at 16.40.43_thumb.jpg" width="1000" height="264" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-06-29 at 16.40.22.png"><!-- 2670x812 -->
	      <img src="Screen Shot 2022-06-29 at 16.40.22_thumb.jpg" width="1000" height="304" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-06-29 at 16.40.29.png"><!-- 2671x787 -->
	      <img src="Screen Shot 2022-06-29 at 16.40.29_thumb.jpg" width="1000" height="295" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-06-29 at 16.40.34.png"><!-- 2668x1184 -->
	      <img src="Screen Shot 2022-06-29 at 16.40.34_thumb.jpg" width="1000" height="444" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-06-29 at 16.40.39.png"><!-- 2671x801 -->
	      <img src="Screen Shot 2022-06-29 at 16.40.39_thumb.jpg" width="1000" height="300" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li><!-- ã‚µãƒ¼ã‚¯ãƒ«ã®ä¼ç”» -->

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />


  <center id="part2-lets-discuss">
    <div style="font-size: 50px; font-weight: bolder;">
      æŠ€è¡“æ›¸å…¸ï¼‘ï¼“<br />
      ä¼ç”»ä¼šè­°ï¼
    </div>
  </center>

  <ul>
    <li>ä»˜è¨˜ï¼šå½“æ—¥ã®ä¼ç”»ä¼šè­°ã®æ¨¡æ§˜
      <center>
	<a href="Screen Shot 2022-06-30 at 11.52.58.png"><!-- 2767x1091 -->
	  <img src="Screen Shot 2022-06-30 at 11.52.58_thumb.jpg" width="1000" height="394" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>
  </ul>


  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="epilogue">
    <div style="font-size: 50px; font-weight: bolder;">
      ä»Šæ—¥ã®ãŠã‚ã‚Šã«
    </div>
  </center>

  <p>â€¦â€¦</p>

  <h3>ä»Šå¾Œã®äºˆå®š</h3>
  <ul>
    <li>æ¬¡å› ZAF ã¯ 2022 å¹´ï¼—æœˆï¼’ï¼—æ—¥é–‹å‚¬ã®äºˆå®šã§ã™ã€‚</li>
    <li>ZAF è¬›æ¼”è€…ã€ ZAM åŸ·ç­†è€…ã€çµ¶è³›ã€å¤§å‹Ÿé›†ä¸­ã§ã™ï¼<br />
      ãŠæ°—è»½ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ï¼</li>
  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <hr />
  <hr />

  <h2 id="detailed-toc">ç·åˆç›®æ¬¡</h2>
  <ul>
    <li><b>å‰åº§</b>
      <ul>
	<li><a href="#part0-twitch">æœ€è¿‘ã®ç§ï¼ˆã„ã¡ãï¼‰ã¯ã©ã“ã«å‘ã‹ã£ã¦ã„ã‚‹ã®ã‹ï¼Ÿ</a></li>
	<li><a href="#part0-dance">è¸Šã£ã¦ã¿ãŸ-ãã®å¾Œ</a></li>
      </ul>
    </li>

    <li><b>ç¬¬ï¼‘éƒ¨</b>
      <a href="#part1">æœ€è¿‘ã® AI ã¯æœ¬å½“ã™ã”ã„ã­Let's Dance!</a>
      <ul>
	<li><a href="#part1-community-oriented-life">ï¼ˆå‰åº§ï¼‰ä»¤å’Œæ™‚ä»£ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å¿—å‘ãªç”Ÿãæ–¹</a></li>
	<li><a href="#part1-portrait">é¡”ã® 3D å†æ§‹æˆ</a></li>
	<li><a href="#part1-NeRF">3D å†æ§‹æˆã€ NeRF é–¢ä¿‚</a></li>
	<li><a href="#part1-photogrammetry">ãƒ•ã‚©ãƒˆã‚°ãƒ©ãƒ¡ãƒˆãƒªã€LiDAR é–¢ä¿‚</a></li>
	<li><a href="#part1-text-to-image">Text to Image ãªã©</a></li>
	<li><a href="#part1-super-resolution">è¶…è§£åƒãªã©</a></li>
	<li><a href="#part1-demos">ãƒ‡ãƒ¢</a></li>
	<li><a href="#part1-pose">å§¿å‹¢æ¨å®š</a></li>
	<li><a href="#part1-misc">ãã®ä»–</a></li>
      </ul>
    </li>

    <li><b>ç¬¬ï¼’éƒ¨</b>
      <a href="#part2">æŠ€è¡“æ›¸å…¸ï¼‘ï¼“ä¼ç”»ä¼šè­°ï¼</a>
      <ul>
	<li><a href="#part2-invitation">æŠ€è¡“æ›¸å…¸ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆï¼‰ã¸ã®ãŠèª˜ã„</a></li>
	<li><a href="#part2-mission-statement">ZENKEI AI FORUM ã® Mission Statement</a></li>
	<li><a href="#part2-fandom-economy">åŒäººèªŒæ´»å‹•ã¯ä»Šã®ãƒ“ã‚¸ãƒã‚¹ã®æœ€å…ˆç«¯ï¼</a></li>
	<li><a href="#part2-line-up">ã“ã‚Œã¾ã§ã®ãƒ©ã‚¤ãƒ³ãƒŠãƒƒãƒ—</a></li>
        <li><a href="#part2-my-personal-project">ã„ã¡ãã®ã‚½ãƒ­ä¼ç”»</a></li>
	<li><a href="#part2-as-a-circle">ZAF ã®ã‚µãƒ¼ã‚¯ãƒ«ä¼ç”»</a></li>
	<li><a href="#part2-lets-discuss">ä¼ç”»ä¼šè­°ï¼</a></li>
      </ul>
    </li>

    <li><a href="#epilogue">ä»Šæ—¥ã®ãŠã‚ã‚Šã«</a></li>
  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

</section>

</body>           
</html>
