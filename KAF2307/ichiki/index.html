<!doctype html>
<html>
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta charset="UTF-8" />
    <title>HELLO! AI FORUM (2023/07/29)</title>
    <link href="https://fonts.googleapis.com/css?family=M+PLUS+1p:100,400,700&display=swap&subset=japanese" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="../../bright-M_PLUS_1p.css" />

    <link rel="stylesheet"
	  href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.2.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.2.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="text/javascript" id="MathJax-script" async
	    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  </head>

<body style="font-size: 20px;">

<header>
<center><h1>HELLO! AI FORUM 2023/07/29</h1></center>
</header>

<article>

<section id="main">

  <center>
    <a href="HELLO_AI_FORUM_zoom_20230729-2488x1400.jpg"><!-- 2341x1400 -->
      <img src="HELLO_AI_FORUM_zoom_20230729-2488x1400_thumb.jpg" width="800" height="478" style="border: 2px #ccc solid;" /></a>
  </center>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center>
    <div style="font-size: 60px; font-weight: bold;">
      ã“ã‚“ã«ã¡ã‚ï¼ AI FORUM<br />
      2023 å¹´ 7 æœˆ 29 æ—¥ ï¼ˆåœŸæ›œæ—¥ï¼‰
    </div>
    <br />
    <div style="font-size: 50px;">ï¼œæœ¬æ—¥ã®ãƒ†ãƒ¼ãƒï¼</div>
    <div style="font-size: 70px;">
      å¤ä¼‘ã¿ã‚‚ï¼¡ï¼©ã ï¼
    </div>
  </center>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <hr />

  <h2 id="toc">ç›®æ¬¡</h2>
  <ul>

      </ul>
    </li><!-- ãƒã‚¿ -->

    <li>[6:30 - 7:00]
      <b>å‰åº§</b>ã€€
      <a href="#part0">2023 å¹´å‰åŠã®æŒ¯ã‚Šè¿”ã‚Š</a>
    </li><!-- å‰åº§ -->

    <li>[7:00 - 8:00]
      <b>ãƒ‘ãƒ¼ãƒˆï¼‘</b>
      <a href="#part1">AI ã®æœªæ¥</a>
    </li><!-- ãƒ‘ãƒ¼ãƒˆï¼‘ -->

    <li>[8:00 - 9:00]
      <b>ãƒ‘ãƒ¼ãƒˆï¼’</b>
      <a href="#part2">æœ€è¿‘ã® LLMs</a>
    </li><!-- ãƒ‘ãƒ¼ãƒˆï¼’ -->

    <li><a href="#epilogue">ä»Šæ—¥ã®ãŠã‚ã‚Šã«</a></li>

    <li><a href="#detailed-toc">ç·åˆç›®æ¬¡</a></li>
  </ul>

  <hr />

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part0">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      å‰åº§
      <br />
      2023 å¹´å‰åŠã®æŒ¯ã‚Šè¿”ã‚Š
    </div>
    <br /><br />
    <div style="font-size: 40px;">
      ï¼ˆæœ¬é¡Œã«å…¥ã‚‹å‰ã®ã‚¦ã‚©ãƒ¼ãƒŸãƒ³ã‚°ã‚¢ãƒƒãƒ—ï¼‰
    </div>
    <br /><br />
  </center>

  <ul>
    <li>ä»Šæ—¥ã¯ï¼—æœˆï¼’ï¼™æ—¥</li>
    <li>ä»Šå¹´ã‚‚ã‚‚ã†åŠåˆ†ä»¥ä¸Šéãã¦ã—ã¾ã„ã¾ã—ãŸ
      <ul>
	<li>æœ¬å½“ãªã‚‰ã€å…ˆæœˆã€ã¡ã‚‡ã†ã©åŠåˆ†ã£ã¦ã“ã¨ã§ã‚„ã‚‹ã¹ããƒã‚¿ã§ã—ãŸã­</li>
      </ul>
    </li>

    <li>ãªãœä»Šï¼Ÿ
      <ul>
	<li>ã€Œã“ã‚“ã«ã¡ã‚ï¼ AI FORUM ã®ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã€
	  ã¨ã„ã†ã‚‚ã®ãŒã‚ã‚Šã¾ã™</li>
	<li>é€±ï¼’å›ã€æ°´æ›œæ—¥ã¨æ—¥æ›œæ—¥ã«ã€éå»ã®ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã®ã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰
	  ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’åˆ‡ã‚Šå‡ºã—ã¦é…ä¿¡ã—ã¦ã„ã¾ã™
	</li>
	<li>ãã‚ŒãŒã€ä»Šé€±ã®æ°´æ›œæ—¥ï¼ˆï¼—æœˆï¼’ï¼–æ—¥ï¼‰ã‚·ãƒ¼ã‚ºãƒ³ï¼“ï¼—ã«å…¥ã‚Šã¾ã—ãŸ</li>
	<li>ã“ã‚ŒãŒã€ã‚„ã£ã¨ä»Šå¹´ï¼‘æœˆã®ã‚¤ãƒ™ãƒ³ãƒˆã§ã€<br />
	  <a href="https://hello-ai.seesaa.net/article/499849673.html">
	    S37E01 ï¼ˆå‰åº§ï¼‰ï¼‘å¹´ã®è¨ˆã¯ï¼‘æœˆã® ZAF ã«ã‚ã‚Š - ãã®ï¼‘ã€å€‹äººã®ç›®æ¨™</a>
	  <center>
	    <a href="Screen Shot 2023-07-29 at 15.23.54.png"><!-- 2748x1117 -->
	      <img src="Screen Shot 2023-07-29 at 15.23.54_thumb.jpg" width="800" height="325" style="border: 2px #ccc solid;" /></a>
	  </center>
	  ã¨ã„ã†ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã ã£ãŸã®ã§ã€<br />
	  ä»Šå¹´ã®ç›®æ¨™ã€åŠåˆ†ä»¥ä¸Šã€é€²ã‚“ã§ã‚‹ã‹ãªï¼Ÿã¨ãŠã‚‚ã£ãŸã‹ã‚‰
	</li>
      </ul>
    </li>

    <li>ä»Šå¹´ã®ç›®æ¨™ã¯ã€
      ä»Šå¹´ï¼‘æœˆã®ãƒ•ã‚©ãƒ¼ãƒ©ãƒ  (<a href="https://hello-ai-forum.github.io/pages/ZAF202301/ichiki/#part0">ZAF-2301</a>) ã«ã¦
      <center>
	<a href="https://hello-ai-forum.github.io/pages/ZAF202301/ichiki/#part0">
	  <img src="Screen Shot 2023-07-29 at 15.27.21_thumb.jpg" width="600" height="250" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part0-1">
    <br />
    <div style="font-size: 50px; font-weight: bolder;">
      ãƒ”ã‚¢ãƒ
    </div>
      <br /><br />
    <div style="font-size: 40px; font-weight: bolder;">
      Twitch ã§é ‘å¼µã£ã¦ã‚‹ï¼
    </div>
    <br /><br />
  </center>

  <ul>
    <li><a href="https://hello-ai-forum.github.io/pages/KAF2306/ichiki/#part01-2">KAF-2306</a> ã§ã‚‚ã¾ã¨ã‚ã¾ã—ãŸ
      <center>
	<a href="https://hello-ai-forum.github.io/pages/KAF2306/ichiki/#part01-2">
	  <img src="Screen Shot 2023-07-29 at 15.32.06_thumb.jpg" width="800" height="359" style="border: 2px #ccc solid;" /></a>
	<br />
	<a href="https://hello-ai-forum.github.io/pages/KAF2306/ichiki/#part01-2">
	  <img src="Screen Shot 2023-07-29 at 15.31.01_thumb.jpg" width="800" height="205" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part0-2">
    <br />
    <div style="font-size: 50px; font-weight: bolder;">
      ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã€€ãã®ï¼‘
    </div>
    <br /><br />
    <div style="font-size: 40px; font-weight: bolder;">
      ã€Œã“ã‚“ã«ã¡ã‚ï¼ AI FORUM ã®ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã€
    </div>
    <br />
    <div style="font-size: 30px; font-weight:">
      <a href="https://hello-ai.seesaa.net/">https://hello-ai.seesaa.net/</a>
    </div>
    <br /><br />
  </center>

  <center>
    <a href="Screen Shot 2023-07-29 at 15.37.17.png"><!-- 682x491 -->
      <img src="Screen Shot 2023-07-29 at 15.37.17_thumb.jpg" width="240" height="173" style="border: 2px #ccc solid;" /></a>
    <a href="Screen Shot 2023-07-29 at 15.37.13.png"><!-- 678x495 -->
      <img src="Screen Shot 2023-07-29 at 15.37.13_thumb.jpg" width="240" height="175" style="border: 2px #ccc solid;" /></a>
    <a href="Screen Shot 2023-07-29 at 15.37.10.png"><!-- 682x496 -->
      <img src="Screen Shot 2023-07-29 at 15.37.10_thumb.jpg" width="240" height="175" style="border: 2px #ccc solid;" /></a>
    <br />
    <a href="Screen Shot 2023-07-29 at 15.37.07.png"><!-- 676x542 -->
      <img src="Screen Shot 2023-07-29 at 15.37.07_thumb.jpg" width="240" height="192" style="border: 2px #ccc solid;" /></a>
    <a href="Screen Shot 2023-07-29 at 15.37.04.png"><!-- 682x493 -->
      <img src="Screen Shot 2023-07-29 at 15.37.04_thumb.jpg" width="240" height="173" style="border: 2px #ccc solid;" /></a>
    <a href="Screen Shot 2023-07-29 at 15.37.00.png"><!-- 682x494 -->
      <img src="Screen Shot 2023-07-29 at 15.37.00_thumb.jpg" width="240" height="174" style="border: 2px #ccc solid;" /></a>
    <a href="Screen Shot 2023-07-29 at 15.36.55.png"><!-- 688x563 -->
      <img src="Screen Shot 2023-07-29 at 15.36.55_thumb.jpg" width="240" height="196" style="border: 2px #ccc solid;" /></a>
    <br />
    <a href="Screen Shot 2023-07-29 at 15.38.57.png"><!-- 1904x1414 -->
      <img src="Screen Shot 2023-07-29 at 15.38.57_thumb.jpg" width="600" height="446" style="border: 2px #ccc solid;" /></a>
    <br />
    <a href="Screen Shot 2023-07-29 at 15.38.50.png"><!-- 1902x1328 -->
      <img src="Screen Shot 2023-07-29 at 15.38.50_thumb.jpg" width="600" height="419" style="border: 2px #ccc solid;" /></a>
    <br />
    <a href="Screen Shot 2023-07-29 at 15.38.40.png"><!-- 1902x548 -->
      <img src="Screen Shot 2023-07-29 at 15.38.40_thumb.jpg" width="600" height="173" style="border: 2px #ccc solid;" /></a>
    <br />
    <a href="Screen Shot 2023-07-29 at 15.38.34.png"><!-- 1900x1414 -->
      <img src="Screen Shot 2023-07-29 at 15.38.34_thumb.jpg" width="600" height="447" style="border: 2px #ccc solid;" /></a>
    <br />
    <a href="Screen Shot 2023-07-29 at 15.38.18.png"><!-- 1905x1328 -->
      <img src="Screen Shot 2023-07-29 at 15.38.18_thumb.jpg" width="600" height="418" style="border: 2px #ccc solid;" /></a>
    <br />
    <a href="Screen Shot 2023-07-29 at 15.37.44.png"><!-- 1905x138 -->
      <img src="Screen Shot 2023-07-29 at 15.37.44_thumb.jpg" width="600" height="43" style="border: 2px #ccc solid;" /></a>
  </center>
  <center>
    <br />
    <div style="font-size: 40px; font-weight: bolder;">
      ï¼“æœˆã‹ã‚‰é€±ï¼’æœ¬ã®ãƒšãƒ¼ã‚¹ã§
      <br />
      ä»Šå¹´ã«å…¥ã£ã¦ï¼•ï¼’ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ãƒªãƒªãƒ¼ã‚¹
    </div>
    <br /><br />
  </center>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part0-3">
    <br />
    <div style="font-size: 50px; font-weight: bolder;">
      ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã€€ãã®ï¼’
    </div>
    <br /><br />
    <div style="font-size: 40px; font-weight: bolder;">
      ã€ŒéŸ³æ¥½ã¨æ•°ç† ğŸ¼ â™¾ ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã€
    </div>
    <br />
    <div style="font-size: 30px; font-weight:">
      <a href="https://music0math.wordpress.com/">https://music0math.wordpress.com/</a>
    </div>
    <br /><br />
  </center>

  <center>
    <a href="Screen Shot 2023-07-29 at 15.52.23.png"><!-- 2758x1123 -->
      <img src="Screen Shot 2023-07-29 at 15.52.23_thumb.jpg" width="800" height="326" style="border: 2px #ccc solid;" /></a>
    <br />
    <a href="Screen Shot 2023-07-29 at 15.52.33.png"><!-- 2733x813 -->
      <img src="Screen Shot 2023-07-29 at 15.52.33_thumb.jpg" width="400" height="119" style="border: 2px #ccc solid;" /></a>
    <a href="Screen Shot 2023-07-29 at 15.52.42.png"><!-- 2739x830 -->
      <img src="Screen Shot 2023-07-29 at 15.52.42_thumb.jpg" width="400" height="121" style="border: 2px #ccc solid;" /></a>
    <a href="Screen Shot 2023-07-29 at 15.52.48.png"><!-- 2737x945 -->
      <img src="Screen Shot 2023-07-29 at 15.52.48_thumb.jpg" width="400" height="138" style="border: 2px #ccc solid;" /></a>
    <a href="Screen Shot 2023-07-29 at 15.52.54.png"><!-- 2736x888 -->
      <img src="Screen Shot 2023-07-29 at 15.52.54_thumb.jpg" width="400" height="130" style="border: 2px #ccc solid;" /></a>
    <a href="Screen Shot 2023-07-29 at 15.52.58.png"><!-- 2733x967 -->
      <img src="Screen Shot 2023-07-29 at 15.52.58_thumb.jpg" width="400" height="142" style="border: 2px #ccc solid;" /></a>
  </center>
  <center>
    <br />
    <div style="font-size: 40px; font-weight: bolder;">
      ã“ã¡ã‚‰ã¯é€±ï¼‘æœ¬ã®ãƒšãƒ¼ã‚¹ã§
      <br />
      ä»Šå¹´ã«å…¥ã£ã¦ï¼“ï¼ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ãƒªãƒªãƒ¼ã‚¹ï¼
    </div>
    <br /><br />
  </center>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part0-4">
    <br />
    <div style="font-size: 40px; font-weight: bolder;">
      ã€Œè‹±èªã®ï¼ˆç´™ã®ï¼‰æœ¬ã‚’ã‚¢ãƒã‚¾ãƒ³ã§ä¸–ç•Œã«å‘ã‘ã¦å£²ã‚‹ã€
    </div>
    <br /><br />
  </center>

  <ul>
    <li>ã¨ã„ã†ç›®æ¨™ã‚’æ²ã’ã¦ã¾ã—ãŸ</li>
    <li>è¦ã™ã‚‹ã«ã€ã‚¢ãƒã‚¾ãƒ³ Kindle Direct Publishing ä½¿ã£ã¦ã¿ã‚ˆã†ã€ã¨ã„ã¯ãªã—
      <center>
	(<a href="https://qiita.com/kichiki/items/1d54e3ba66694ac26f49">https://qiita.com/kichiki/items/1d54e3ba66694ac26f49</a>)
	<br />
	<a href="https://qiita.com/kichiki/items/1d54e3ba66694ac26f49">
	  <img src="Screen Shot 2023-07-29 at 16.02.07_thumb.jpg" width="600" height="383" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>
    <li>ï¼•æœˆä¸‹æ—¬ã«é–‹å‚¬ã•ã‚ŒãŸã€ŒæŠ€è¡“æ›¸å…¸ï¼‘ï¼”ã€ã§å‡ºã—ãŸæœ¬ã‚‚ã€
      ç´™ã®æœ¬ï¼ˆPrint On Demandï¼‰ã§ã€ã‚¢ãƒã‚¾ãƒ³ã‹ã‚‰è²·ãˆã¾ã™
      <center>
	<a href="Screen Shot 2023-07-29 at 16.06.52.png"><!-- 1487x997 -->
	  <img src="Screen Shot 2023-07-29 at 16.06.52_thumb.jpg" width="600" height="402" style="border: 2px #ccc solid;" /></a>
      </center>
      <ul>
	<li>ã€<a href="https://www.amazon.co.jp/dp/B0C7JG3GYS">ã‚¨ãƒƒã‚»ã‚¤ã€€éŸ³æ¥½ã¨æ•°ç†ã€€ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã¯è‡ªç”±ã«ã™ã‚‹ï¼ˆæŠ„ï¼‰</a>ã€</li>
	<li>ã€<a href="https://www.amazon.co.jp/dp/B0C7JFHTDF">éŸ³æ¥½ã¨æ•°ç†ã€€æ‰èƒ½ã«ãŸã‚ˆã‚‰ãªã„è€³ã‚³ãƒ”</a>ã€</li>
	<li>ã€<a href="https://www.amazon.co.jp/dp/B0C7JCBC6P">å³å¯†ãªè¨ˆç®—ã€€ãµãŸã¤ã®çƒã®ãªã‚ã‚‰ã‹ãªãƒ€ãƒ³ã‚¹</a>ã€</li>
      </ul>
      <center>
	<br />
	<div style="font-size: 40px; font-weight: bolder;">
	  ã€Œè‹±èªã€ã®æœ¬ã¯â€¦â€¦
	  <br />
	  ä»Šå¹´ã®å¾ŒåŠã€ãŒã‚“ã°ã‚‹ã‹ãªâ€¦â€¦ï¼Ÿ
	</div>
	<br /><br />
      </center>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part0-5">
    <br />
    <div style="font-size: 50px; font-weight: bolder;">
      ã¾ã¨ã‚
    </div>
    <br />
    <div style="font-size: 40px; font-weight: bolder;">
      2023 å¹´å‰åŠã®æŒ¯ã‚Šè¿”ã‚Š
      <br />
      ä»Šå¹´ã®ç›®æ¨™ã¯ã“ã“ã¾ã§
      <br />
      é †èª¿ã«é€²ã‚“ã§ã„ã¾ã™ã­ï¼
    </div>
    <br /><br />
  </center>

  <br /><br />
  <div align="right">
    ï¼ˆ<a href="#toc">ãƒˆãƒƒãƒ—ã«æˆ»ã‚‹</a>ã€<a href="#detailed-toc">è©³ç´°ç›®æ¬¡ã¸</a>ï¼‰
  </div>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part1">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      ãƒ‘ãƒ¼ãƒˆï¼‘
      <br />
      AI ã®æœªæ¥
    </div>
  </center>

  <ul>
    <li><a href="#part1-1">Jeremy Howard ã®ã€ŒDelightenmentã€</a></li>
    <li><a href="#part1-2">æœ€è¿‘ã® AI æ¥­ç•Œã®å‹•ã</a></li>
    <li><a href="#part1-3">The Frontier Model Forum</a></li>
  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part1-1">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      Jeremy Howard ã®
      <br />
      ã€ŒDelightenmentã€è«–æ–‡
    </div>
  </center>

  <ul>
    <li>ã¼ãè‡ªä¿¡ãŒã€æœ€è¿‘ãšã£ã¨
      <center>
	<br />
	<div style="font-size: 40px; font-weight: bolder;">
	  ã€ŒAI ã®å°†æ¥ã€ã¨ã‹ã€Œäººé¡ã«æœªæ¥ã€ã¨ã‹ã€<br />
	  ã“ã®è¾ºãŒæ°—ã«ãªã£ã¦ã‚‹
	</div>
	<br /><br />
      </center>
      ã¨è¨€ã£ã¦ã‚‹æ‰‹å‰ã€<br />
      Jeremy ã®ã“ã®ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆã˜ã‚ƒãªãã¦ã€Œğ•ã€ã‹ãªï¼Ÿï¼‰<br />
      ã®è¨˜äº‹ã¯èª­ã‚“ã§ãŠã‹ãªã„ã¨ãƒ€ãƒ¡ã ã‚ã†ã€ã¨
      <br /><br />
      <table border="1" style="border: 1px solid black; border-collapse: collapse; table-layout: fixed;" width="100%">
	<tr>
	  <td>
	    <a href="https://twitter.com/jeremyphoward/status/1678558165712113664">https://twitter.com/jeremyphoward/status/1678558165712113664</a>
	    <div style="float: left; padding-right:1em;">
	      9:13 AM Â· Jul 11, 2023<br />
	      <a href="Screen Shot 2023-07-11 at 10.58.26.png"><!-- 1179x1052 -->
		<img src="Screen Shot 2023-07-11 at 10.58.26_thumb.jpg" width="400" height="357" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Iâ€™ve spent the last few months interviewing >60 experts
in law, economics, AI, alignment, etc, on the impacts of AI,
and safety interventions.

Today Iâ€™m publishing my first article, showing regulation designed
to increase AI safety may backfire badly!

<a href="https://www.fast.ai/posts/2023-11-07-dislightenment.html">https://www.fast.ai/posts/2023-11-07-dislightenment.html</a>
	    </pre>
	  </td>
	</tr>
      </table>
    </li>

    <br />

    <li>ã€Œ<a href="https://www.fast.ai/posts/2023-11-07-dislightenment.html">AI Safety and the Age of Dislightenment</a>ã€
      <center>
	<div style="font-size: 40px; font-weight: bolder;">
	  AI ã®å®‰å…¨æ€§ã¨ã€åå•“è’™æ™‚ä»£
	</div>
	<br />
	<a href="Screen Shot 2023-07-17 at 18.41.54.png"><!-- 2750x1246 -->
	  <img src="Screen Shot 2023-07-17 at 18.41.54_thumb.jpg" width="800" height="362" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>

    <li>ä¸€é€šã‚Šã€ç›®ã‚’é€šã™
      <ul>
	<li>regulation ã‚‚ã€
	  ä¸€æ—¦å®Ÿæ–½ã—ã¦ã—ã¾ã†ã¨ã€ç°¡å˜ã«ã¯ undo ã§ããªã„ã®ã§ã€
	  æ…é‡ã«ã™ã¹ãã ã€ã¨ã€‚
	</li>
	<li>"FAR" ã¯ã€ OpenAI ã¨ã‹ Google ãŒè¨€ã£ã¦ã‚‹ã‚„ã¤</li>
	<li>ã¡ãªã¿ã«ã€ The Enlightment (Age of Enlightment) ã¯ã€Œå•“è’™æ™‚ä»£ã€
	  <ul>
	    <li>å•“è’™æ™‚ä»£ã¯ã€ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘ã§å•“è’™æ€æƒ³ãŒä¸»æµã¨ãªã£ã¦ã„ãŸ
	      17ä¸–ç´€å¾ŒåŠã‹ã‚‰18ä¸–ç´€ã«ã‹ã‘ã¦ã®æ™‚ä»£ã®ã“ã¨ã€‚
	    </li>
	    <li>ã‚¿ã‚¤ãƒˆãƒ«ã®ã€ŒDislightenmentã€ã¯ã€ã—ãŸãŒã£ã¦ã€Œå•“è’™æ™‚ä»£ã€ã®åå¯¾
	      ã¨ã„ã†ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã§ã®é€ èªã‹ãªã€‚
	    </li>
	    <li>èª­ã¿å§‹ã‚ã‚‹ã¾ã§ã€ãšã£ã¨ã€Œdisalignmentã€ã ã¨æ€ã„è¾¼ã‚“ã§ãŸã€‚</li>
	  </ul>
	</li>
      </ul>
    </li>

    <li>å†…å®¹ã‚’ã¾ã¨ã‚ã‚‹ã¨ã€
      <ul>
	<li>ãã¡ã‚“ã¨å¿ƒé…ã—ã‚ˆã†ï¼ˆå¿ƒé…ã„ã‚‰ã‚“ã€ã¨ã„ã†æ¥½è¦³æ´¾ã§ã¯ãªã„ï¼‰</li>
	<li>è¦åˆ¶ã¯ã€ã‹ã‘ã‚‹ãªã‚‰ãƒ¢ãƒ‡ãƒ«ã§ã¯ãªãã€Œåˆ©ç”¨ã€ã«</li>
	<li>ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã«ã™ã¹ãï¼ˆã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹çš„ãªè€ƒãˆæ–¹ï¼‰</li>
	<li>ãã®æ„å‘³ã§ã®ã€Œå•“è’™æ™‚ä»£ã‚’æ€ã„å‡ºãã†ã€ã¨ã„ã†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸</li>
      </ul>
      ã¿ãŸã„ãªæ„Ÿã˜ã‹ãªã€‚<br />
      ã•ã£ã¨èª­ã‚“ã ã ã‘ãªã®ã§ã€ã‚ã¨ã§ã‚†ã£ãã‚Šè¦‹è¿”ãã†ã€‚
    </li>

    <li>ã‚¸ã‚§ãƒ¬ãƒŸãƒ¼ã¯ã„ã¤ã‚‚å‰å‘ãã§ã€å»ºè¨­çš„ã§ã€ç¾å®Ÿçš„ã ãªã¨æ€ã£ãŸã€‚</li>

    <li>ã‚¸ã‚§ãƒ¬ãƒŸãƒ¼ã¨ã¯åˆ¥ãªæ„å‘³ã§ã€å‰å‘ãã¨è¨€ã†ã‹ã€
      ç´ æœ´ãªäººã ã¨æ€ã£ã¦ã‚‹ãƒ¬ãƒƒã‚¯ã‚¹ãƒ•ãƒªãƒ¼ãƒ‰ãƒãƒ³ã¯ã€
      ç›´è¿‘ã€ã‚¤ã‚¹ãƒ©ã‚¨ãƒ«ã«è¡Œã£ã¦ãŸã¿ãŸã„ã§ã€ã¼ãã¯æ˜¨æ—¥ã€ãƒ¦ãƒãƒ«ãƒãƒ©ãƒªã®ãƒ“ãƒ‡ã‚ª
      (<a href="https://youtu.be/Mde2q7GFCrw">https://youtu.be/Mde2q7GFCrw</a>) ã‚’ã‚†ã£ãã‚Šè¦‹ãŸã€‚
    </li>
    <li>ã“ã®ã‚¸ã‚§ãƒ¬ãƒŸãƒ¼ã®è©±ã¯ã€é–“æ¥çš„ã«ã€ãã®å†…å®¹ã¨ã‚‚å‘¼å¿œã—ã¦ã„ã‚‹ã‚ˆã†ã«æ€ã£ãŸã€‚
      ã‚‚ã¡ã‚ã‚“ã€ãƒ¦ãƒãƒ«ãƒãƒ©ãƒªã‚‚ AI ã®ã“ã¨ã‚‚å¿µé ­ã«è©±ã—ã¦ãŸãŒã€
      ã€Œä»Šã€ã‚¤ã‚¹ãƒ©ã‚¨ãƒ«ã§è©±ã—ã¦ã„ã‚‹ã€ã“ã¨ã®æ–¹ãŒå¤šåˆ†ã€å¤§ããªæ„å‘³ãŒã‚ã£ã¦ã€
      å¿…ç„¶çš„ã«ã€ç¤¾ä¼šã¨ã‹æ”¿æ²»ã¨ã‹ãŒè»¸è¶³ã«ã‚ã£ãŸã€‚
      ãã®ä¸Šã§ã€Œä»Šã€å±æ©Ÿã«ç€•ã—ã¦ã„ã‚‹ã®ã¯ã€æ°‘ä¸»ä¸»ç¾©ã ã€ã¨ã„ã†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã ã£ãŸã¨æ€ã†ã€‚
    </li>

    <li>ã‚¸ã‚§ãƒ¬ãƒŸãƒ¼ã‚‚ã€å•“è’™ä¸»ç¾©ã¨ã‹ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã‹è¨€ã£ã¦ã‚‹ãŒã€
      è¦ã™ã‚‹ã«ã€Œæ°‘ä¸»ä¸»ç¾©ã€ã ãªã€ã¨ã€‚
    </li>

    <li>ä»Šã®æ—¥æœ¬ã‚’æŒ¯ã‚Šè¿”ã‚‹ã¨ã€å®Ÿã®ã¨ã“ã‚æ˜”ã‹ã‚‰ãšã£ã¨æ¨©å¨ä¸»ç¾©çš„ç¤¾ä¼šã ã£ãŸã—ã€
      æœ€è¿‘ã¯ã‚€ã—ã‚ãã‚ŒãŒæ›´ã«åŠ é€Ÿã—ã¦ã‚‹ã®ã ãªã€ã¨æ€ã£ãŸã€‚
      ã‚ã‚Œã‹ã­ã€æ—¥æœ¬äººã¯ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã«ã‚ˆã‚‹æ±šæŸ“ã«ä¸–ç•Œã§ä¸€ç•ªæ„Ÿåº¦é«˜ã„ã®ã‹ã‚‚ã­ã€‚
      ã€Œãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ã®åˆ©ç”¨ç‡ãƒ¡ãƒãƒ£é«˜ã€ã¨ã‹ã‚¤ãƒ¼ãƒ­ãƒ³ã«é©šã‹ã‚Œã¦ãŸã‚Šã—ã¦ãŸã—ã€‚
      ã“ã‚Œã¯ã€ã‚ˆã„ã“ã¨ã§ã¯ãªã„ã¨æ€ã†ã€‚
    </li>

    <li>æ¸…æ›¸ã—ãŸãƒ„ã‚¤ãƒ¼ãƒˆ
      (<a href="https://twitter.com/ichiki_k/status/1681917350441021443">https://twitter.com/ichiki_k/status/1681917350441021443</a>)
      <center>
	<a href="Screen Shot 2023-07-21 at 14.17.09.png"><!-- 1187x1217 -->
	  <img src="Screen Shot 2023-07-21 at 14.17.09_thumb.jpg" width="390" height="400" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2023-07-21 at 14.17.58.png"><!-- 1182x1000 -->
	  <img src="Screen Shot 2023-07-21 at 14.17.58_thumb.jpg" width="400" height="338" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part1-2">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      AI æ¥­ç•Œã®å‹•ã
    </div>
  </center>

  <ul>
    <li>æœ€è¿‘ã®ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ï¼ˆã„ã‚„ã€ã€Œğ•ã€ã¨è¨€ã†ã¹ãã‹ï¼Ÿï¼‰ã‹ã‚‰
      <table border="1" style="border: 1px solid black; border-collapse: collapse; table-layout: fixed;" width="100%">

	<tr>
	  <td>
	    <a href="https://twitter.com/DrJimFan/status/1676650766029963264">https://twitter.com/DrJimFan/status/1676650766029963264</a>
	    <div style="float: left; padding-right:1em;">
	      2:54 AM Â· Jul 6, 2023<br />
	      <a href="Screen Shot 2023-07-10 at 18.40.50.png"><!-- 1179x1339 -->
		<img src="Screen Shot 2023-07-10 at 18.40.50_thumb.jpg" width="352" height="400" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
OpenAIâ€™s alignment strategy says that â€œhumans wonâ€™t be able to
reliably supervise AI systems much smarter than usâ€.
But I think we can move humans up the supervision chain,
i.e. â€œfeedback to feedbackâ€.

Letâ€™s consider the concrete example of writing malware.
Itâ€™s very likely that GPT in the next few years can blend in
malicious code so well that even the top engineers canâ€™t detect. 

A well-aligned feedback model studies the code, discusses places
where potential virus may occur,
and explains its findings in intuitive terms.
Then human expert can decide whether the judgements are correct or not,
giving feedback to improve the feedback model,
which in turn steers the main model better.

<a href="https://openai.com/blog/introducing-superalignment">https://openai.com/blog/introducing-superalignment</a>
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/GoogleDeepMind/status/1678767468356210689">https://twitter.com/GoogleDeepMind/status/1678767468356210689</a>
	    <div style="float: left; padding-right:1em;">
	      11:05 PM Â· Jul 11, 2023<br />
	      <a href="Screen Shot 2023-07-12 at 9.51.58.png"><!-- 1186x1186 -->
		<img src="Screen Shot 2023-07-12 at 9.51.58_thumb.jpg" width="400" height="400" style="border: 2px #ccc solid;" /></a>
	      <br />
	      <a href="Screen Shot 2023-07-12 at 9.52.29.png"><!-- 2880x1800 -->
		<img src="Screen Shot 2023-07-12 at 9.52.29_thumb.jpg" width="400" height="250" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
What could the future of global AI governance look like? ğŸŒ

In our latest white paper, we explore theoretical options for
international institutions to help harness the benefits and
manage the risks of advanced artificial intelligence.

Find out more: <a href="https://dpmd.ai/46LXUdR">https://dpmd.ai/46LXUdR</a>

<a href="https://www.deepmind.com/blog/exploring-institutions-for-global-ai-governance">https://www.deepmind.com/blog/exploring-institutions-for-global-...</a>

<a href="https://arxiv.org/abs/2307.04699">https://arxiv.org/abs/2307.04699</a>

local copy: <a href="arxiv-2307.04699.pdf">arxiv-2307.04699.pdf</a>
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/bioshok3/status/1681480047105019907">https://twitter.com/bioshok3/status/1681480047105019907</a>
	    <div style="float: left; padding-right:1em;">
	      10:44 AM Â· Jul 19, 2023<br />
	      <a href="Screen Shot 2023-07-19 at 11.00.05.png"><!-- 1177x678 -->
		<img src="Screen Shot 2023-07-19 at 11.00.05_thumb.jpg" width="400" height="230" style="border: 2px #ccc solid;" /></a>
	      <br />
	      <a href="Screen Shot 2023-07-19 at 11.00.15.png"><!-- 1173x1078 -->
		<img src="Screen Shot 2023-07-19 at 11.00.15_thumb.jpg" width="400" height="368" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
ãƒ¡ã‚¿ã¨ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆãŒæ‰‹ã‚’çµ„ã‚€ã£ã¦ã‚„ã°ããªã„ã‹ï¼Ÿ
æ³•äººå‘ã‘æ¶ˆè²»è€…å‘ã‘VRå¸‚å ´ã‚’å…¨éƒ¨å–ã‚Šã€
Windowsã§PCOSã¯æ”¯é…ã—ã¦ã„ãã“ã¨ã‚’è€ƒãˆã‚‹ã¨
ãƒãƒ¼ãƒãƒ£ãƒ«ä¸Šã®AIãƒ¢ãƒ‡ãƒ«ã®ä¸»æµã¯ãƒ¡ã‚¿ã€ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã€OpenAIç”£ã«ãªã‚Šã€
GoogleDeepMindã¯æ˜”ã‹ã‚‰ã‚„ã£ã¦ã‚‹ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã§ç¾å®Ÿä¸–ç•Œã§è¦‡æ¨©ã‚’ã«ãã‚‹ã‹ï¼Ÿ

<a href="https://twitter.com/nikkei/status/1681428633083322368">https://twitter.com/nikkei/status/1681428633083322368</a>

ãƒ¡ã‚¿ãŒç”ŸæˆAIã§Microsoftã¨ææºã—ã¾ã™ã€‚
ã‚¯ãƒ©ã‚¦ãƒ‰å¤§æ‰‹ã¨ç”ŸæˆAIã®åŸºç›¤æŠ€è¡“ã‚’æ‰‹æ›ã‘ã‚‹ä¼æ¥­ã®ææºãŒç›¸æ¬¡ããƒ¯ã‚±ã¯ã€‚
å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ãŒé–‹ç™ºã‚„åˆ©ç”¨ã«å¿…é ˆã«ãªã£ã¦ã„ã‚‹ã“ã¨ãŒèƒŒæ™¯ã«ã‚ã‚Šã¾ã™ã€‚

<a href="https://nikkei.com/article/DGXZQOGN186BL0Y3A710C2000000/?n_cid=SNSTW007">https://nikkei.com/article/DGXZQOGN186BL0Y3A710C2000000/?n_cid=SNSTW007</a>
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/alex_valaitis/status/1681348531834044426">https://twitter.com/alex_valaitis/status/1681348531834044426</a>
	    <div style="float: left; padding-right:1em;">
	      2:01 AM Â· Jul 19, 2023<br />
	      <a href="Screen Shot 2023-07-19 at 12.53.10.png"><!-- 1182x1200 -->
		<img src="Screen Shot 2023-07-19 at 12.53.10_thumb.jpg" width="394" height="400" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
ğŸš¨BREAKING: Zuck just announced that Meta will be
open sourcing Llama 2 with Microsoft.

This is a massive announcement for a few reasons...

1) This could kill a number of the open source LLM startups.

Mosaic, Red Pajama, etc. are in major trouble.

The $1.2 billion @MosaicML acquisition
looks especially terrible in the wake of this news.

2) This thrusts Meta onto the AI scene. 

With this announcement,
Zuck is signaling how strong Metaâ€™s AI position is. 

They will now own one of the most widely adopted LLMs
+ have one of the best training data sets in the world.

3) This further strengthens @Microsoft â€™s dominant position in the AI space.

With this partnership they now have exclusive partnerships
with the top LLMs (OpenAI, Meta), priority access to @nvidia GPUs,
and strategic assets like GitHub and Azure.

The Game of AI Thrones has just taken another twist. 

Interested to see what happens next!
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/shujisado/status/1682366591462440961">https://twitter.com/shujisado/status/1682366591462440961</a>
	    <div style="float: left; padding-right:1em;">
	      9:27 PM Â· Jul 21, 2023<br />
	      <a href="Screen Shot 2023-07-24 at 11.15.19.png"><!-- 1177x1071 -->
		<img src="Screen Shot 2023-07-24 at 11.15.19_thumb.jpg" width="400" height="364" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
ãµãƒ¼ã‚€ã€‚ã©ã†ã‚‚ç·Šæ€¥ã§
Amazonã€Anthropicã€Googleã€Inflectionã€Metaã€Microsoftã€OpenAI
ã®AIä¼æ¥­7ç¤¾ãŒãƒ›ãƒ¯ã‚¤ãƒˆãƒã‚¦ã‚¹ã«æ‹›é›†ã•ã‚Œã€
AIæŠ€è¡“ã®å®‰å…¨æ€§ã€é€æ˜æ€§ã®ç¢ºä¿ã«ã‚€ã‘ã¦è‡ªä¸»çš„ãªå–ã‚Šçµ„ã¿ã‚’è¡Œã†ã“ã¨ã‚’ç´„æŸã•ã›ã‚‰ã‚ŒãŸã‚ˆã†ã ã€‚
ãƒªãƒªãƒ¼ã‚¹ã§å…¬è¡¨ã•ã‚ŒãŸé …ç›®ã¯å…«ã¤ã€‚

<a href="https://www.whitehouse.gov/briefing-room/statements-releases/2023/07/21/fact-sheet-biden-harris-administration-secures-voluntary-commitments-from-leading-artificial-intelligence-companies-to-manage-the-risks-posed-by-ai/">https://www.whitehouse.gov/briefing-room/statements-releases/...</a>
	    </pre>
	  </td>
	</tr>
      </table>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part1-3">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      The Frontier Model Forum
    </div>
  </center>

  <ul>
    <li>æœ€è¿‘ã®ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ï¼ˆã„ã‚„ã€ã€Œğ•ã€ã¨è¨€ã†ã¹ãã‹ï¼Ÿï¼‰ã‹ã‚‰
      <table border="1" style="border: 1px solid black; border-collapse: collapse; table-layout: fixed;" width="100%">
	<tr>
	  <td>
	    <a href="https://twitter.com/GoogleDeepMind/status/1684143225978724354">https://twitter.com/GoogleDeepMind/status/1684143225978724354</a>
	    <div style="float: left; padding-right:1em;">
	      7:06 PM Â· Jul 26, 2023<br />
	      <a href="Screen Shot 2023-07-26 at 19.22.09.png"><!-- 1172x1050 -->
		<img src="Screen Shot 2023-07-26 at 19.22.09_thumb.jpg" width="400" height="358" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Weâ€™re excited to support the launch of the Frontier Model Forum
- a new effort to ensure safe and responsible development
of frontier AI systems featuring @Google , @AnthropicAI , @Microsoft
and @OpenAI .

Find out more:

<a href="https://blog.google/outreach-initiatives/public-policy/google-microsoft-openai-anthropic-frontier-model-forum/">https://blog.google/outreach-initiatives/public-policy/google-...</a>
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/OpenAI/status/1684145154628653056">https://twitter.com/OpenAI/status/1684145154628653056</a>
	    <div style="float: left; padding-right:1em;">
	      7:14 PM Â· Jul 26, 2023<br />
	      <a href="Screen Shot 2023-07-26 at 19.28.27.png"><!-- 1184x981 -->
		<img src="Screen Shot 2023-07-26 at 19.28.27_thumb.jpg" width="400" height="331" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Announcing Frontier Model Forum, an industry body co-founded
with @anthropicAI , @Google , @googledeepmind , and @microsoft
focused on ensuring safe development of future hyperscale AI models:

<a href="https://openai.com/blog/frontier-model-forum">https://openai.com/blog/frontier-model-forum</a>
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/demishassabis/status/1684142735727394817">https://twitter.com/demishassabis/status/1684142735727394817</a>
	    <div style="float: left; padding-right:1em;">
	      7:04 PM Â· Jul 26, 2023<br />
	      <a href="Screen Shot 2023-07-26 at 19.32.34.png"><!-- 1181x1030 -->
		<img src="Screen Shot 2023-07-26 at 19.32.34_thumb.jpg" width="400" height="349" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Thrilled to bring @GoogleDeepMind â€™s expertise on responsible AI
to the new Frontier Model Forum and look forward to collaborating
with policymakers, academics, civil society & companies
to advance AI safety.
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/bioshok3/status/1684150211604803584">https://twitter.com/bioshok3/status/1684150211604803584</a>
	    <div style="float: left; padding-right:1em;">
	      7:34 PM Â· Jul 26, 2023<br />
	      <a href="Screen Shot 2023-07-27 at 17.40.43.png"><!-- 1180x530 -->
		<img src="Screen Shot 2023-07-27 at 17.40.43_thumb.jpg" width="400" height="180" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
ãªã‚‹ã»ã©ã€å›½éš›çš„ãªé«˜åº¦ãªAIè¦åˆ¶æ©Ÿé–¢ãŒä½œæˆã•ã‚Œã‚‹å‰ã«æ¥­ç•Œå›£ä½“
ï¼ˆGoogleã€GoogleDeepMindã€Anthropicã€Open AIã€Microsoftï¼‰
ã¨ã—ã¦å–ã‚Šçµ„ã¿ã‚„ã™ã„å½¢ã§è¨­ç«‹ã—ãŸæ¨¡æ§˜ã ã€‚METAã‚‚å…¥ã£ã¦ã»ã—ã„ãªã€‚
	    </pre>
	  </td>
	</tr>

      </table>
    </li>

    <br />

    <li>ã€ŒThe Frontier Model Forumã€ã¨ã„ã†ã®ã¯ã€
      <ul>
	<li>Google + DeepMind, Microsoft + OpenAI, AnthropicAI</li>
      </ul>
    </li>

    <li>å…ˆã® White House ã«å‘¼ã°ã‚ŒãŸè©±ã£ã¦ã®ã¯ã€ã¾ãŸåˆ¥ã®ã¯ãªã—
      <ul>
	<li>ã“ã£ã¡ã¯ã€ŒAmazonã€Anthropicã€Googleã€Inflectionã€Metaã€Microsoftã€OpenAI ã®AIä¼æ¥­7ç¤¾ã€ã¨</li>
      </ul>
    </li>

  </ul>

  <br /><br />
  <div align="right">
    ï¼ˆ<a href="#toc">ãƒˆãƒƒãƒ—ã«æˆ»ã‚‹</a>ã€<a href="#detailed-toc">è©³ç´°ç›®æ¬¡ã¸</a>ï¼‰
  </div>

  <hr />

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2">
    <div style="font-size: 50px; font-weight: bolder;">
      ãƒ‘ãƒ¼ãƒˆï¼’
      <br />
      æœ€è¿‘ã® LLMs
    </div>
    <br /><br />
  </center>

  <ul>
    <li><a href="#part2-0">ãƒã‚¹ãƒˆ Transformer æ™‚ä»£ã® LLMs</a></li>
    <li><a href="#part2-1">Llama 2 ç™ºè¡¨</a></li>
    <li><a href="#part2-2">LlaMA.cpp ã§ Llama 2</a></li>
    <li><a href="#part2-3">Andrej Karpathy ã® llama2.c</a></li>
  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-0">
    <div style="font-size: 50px; font-weight: bolder;">
      ãƒã‚¹ãƒˆ Transformer æ™‚ä»£ã® LLMs
    </div>
    <br /><br />
  </center>

  <center id="part2-0-1">
    <br />
    <div style="font-size: 40px; font-weight: bolder;">
      RWKV (Receptance Weighted Key Value)
    </div>
    <br /><br />
  </center>

  <ul>
    <li>æœ€è¿‘ã®ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ï¼ˆã„ã‚„ã€ã€Œğ•ã€ã¨è¨€ã†ã¹ãã‹ï¼Ÿï¼‰ã‹ã‚‰
      <table border="1" style="border: 1px solid black; border-collapse: collapse; table-layout: fixed;" width="100%">

	<tr>
	  <td>
	    <a href="https://twitter.com/_akhaliq/status/1660816265454419969">https://twitter.com/_akhaliq/status/1660816265454419969</a>
	    <div style="float: left; padding-right:1em;">
	      10:13 AM Â· May 23, 2023<br />
	      <a href="Screen Shot 2023-05-23 at 10.45.47.png"><!-- 1184x1208 -->
		<img src="Screen Shot 2023-05-23 at 10.45.47_thumb.jpg" width="392" height="400" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
RWKV: Reinventing RNNs for the Transformer Era

propose a novel model architecture,
Receptance Weighted Key Value (RWKV),
that combines the efficient parallelizable training of Transformers
with the efficient inference of RNNs.
Our approach leverages a linear attention mechanism and allows us
to formulate the model as either a Transformer or an RNN,
which parallelizes computations during training
and maintains constant computational
and memory complexity during inference,
leading to the first non-transformer architecture to be scaled
to tens of billions of parameters. Our experiments reveal
that RWKV performs on par with similarly sized Transformers,
suggesting that future work can leverage this architecture
to create more efficient models.
This work presents a significant step
towards reconciling the trade-offs between computational efficiency
and model performance in sequence processing tasks.

paper page: <a href="https://huggingface.co/papers/2305.13048">https://huggingface.co/papers/2305.13048</a>

<a href="https://arxiv.org/abs/2305.13048">https://arxiv.org/abs/2305.13048</a>

local copy: <a href="arxiv-2305.13048.pdf">arxiv-2305.13048.pdf</a>
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/__genzitsu__/status/1669158661313400832">https://twitter.com/__genzitsu__/status/1669158661313400832</a>
	    <div style="float: left; padding-right:1em;">
	      10:43 AM Â· Jun 15, 2023<br />
	      <a href="Screen Shot 2023-06-15 at 15.56.30.png"><!-- 1185x1036 -->
		<img src="Screen Shot 2023-06-15 at 15.56.30_thumb.jpg" width="400" height="350" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
æ€ã£ãŸã‚ˆã‚Šã‚‚ã™ã”ã„ãªRWKV

RWKVï¼ˆReceptance Weighted Key Valueï¼‰ã‚’ã¤ã‹ã£ã¦ã¿ãŸ

<a href="https://blog.brainpad.co.jp/entry/2023/06/14/144554">https://blog.brainpad.co.jp/entry/2023/06/14/144554</a>
	    </pre>
	  </td>
	</tr>

      </table>
    </li>
  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-0-2">
    <br />
    <div style="font-size: 40px; font-weight: bolder;">
      FlashAttention-2
    </div>
    <br /><br />
  </center>

  <ul>
    <li>æœ€è¿‘ã®ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ï¼ˆã„ã‚„ã€ã€Œğ•ã€ã¨è¨€ã†ã¹ãã‹ï¼Ÿï¼‰ã‹ã‚‰
      <table border="1" style="border: 1px solid black; border-collapse: collapse; table-layout: fixed;" width="100%">

	<tr>
	  <td>
	    <a href="https://twitter.com/ImAI_Eruel/status/1681144116229578752">https://twitter.com/ImAI_Eruel/status/1681144116229578752</a>
	    <div style="float: left; padding-right:1em;">
	      12:29 PM Â· Jul 18, 2023<br />
	      <a href="Screen Shot 2023-07-18 at 13.44.13.png"><!-- 1177x1123 -->
		<img src="Screen Shot 2023-07-18 at 13.44.13_thumb.jpg" width="400" height="382" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
ï¼’å€ä»¥ä¸Šã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã§å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼
ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è‡ªä½“ã«ç€ç›®ã—ãŸé«˜é€ŸåŒ–æ‰‹æ³•FlashAttentionã®æ–°ä½œãŒå‡ºã¾ã—ãŸï¼
"FlashAttention-2:
 Faster Attention with Better Parallelism and Work Partitioning"
<a href="https://tridao.me/publications/flash2/flash2.pdf">https://tridao.me/publications/flash2/flash2.pdf</a>
ãƒ‰ãƒ©ã‚´ãƒ³ãƒœãƒ¼ãƒ«ä¸¦ã¿ã®ã‚¤ãƒ³ãƒ•ãƒ¬
	    </pre>
	  </td>
	</tr>
      </table>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-0-3">
    <br />
    <div style="font-size: 40px; font-weight: bolder;">
      Retentive Network (RetNet)
    </div>
    <br /><br />
  </center>

  <ul>
    <li>æœ€è¿‘ã®ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ï¼ˆã„ã‚„ã€ã€Œğ•ã€ã¨è¨€ã†ã¹ãã‹ï¼Ÿï¼‰ã‹ã‚‰
      <table border="1" style="border: 1px solid black; border-collapse: collapse; table-layout: fixed;" width="100%">

	<tr>
	  <td>
	    <a href="https://twitter.com/RosaRugosaBeach/status/1681138056106233858">https://twitter.com/RosaRugosaBeach/status/1681138056106233858</a>
	    <div style="float: left; padding-right:1em;">
	      12:05 PM Â· Jul 18, 2023<br />
	      <a href="Screen Shot 2023-07-18 at 13.44.46.png"><!-- 1183x550 -->
		<img src="Screen Shot 2023-07-18 at 13.44.46_thumb.jpg" width="400" height="186" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Transformerã®å¾Œç¶™ã¨ãªã‚‹ã¹ãæ–°ãŸã«ææ¡ˆã•ã‚ŒãŸRetentive Networkã€é¢ç™½ã„

ä¸¦åˆ—å‡¦ç†ã¨å†å¸°æ§‹é€ ã‚’ã†ã¾ãçµ„ã¿åˆã‚ã›ãŸä»•çµ„ã¿ã§ã€
ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ã‚„æ¨è«–åŠ¹ç‡ãŒæ”¹å–„ã—ã¦ã„ã‚‹ã»ã‹ã€
2Bä»¥ä¸Šã®è¦æ¨¡ã«ãªã‚‹ã¨ç²¾åº¦ã‚‚ä¸Šå›ã‚Šå§‹ã‚ã‚‹
ï¼ˆæ˜¨ä»Šã®LLMã¨ã—ã¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒã©ã†ãªã‚‹ã‹ã¯æ°—ã«ãªã‚‹ãŒï¼‰

<a href="https://arxiv.org/abs/2307.08621">https://arxiv.org/abs/2307.08621</a>

local copy: <a href="arxiv-2307.08621.pdf">arxiv-2307.08621.pdf</a>
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/arankomatsuzaki/status/1681113977500184576">https://twitter.com/arankomatsuzaki/status/1681113977500184576</a>
	    <div style="float: left; padding-right:1em;">
	      10:29 AM Â· Jul 18, 2023<br />
	      <a href="Screen Shot 2023-07-18 at 13.48.19.png"><!-- 1172x1165 -->
		<img src="Screen Shot 2023-07-18 at 13.48.19_thumb.jpg" width="400" height="398" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Retentive Network: A Successor to Transformer
for Large Language Models

Proposes RetNet as a foundation architecture for LLMs,
simultaneously achieving training parallelism, low-cost inference,
and good performance.

<a href="https://arxiv.org/abs/2307.08621">https://arxiv.org/abs/2307.08621</a>
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/_kaiinui/status/1681169026658217985">https://twitter.com/_kaiinui/status/1681169026658217985</a>
	    <div style="float: left; padding-right:1em;">
	      2:08 PM Â· Jul 18, 2023<br />
	      <a href="Screen Shot 2023-07-18 at 17.33.23.png"><!-- 1185x1050 -->
		<img src="Screen Shot 2023-07-18 at 17.33.23_thumb.jpg" width="400" height="354" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
è©±é¡Œã®(?) RetNet, O(1) ã¨ã„ã†ã“ã¨ã§ã‚°ãƒ©ãƒ•ã‚’è¦‹ã¦ã¿ãŸã‚‰ã™ã”ã„

1. Context é•·ã«å¯¾ã—ã¦ãƒ¡ãƒ¢ãƒªãŒã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„
2. Context é•·ã«å¯¾ã—ã¦å‡¦ç†æ™‚é–“ãŒã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„
3. å…¥åŠ›é•·ã«å¯¾ã—ã¦å‡¦ç†æ™‚é–“ãŒã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/nkmry_/status/1681235176574324736">https://twitter.com/nkmry_/status/1681235176574324736</a>
	    <div style="float: left; padding-right:1em;">
	      6:31 PM Â· Jul 18, 2023<br />
	      <a href="Screen Shot 2023-07-18 at 18.44.50.png"><!-- 1178x742 -->
		<img src="Screen Shot 2023-07-18 at 18.44.50_thumb.jpg" width="400" height="252" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
<a href="https://arxiv.org/abs/2307.08621">https://arxiv.org/abs/2307.08621</a>
RetNet (Retentive Network) ã¯ RWKV ã¨åŒç­‰ã«é«˜é€Ÿã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ãã€
Transformer ä¸¦ã®æ€§èƒ½ãŒå‡ºã›ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã€Microsoft ã¨æ¸…è¯å¤§å­¦ãŒé–‹ç™ºã€‚

RWKV ã‚„ H3 ãªã©é«˜é€Ÿãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯å‡ºã¦ãã¦ã„ãŸãŒã€
æ›´ã«æ€§èƒ½ã¾ã§ Transformer ã«è¿½ã„ã¤ã„ãŸã®ã¯ã™ã”ã„ï¼
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/hillbig/status/1681417687380152320">https://twitter.com/hillbig/status/1681417687380152320</a>
	    <div style="float: left; padding-right:1em;">
	      6:36 AM Â· Jul 19, 2023<br />
	      <a href="Screen Shot 2023-07-19 at 8.15.25.png"><!-- 1184x512 -->
		<img src="Screen Shot 2023-07-19 at 8.15.25_thumb.jpg" width="400" height="173" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Retentive Network (RetNet)ã¯ã€
ä¸¦åˆ—å­¦ç¿’ã€Contexté•·ã«ä¾å­˜ã—ãªã„åŠ¹ç‡çš„ãªæ¨è«–ã€é«˜ã„è¡¨ç¾åŠ›ã‚’åŒæ™‚ã«é”æˆã™ã‚‹ã€‚
ç·šå½¢RNNã®é·ç§»è¡Œåˆ—ã‚’å¯¾è§’åŒ–ã—ã¦ä¸¦åˆ—ã«è¨ˆç®—ã§ãã‚‹ã‚ˆã†ã«ã—ãŸRetentionã‚’ã€
ãƒãƒ£ãƒ³ã‚¯æ¯ã«ã‚‚é©ç”¨ã—é•·è·é›¢ä¾å­˜ã‚’æ‰ãˆã‚‹ã€‚
Transformerã«é€Ÿåº¦ã€æ€§èƒ½é¢ã§ä¸¦ã¶ã‹ä¸Šå›ã‚‹

<a href="https://arxiv.org/abs/2307.08621">https://arxiv.org/abs/2307.08621</a>
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/heat_1nt/status/1684447745808171008">https://twitter.com/heat_1nt/status/1684447745808171008</a>
	    <div style="float: left; padding-right:1em;">
	      3:16 PM Â· Jul 27, 2023<br />
	      <a href="Screen Shot 2023-07-28 at 11.20.56.png"><!-- 1175x325 -->
		<img src="Screen Shot 2023-07-28 at 11.20.56_thumb.jpg" width="400" height="111" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
transformerã®å¾Œç¶™ã¨ç§°ã•ã‚Œã‚‹
RetNetã‚‚ã†å®Ÿè£…å‡ºã¦ãŸ ãƒ¯ã‚¯ãƒ¯ã‚¯

<a href="https://github.com/microsoft/unilm/tree/master/retnet">https://github.com/microsoft/unilm/tree/master/retnet</a>
	    </pre>
	  </td>
	</tr>

      </table>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-0-4">
    <br />
    <div style="font-size: 40px; font-weight: bolder;">
      ã€ŒTextbooks Are All You Needã€è«–æ–‡
      <br />
      phi-1
    </div>
    <br /><br />
  </center>

  <ul>
    <li>æœ€è¿‘ã®ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ï¼ˆã„ã‚„ã€ã€Œğ•ã€ã¨è¨€ã†ã¹ãã‹ï¼Ÿï¼‰ã‹ã‚‰
      <table border="1" style="border: 1px solid black; border-collapse: collapse; table-layout: fixed;" width="100%">

	<tr>
	  <td>
	    <a href="https://twitter.com/EldanRonen/status/1658321669407248387">https://twitter.com/EldanRonen/status/1658321669407248387</a>
	    <div style="float: left; padding-right:1em;">
	      1:01 PM Â· May 16, 2023<br />
	      <a href="Screen Shot 2023-07-28 at 22.11.51.png"><!-- 1178x1310 -->
		<img src="Screen Shot 2023-07-28 at 22.11.51_thumb.jpg" width="360" height="400" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Will future LLMs be based almost entirely on synthetic training data?
In a new paper, we introduce TinyStories,
a dataset of short stories generated by GPT-3.5&4.
We use it to train tiny LMs (&lt; 10M params)
that produce fluent stories and exhibit reasoning.
<a href="https://arxiv.org/abs/2305.07759">https://arxiv.org/abs/2305.07759</a>

local copy: <a href="arxiv-2305.07759.pdf">arxiv-2305.07759.pdf</a>
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/SebastienBubeck/status/1671326369626853376">https://twitter.com/SebastienBubeck/status/1671326369626853376</a>
	    <div style="float: left; padding-right:1em;">
	      10:17 AM Â· Jun 21, 2023<br />
	      <a href="Screen Shot 2023-07-28 at 22.12.09.png"><!-- 1188x943 -->
		<img src="Screen Shot 2023-07-28 at 22.12.09_thumb.jpg" width="400" height="318" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
New LLM in town:

***phi-1 achieves 51% on HumanEval
w. only 1.3B parameters & 7B tokens training dataset***

Any other &gt;50% HumanEval model is &gt;1000x bigger
(e.g., WizardCoder from last week is 10x in model size
and 100x in dataset size).

How?

***Textbooks Are All You Need***
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/SebastienBubeck/status/1671326371921154049">https://twitter.com/SebastienBubeck/status/1671326371921154049</a>
	    <div style="float: left; padding-right:1em;">
	      10:17 AM Â· Jun 21, 2023<br />
	      <a href="Screen Shot 2023-07-28 at 21.24.15.png"><!-- 1181x641 -->
		<img src="Screen Shot 2023-07-28 at 21.24.15_thumb.jpg" width="400" height="217" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Full details in the paper: <a href="https://arxiv.org/abs/2306.11644">https://arxiv.org/abs/2306.11644</a>

Awesome collaboration with our (also awesome) @MSFTResearch team!

Cc a few authors with an active twitter account: 
@EldanRonen (we follow-up on his TinyStories w. Yuanzhi Li!) 
@JyotiAneja @sytelus @AdilSlm @YiZhangZZZ @xinw_ai
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/_akhaliq/status/1671360619986010112">https://twitter.com/_akhaliq/status/1671360619986010112</a>
	    <div style="float: left; padding-right:1em;">
	      12:33 PM Â· Jun 21, 2023<br />
	      <a href="Screen Shot 2023-06-21 at 13.19.29.png"><!-- 1182x1029 -->
		<img src="Screen Shot 2023-06-21 at 13.19.29_thumb.jpg" width="400" height="348" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Textbooks Are All You Need

paper page: <a href="https://huggingface.co/papers/2306.11644">https://huggingface.co/papers/2306.11644</a>

introduce phi-1, a new large language model for code,
with significantly smaller size than competing models:
phi-1 is a Transformer-based model with 1.3B parameters,
trained for 4 days on 8 A100s, using a selection of
``textbook quality'' data from the web (6B tokens)
and synthetically generated textbooks and exercises
with GPT-3.5 (1B tokens). Despite this small scale,
phi-1 attains pass@1 accuracy 50.6% on HumanEval and 55.5% on MBPP.
It also displays surprising emergent properties
compared to phi-1-base, our model before our finetuning stage
on a dataset of coding exercises,
and phi-1-small, a smaller model with 350M parameters
trained with the same pipeline as phi-1 that still achieves 45% on HumanEval.
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/karpathy/status/1671587087542530049">https://twitter.com/karpathy/status/1671587087542530049</a>
	    <div style="float: left; padding-right:1em;">
	      3:33 AM Â· Jun 22, 2023<br />
	      <a href="Screen Shot 2023-07-28 at 21.20.29.png"><!-- 1181x558 -->
		<img src="Screen Shot 2023-07-28 at 21.20.29_thumb.jpg" width="400" height="189" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
"Textbooks Are All You Need" is making rounds:
<a href="https://twitter.com/SebastienBubeck/status/1671326369626853376">https://twitter.com/SebastienBubeck/status/1671326369626853376</a>
reminding me of my earlier tweet :).
TinyStories is also an inspiring read:
<a href="https://twitter.com/EldanRonen/status/1658321669407248387">https://twitter.com/EldanRonen/status/1658321669407248387</a>
Weâ€™ll probably see a lot more creative "scaling down" work:
prioritizing data quality and diversity over quantity,
a lot more synthetic data generation,
and small but highly capable expert models.

<a href="https://twitter.com/karpathy/status/1509289133637832705">https://twitter.com/karpathy/status/1509289133637832705</a>

Seems likely weâ€™ll have custom (and partially auto-generated) â€œtextbooksâ€
but for teaching language models, not humans, to help them â€œgrokâ€ concepts.
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/hillbig/status/1671643297616654342">https://twitter.com/hillbig/status/1671643297616654342</a>
	    <div style="float: left; padding-right:1em;">
	      7:16 AM Â· Jun 22, 2023<br />
	      <a href="Screen Shot 2023-06-22 at 16.51.26.png"><!-- 1180x574 -->
		<img src="Screen Shot 2023-06-22 at 16.51.26_thumb.jpg" width="400" height="195" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
LLMã®å­¦ç¿’ã§ã¯ãƒ‡ãƒ¼ã‚¿ã®è³ªãŒé‡è¦ã§ã‚ã‚Šã€
æ˜ç¢ºã€è‡ªå·±å®Œçµã€æœ‰ç›Šã§ãƒãƒ©ãƒ³ã‚¹ã•ã‚Œã¦ã„ã‚‹ã€Œæ•™ç§‘æ›¸ã€ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã¨
å¾®èª¿æ•´ç”¨ã€Œç·´ç¿’å•é¡Œã€ã‚’æ—¢å­˜LLMã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ç”Ÿæˆã§ç”¨æ„ã€‚
çµæœã®phi-1ã¯1/10ã®ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã€1/100ã®ãƒ‡ãƒ¼ã‚¿é‡ã§
ã‚³ãƒ¼ãƒ‰å‘ã‘æ—¢å­˜OSS LLMã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’é”æˆ

<a href="https://arxiv.org/abs/2306.11644">https://arxiv.org/abs/2306.11644</a>
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/Beluuuuuuga/status/1684529301293776897">https://twitter.com/Beluuuuuuga/status/1684529301293776897</a>
	    <div style="float: left; padding-right:1em;">
	      8:40 PM Â· Jul 27, 2023<br />
	      <a href="Screen Shot 2023-07-27 at 21.41.51.png"><!-- 1185x396 -->
		<img src="Screen Shot 2023-07-27 at 21.41.51_thumb.jpg" width="400" height="134" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Microsoftã‹ã‚‰ã‚„ã°ãã†ãªè«–æ–‡ãŒã§ã¦ãŸ

<a href="https://arxiv.org/abs/2306.11644">https://arxiv.org/abs/2306.11644</a>

local copy: <a href="arxiv-2306.11644.pdf">arxiv-2306.11644.pdf</a>
	    </pre>
	  </td>
	</tr>

      </table>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-1">
    <div style="font-size: 50px; font-weight: bolder;">
      Llama 2 ç™ºè¡¨
    </div>
    <br /><br />
  </center>

  <ul>
    <li>æœ€è¿‘ã®ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ï¼ˆã„ã‚„ã€ã€Œğ•ã€ã¨è¨€ã†ã¹ãã‹ï¼Ÿï¼‰ã‹ã‚‰
      <table border="1" style="border: 1px solid black; border-collapse: collapse; table-layout: fixed;" width="100%">

    <tr>
      <td>
	<a href="https://twitter.com/tmiyatake1/status/1669495679633485824">https://twitter.com/tmiyatake1/status/1669495679633485824</a>
	<div style="float: left; padding-right:1em;">
	  <a href="Screen Shot 2023-06-20 at 19.29.49.png"><!-- 1179x1102 -->
	    <img src="Screen Shot 2023-06-20 at 19.29.49_thumb.jpg" width="400" height="374" style="border: 2px #ccc solid;" /></a>
	</div>
	<pre>
MetaãŒè‡ªç¤¾é–‹ç™ºã—ãŸLLMã€ŒLLaMAã€ã®æ¬¡ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’é–‹ç™ºã—ã¦ã„ã‚‹ãŒã€
ä»Šå›ã¯å•†æ¥­åˆ©ç”¨å‡ºæ¥ã‚‹ã‚ˆã†ã«ä½œã£ã¦ã„ã‚‹ã€‚

ç¾åœ¨ã®LLaMAã¯ç ”ç©¶åˆ©ç”¨ã§ã—ã‹ä½¿ãˆãªã„ãŒã€
ã“ã‚Œã‚’å•†æ¥­åˆ©ç”¨ã§ä½¿ãˆã‚‹ã¨ã‹ãªã‚Šé¢ç™½ã„å±•é–‹ã«ãªã‚Šãã†ã€‚

<a href="https://www.theinformation.com/articles/meta-wants-companies-to-make-money-off-its-open-source-ai-in-challenge-to-google">https://www.theinformation.com/articles/meta-wants-companies-to-...</a>
	</pre>
      </td>
    </tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/MetaAI/status/1681363272484945921">https://twitter.com/MetaAI/status/1681363272484945921</a>
	    <div style="float: left; padding-right:1em;">
	      <a href="Screen Shot 2023-07-19 at 8.14.16.png"><!-- 1182x946 -->
		<img src="Screen Shot 2023-07-19 at 8.14.16_thumb.jpg" width="400" height="320" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
We believe an open approach is the right one
for the development of todayâ€™s Al models.

Today, weâ€™re releasing Llama 2,
the next generation of Metaâ€™s open source Large Language Model,
available for free for research & commercial use.

Details â¡ï¸ <a href="https://bit.ly/3Dh9hNp">https://bit.ly/3Dh9hNp</a>

<a href="https://ai.meta.com/llama/">https://ai.meta.com/llama/</a>
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/hillbig/status/1681436336451125257">https://twitter.com/hillbig/status/1681436336451125257</a>
	    <div style="float: left; padding-right:1em;">
	      <a href="Screen Shot 2023-07-19 at 10.57.12.png"><!-- 1181x352 -->
		<img src="Screen Shot 2023-07-19 at 10.57.12_thumb.jpg" width="400" height="119" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Llama2ã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’2Tãƒˆãƒ¼ã‚¯ãƒ³ã«å¢—ã‚„ã—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’4Kã«ã—GQAã‚’æ¡ç”¨ã€‚
å ±å‘Šæ›¸ã§ã¯æœ‰ç”¨æ€§ã¨å®‰å…¨æ€§ã®å‘ä¸Šã«å‘ã‘ãŸSFTã¨RLHFã®è©³ç´°ãŒå……å®Ÿã—ã¦ã„ã‚‹ã€‚

SFTã¯é‡ã‚ˆã‚Šè³ªãŒå¤§äº‹ã€‚
2ä¸‡ç¨‹åº¦ä½œã‚‹ã¨SFTå‘ã‘ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã¯ç”Ÿæˆã¨äººæ‰‹ãŒåŒºåˆ¥ã§ããªã„ãƒ¬ãƒ™ãƒ«ã¨ãªã‚‹ã€‚

5ç« ã®è­°è«–ãŒèˆˆå‘³æ·±ã„
1) ç ”ç©¶ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã§ã¯SFTãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ãŒã€SFTã‚ˆã‚ŠRLHFãŒåŠ¹æœçš„ã€‚
SFTã‚¢ãƒãƒ†ãƒ¼ã‚¿ãƒ¼ãŒãŸã¾ã«ä½å“è³ªãªæ•™å¸«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚Šã€SFTãŒãã‚Œã«å¼•ã£å¼µã‚‰ã‚Œã‚‹ãŒã€
Rewordãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯ãã‚ŒãŒå°‘ãªã„ã€‚
ã¾ãŸSFTã¯å­¦ç¿’å¯¾è±¡ãŒã‚¢ãƒãƒ†ãƒ¼ã‚¿ãƒ¼ã®èƒ½åŠ›ã«é™å®šã•ã‚Œã—ã¾ã†ã®ã«å¯¾ã—ã€
RLHFã¯LLMãŒæŒã¤å‰µä½œèƒ½åŠ›ãŒã‚¢ãƒãƒ†ãƒ¼ã‚¿ãƒ¼ã‚’è¶…ãˆã¦ã„ãã“ã¨ãŒã§ãã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚

2) ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ™‚ã®æ¸©åº¦ã¯ã€
å‰µä½œçš„ãªã“ã¨ã‚’ç”Ÿæˆã™ã‚‹å ´åˆã¯æ¸©åº¦ã‚’åæ˜ ã—å¤šæ§˜çš„ãªã®ã‚’ä½œã‚‹ã®ã«å¯¾ã—ã€
äº‹å®Ÿã‚’è¿°ã¹ã‚‹å ´åˆã¯æ¸©åº¦ã‚’ç„¡è¦–ã—åŒã˜ã®ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«å‹æ‰‹ã«ãªã‚‹

3) æ¬¡ã®å˜èªäºˆæ¸¬ã—ã‹ã—ã¦ã„ãªã„ã«ã‚‚é–¢ã‚ã‚‰ãšã€æ™‚é–“ã‚’ç†è§£ã—ã¦ãŠã‚Šã€
ä¾‹ãˆã°ä»Šã®æ™‚ä»£ã‚’SFTã§èª¿æ•´ã™ã‚‹ã¨ãã‚Œã«åˆã‚ã›ã¦å›ç­”ã—ã€
ä¾‹ãˆã°ä»Šã®æ™‚ä»£ãŒ852å¹´ã¨èª¿æ•´ã™ã‚‹ã¨åœ°çƒã¯å¹³ã‚‰ã‹ä¸¸ã„ã‹ã‚’çŸ¥ã‚‰ãªã„ã¨ç­”ãˆã‚‹
ï¼ˆLLMãŒç©ºé–“ã‚‚æŠŠæ¡ã—ã¦ã„ã‚‹ã®ã¯æ—¢å ±ï¼‰

4) ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†èƒ½åŠ›ã¯è¿½åŠ å­¦ç¿’ã›ãšã¨ã‚‚äº‹å‰å­¦ç¿’æ™‚ã§ç™ºç¾ã™ã‚‹

<a href="https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/">https://ai.meta.com/research/publications/llama-2-...</a>
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/snakajima/status/1682164910359461888">https://twitter.com/snakajima/status/1682164910359461888</a>
	    <div style="float: left; padding-right:1em;">
	      <a href="Screen Shot 2023-07-21 at 10.27.28.png"><!-- 1176x1320 -->
		<img src="Screen Shot 2023-07-21 at 10.27.28_thumb.jpg" width="356" height="400" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
MetaãŒã€LLMï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ã§ã‚ã‚‹Llama2ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã¾ã—ãŸãŒã€
æ¥­ç•Œå…¨ä½“ã«å¤§ããªæ¿€éœ‡ã‚’ä¸ãˆã¦ã„ã¾ã™ã€‚
ãªãœãã‚“ãªã«å¤§ããªæ„å‘³ã‚’æŒã¤ã®ã‹ã‚’é€£æŠ•ã§æ›¸ãã¾ã™ã€‚ï¼ˆç¶šãï¼‰
	    </pre>
	  </td>
	</tr>

      </table>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-1-1">
    <div style="font-size: 40px; font-weight: bolder;">
      Llama 2 ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    </div>
    <br /><br />
  </center>

  <ul>
    <li><a href="https://ai.meta.com/llama/">https://ai.meta.com/llama/</a>
      <center>
	<a href="Screen Shot 2023-07-27 at 22.02.52.png"><!-- 2751x1403 -->
	  <img src="Screen Shot 2023-07-27 at 22.02.52_thumb.jpg" width="400" height="204" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>

    <li>è«–æ–‡ï¼š
      (<a href="https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/">https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/</a>)
      <center>
	<a href="Screen Shot 2023-07-27 at 22.15.32.png"><!-- 2755x1416 -->
	  <img src="Screen Shot 2023-07-27 at 22.15.32_thumb.jpg" width="400" height="206" style="border: 2px #ccc solid;" /></a>
      </center>
      <ul>
	<li>"Llama 2: Open Foundation and Fine-Tuned Chat Models"
	  <br />
	  (local copy: <a href="10000000_662098952474184_2584067087619170692_n.pdf">PDF</a>)
	  <center>
	    <object data="10000000_662098952474184_2584067087619170692_n.pdf"
		    type="application/pdf"
		    width="500" height="700">
	      link to PDF:
	      <a href="10000000_662098952474184_2584067087619170692_n.pdf">PDF</a>
	    </object>
	  </center>
	</li>
      </ul>
    </li>

    <li>ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯æ‰‹é †é€šã‚Šã«ã™ã‚Œã°ã€å•é¡Œãªã„
      <ul>
	<li><a href="https://github.com/facebookresearch/llama">https://github.com/facebookresearch/llama</a> ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ã‚¯ãƒ­ãƒ¼ãƒ³</li>
	<li>Mac ã®å ´åˆã€ md5sum ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯å…¥ã£ã¦ãªã„ã®ã§ã€
	  é©å®œã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
	  <ul>
	    <li>ã¼ãã¯ macports ã‚’ä½¿ã£ã¦ã‚‹ã®ã§
	      <pre>
$ sudo port install -v md5sha1sum
	      </pre>
	    </li>
	  </ul>
	</li>
	<li>download.sh ã‚’å®Ÿè¡Œã—ã¦ã€è¦æ±‚ã•ã‚Œã‚‹ URL ã‚’ãƒ¡ãƒ¼ãƒ«ã‹ã‚‰ã‚³ãƒ”ãƒšã—ã¦ã€<br />
	  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸã„ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã™ã‚Œã°ã€<br />
	  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹ã•ã‚Œã‚‹
	  <ul>
	    <li>é€”ä¸­ã§ãƒˆãƒ©ãƒ–ã£ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ«ã®æ®‹éª¸ãŒã‚ã‚‹çŠ¶æ…‹ã§ã‚‚ã€<br />
	      ã‚„ã‚Šç›´ã™ã¨ã€å…¨éƒ¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ç›´ã—ã¾ã™</li>
	    <li>ï¼ˆã“ã‚Œã€ãƒã‚§ãƒƒã‚¯ã‚µãƒ ã‚ã‚‹ã®ã§ã€å¤§ä¸ˆå¤«ãªãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚Œã°ã„ã„ã®ã«â€¦â€¦<br />
	      ã£ã¦ã€ãã‚Œãªã‚‰è‡ªåˆ†ã§ã‚·ã‚§ãƒ«ã‚¯ã‚¹ãƒªãƒ—ãƒˆã«ãƒ‘ãƒƒãƒæ›¸ã‘ã€ã¨ã„ã†ã“ã¨ã ãª<br />
	      ï¼ˆã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€è©³ã—ããªã„ã®ã§ã€ã”ã‚ã‚“ãªã•ã„ï¼‰ï¼‰</li>
	  </ul>
	</li>
	<li>ãƒ¢ãƒ‡ãƒ«ã¯ï¼ˆä»Šã®ã¨ã“ã‚ï¼‰ä»¥ä¸‹ã®ï¼–ç¨®é¡
	  <pre>
llama-2-13b
llama-2-13b-chat
llama-2-70b
llama-2-70b-chat
llama-2-7b
llama-2-7b-chat
	  </pre>
	  ãƒ•ã‚©ãƒ«ãƒ€ã®ä¸­èº«ã¯ã€ä¾‹ãˆã° llama-2-7b ã ã¨
	  <pre>
llama-2-7b:
total 26322160
drwxr-xr-x   5 ichiki  staff          170 Jul 27 23:08 ./
drwxr-xr-x  25 ichiki  staff          850 Jul 28 13:14 ../
-rw-r--r--   1 ichiki  staff          100 Jul 14 08:00 checklist.chk
-rw-r--r--   1 ichiki  staff  13476925163 Jul 14 08:00 consolidated.00.pth
-rw-r--r--   1 ichiki  staff          102 Jul 14 08:00 params.json
	  </pre>
	</li>
	<li>params.json ãŒãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å«ã‚€
	  <pre>
$ cat llama-2-7b/params.json 
{"dim": 4096,
"multiple_of": 256,
"n_heads": 32,
"n_layers": 32,
"norm_eps": 1e-05,
"vocab_size": -1}
	  </pre>
	</li>
      </ul>
    </li><!-- ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯æ‰‹é †é€šã‚Šã«ã™ã‚Œã°ã€å•é¡Œãªã„ -->

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-2">
    <div style="font-size: 50px; font-weight: bolder;">
      LlaMA.cpp ã§ Llama 2
    </div>
    <br /><br />
    <a href="https://github.com/ggerganov/llama.cpp">
      <img src="Screen Shot 2023-07-29 at 18.05.18_thumb.jpg" width="600" height="306" style="border: 2px #ccc solid;" /></a>
  </center>

  <ul>
    <li>ã“ã“ã‹ã‚‰ã¯ã€å…ˆæœˆ (<a href="https://hello-ai-forum.github.io/pages/KAF2306/ichiki/#part2">KAF-2306</a>) ã®ãƒãƒªã«ãªã‚Šã¾ã™â€¦â€¦ã¤ã¾ã‚Š
      <center>
	<div style="font-size: 40px; font-weight: bolder;">
	  è²§ä¹äººã® AI
	  <br />
	  å¤ã„ãƒ‘ã‚½ã‚³ãƒ³ã§ã‚‚ Llama 2 ã‚’ä½¿ã„ãŸã„ï¼
	</div>
	<br /><br />
      </center>
    </li>

    <li>æœ€è¿‘ã®ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ï¼ˆã„ã‚„ã€ã€Œğ•ã€ã¨è¨€ã†ã¹ãã‹ï¼Ÿï¼‰ã‹ã‚‰
      <table border="1" style="border: 1px solid black; border-collapse: collapse; table-layout: fixed;" width="100%">

	<tr>
	  <td>
	    <a href="https://twitter.com/ItakGol/status/1681684771833884675">https://twitter.com/ItakGol/status/1681684771833884675</a>
	    <div style="float: left; padding-right:1em;">
	      <a href="Screen Shot 2023-07-24 at 11.21.54.png"><!-- 1183x1186 -->
		<img src="Screen Shot 2023-07-24 at 11.21.54_thumb.jpg" width="399" height="400" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Llama2 weights have  already been quantized
and available in cpp for local inference! ğŸ‘¼

Weights: <a href="http://huggingface.co/TheBloke">http://huggingface.co/TheBloke</a>
	    </pre>
	  </td>
	</tr>

      </table>
    </li>

    <li>ã¿ãªã•ã‚“ã”æ‰¿çŸ¥ã®é€šã‚Šã€
      python ãªãã¦ã‚‚ Llama ãŒèµ°ã‚‹ <a href="https://github.com/ggerganov/llama.cpp">LlaMA.cpp</a> ã‚’ä½¿ã†ã«ã¯ã€
      ãƒ¢ãƒ‡ãƒ«ã‚’ï¼ˆã„ã‚ã‚†ã‚‹ GGML å½¢å¼ã¨ã‚ˆã°ã‚Œã‚‹ã‚‚ã®ã«ï¼‰å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
      <ul>
	<li>ï¼ˆå¤‰æ›ã«ã¤ã„ã¦ã¯ã€å¾Œè¿°ï¼‰</li>
      </ul>
    </li>
    <li>ä¸Šã®ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆã˜ã‚ƒãªãã¦ã€Œğ•ã€â€¦â€¦ã—ã¤ã“ã„ï¼Ÿï¼‰ãŒè¨€ã£ã¦ã‚‹ã®ã¯ã€
      <ul>
	<li>TheBloke ã•ã‚“ï¼ˆï¼Ÿï¼‰ãŒã€æ—¢ã« GGML å½¢å¼ã«å¤‰æ›ã—ã¦ãã‚Œã¦ã€
	  ãã‚ŒãŒ HuggingFace ã«ã‚ã‚‹ã‚ˆã€
	  ã¨ã„ã†çŸ¥ã‚‰ã›
	</li>
      </ul>
    </li>
    
    <li>å®Ÿé¨“
      <ul>
	<li>å‰ã« clone ã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«è¡Œã£ã¦ã€
	  <pre>
$ cd somewhere/llama.cpp
	    
$ git fetch
$ git merge origin/master

$ make clean
$ make
	  </pre>
	</li>

	<li>ãƒ¢ãƒ‡ãƒ«ã¯ llama-2-7b-chat.ggmlv3.q4_K_M.bin ã‚’ä½¿ã£ã¦ã¿ã‚‹
	  <pre>
$ ./main -m ./models/llama-2-7b-chat.ggmlv3.q4_K_M.bin\
-p "### Instruction: What is the height of Mount Fuji?\
> ### Response:"
main: build = 926 (8a88e58)
main: seed  = 1690618277
llama.cpp: loading model from ./models/llama-2-7b-chat.ggmlv3.q4_K_M.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 4096
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 32
llama_model_load_internal: n_head_kv  = 32
llama_model_load_internal: n_layer    = 32
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: n_gqa      = 1
llama_model_load_internal: rnorm_eps  = 5.0e-06
llama_model_load_internal: n_ff       = 11008
llama_model_load_internal: freq_base  = 10000.0
llama_model_load_internal: freq_scale = 1
llama_model_load_internal: ftype      = 15 (mostly Q4_K - Medium)
llama_model_load_internal: model size = 7B
llama_model_load_internal: ggml ctx size =    0.08 MB
llama_model_load_internal: mem required  = 4193.33 MB (+  256.00 MB per state)
llama_new_context_with_model: kv self size  =  256.00 MB

system_info: n_threads = 4 / 8 | AVX = 1 | AVX2 = 0 | AVX512 = 0 |
AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 |
F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 |
sampling: repeat_last_n = 64, repeat_penalty = 1.100000,
presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40,
tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000,
mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = -1, n_keep = 0


### Instruction: What is the height of Mount Fuji?
### Response: The height of Mount Fuji, located on Honshu Island in Japan,
is 3,776 meters (12,480 feet) above sea level.
This is based on the mountainâ€™s summit elevation,
which is the highest point on the mountain. However,
itâ€™s important to note that the height of Mount Fuji
can vary slightly depending on how it is measured
and where the measurement is taken along the mountain.
For example, some sources may give a height of 3,791 meters (12,438 feet)
or 3,780 meters (12,400 feet), based on different methods of measurement.
Nonetheless, 3,776 meters is the most commonly cited
and accepted height for Mount Fuji. [end of text]

llama_print_timings:        load time = 157994.23 ms
llama_print_timings:      sample time =   338.27 ms
/   169 runs   (    2.00 ms per token,   499.61 tokens per second)
llama_print_timings: prompt eval time = 17858.14 ms
/    18 tokens (  992.12 ms per token,     1.01 tokens per second)
llama_print_timings:        eval time = 45131.00 ms
/   168 runs   (  268.64 ms per token,     3.72 tokens per second)
llama_print_timings:       total time = 63353.35 ms
	  </pre>
	</li>

	<li>çµæ§‹ã€ã¯ã‚„ã„ï¼</li>

      </ul>
    </li><!-- å®Ÿé¨“ -->

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-3">
    <div style="font-size: 50px; font-weight: bolder;">
      Andrej Karpathy ã® llama2.c
    </div>
    <br /><br />
    <a href="https://github.com/karpathy/llama2.c">
      <img src="Screen Shot 2023-07-29 at 18.04.57_thumb.jpg" width="600" height="277" style="border: 2px #ccc solid;" /></a>
  </center>

  <ul>
    <li>æœ€è¿‘ã®ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ï¼ˆã„ã‚„ã€ã€Œğ•ã€ã¨è¨€ã†ã¹ãã‹ï¼Ÿï¼‰ã‹ã‚‰
      <table border="1" style="border: 1px solid black; border-collapse: collapse; table-layout: fixed;" width="100%">

	<tr>
	  <td>
	    <a href="https://twitter.com/karpathy/status/1683143097604243456">https://twitter.com/karpathy/status/1683143097604243456</a>
	    <div style="float: left; padding-right:1em;">
	      <a href="Screen Shot 2023-07-24 at 11.06.44.png"><!-- 1179x1309 -->
		<img src="Screen Shot 2023-07-24 at 11.06.44_thumb.jpg" width="360" height="400" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
My fun weekend hack: llama2.c ğŸ¦™ğŸ¤ 
<a href="https://github.com/karpathy/llama2.c">https://github.com/karpathy/llama2.c</a>
Lets you train a baby Llama 2 model in PyTorch,
then inference it with one 500-line file with no dependencies, in pure C.
My pretrained model (on TinyStories) samples stories in fp32
at 18 tok/s on my MacBook Air M1 CPU.
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/karpathy/status/1683698478080466944">https://twitter.com/karpathy/status/1683698478080466944</a>
	    <div style="float: left; padding-right:1em;">
	      <a href="Screen Shot 2023-07-25 at 14.03.13.png"><!-- 1181x997 -->
		<img src="Screen Shot 2023-07-25 at 14.03.13_thumb.jpg" width="400" height="338" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Yay, llama2.c can now load and inference the Meta released models! :)
E.g. here inferencing the smallest 7B model at ~3 tokens/s
on 96 OMP threads on a cloud Linux box.
Still just CPU, fp32, one single .c file of 500 lines:
<a href="https://github.com/karpathy/llama2.c">https://github.com/karpathy/llama2.c</a>
expecting ~300 tok/s tomorrow :)
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/ggerganov/status/1683574709470875649">https://twitter.com/ggerganov/status/1683574709470875649</a>
	    <div style="float: left; padding-right:1em;">
	      <a href="Screen Shot 2023-07-27 at 17.47.44.png"><!-- 1179x947 -->
		<img src="Screen Shot 2023-07-27 at 17.47.44_thumb.jpg" width="400" height="321" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Lets add support for llama2.c models to llama.cpp

<a href="https://github.com/ggerganov/llama.cpp/issues/2379">https://github.com/ggerganov/llama.cpp/issues/2379</a>
	    </pre>
	  </td>
	</tr>

	<tr>
	  <td>
	    <a href="https://twitter.com/karpathy/status/1684612972034011136">https://twitter.com/karpathy/status/1684612972034011136</a>
	    <div style="float: left; padding-right:1em;">
	      <a href="Screen Shot 2023-07-28 at 11.27.27.png"><!-- 1177x760 -->
		<img src="Screen Shot 2023-07-28 at 11.27.27_thumb.jpg" width="400" height="258" style="border: 2px #ccc solid;" /></a>
	    </div>
	    <pre>
Neat, didnâ€™t realize llama2.c made it to the top of Github trending.
Also more generally Github trending is a great place
to keep an eye on for projects that are seeing traction,
either as following this account and its xeets, or as bookmark.

<a href="https://twitter.com/trending_repos/status/1684488232862732289">https://twitter.com/trending_repos/status/1684488232862732289</a>

Trending repository of the day ğŸ“ˆ
  
llama2.c by @karpathy

Inference Llama 2 in one file of pure C

Last 24h: 2214 â­
Total: 8367 â­ï¸
	    </pre>
	  </td>
	</tr>

      </table>
    </li>

    <br />

    <li>andrej karpathy ã® <a href="https://github.com/karpathy/llama2.c">llama2.c</a>
      <ul>
	<li>ã“ã‚Œã€ã‚„ã£ã±ã‚Šé¢ç™½ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã </li>

	<li>Llama 2 ãƒ¢ãƒ‡ãƒ«ã‚’ã€è‡ªåˆ†ã§å­¦ç¿’ã—ã‚ˆã†ï¼ˆpytorch ã§ï¼‰ã¨è¨€ã†ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</li>
	<li>ã¨ã„ã†ã‚ˆã‚Šã€ãã®çµæœï¼ˆã¤ã¾ã‚Š Llama 2 ãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’å®Ÿè¡Œï¼ˆæ¨è«–ï¼‰ã™ã‚‹
	  ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ C ã ã‘ã§ï¼ˆãªã‚“ã®ä¾å­˜æ€§ã‚‚ãªãï¼‰æ›¸ã„ãŸã‚ˆã€ã¨ã„ã†ã®ãŒãƒã‚¤ãƒ³ãƒˆ</li>

	<li>ã ã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåãŒ llama2.c</li>

	<li>ä»¥å‰ã€ã¼ãè‡ªèº«ã‚‚æ‰‹ã‚’å‹•ã‹ã—ãŸ karpathy ã® nanoGPT
	  (<a href="https://hello-ai-forum.github.io/pages/ZAF202302/ichiki/#part1-gpt-from-scratch">ZAF-2302</a>)
	  <center>
      	    <a href="Screen Shot 2023-07-29 at 17.28.17.png"><!-- 2732x1188 -->
	      <img src="Screen Shot 2023-07-29 at 17.28.17_thumb.jpg" width="600" height="261" style="border: 2px #ccc solid;" /></a>
	  </center>
	  ã‚’æ€ã„å‡ºã™
	</li>

	<center>
	  <br />
	  <div style="font-size: 40px; font-weight: bolder;">
	    éŠã³ãŸã„ã“ã¨ãƒªã‚¹ãƒˆ
	  </div>
	  <br /><br />
	</center>

	<li>ï¼ˆä»Šå›ã¯æ™‚é–“ãŒãªã‹ã£ãŸã®ã§ã€ã§ããªã‹ã£ãŸã“ã¨ï¼‰
	  <ul>
	    <li>Llama 2 ã®è«–æ–‡ã‚’èª­ã‚“ã§ã€ GPT ã¨ã®é•ã„ã‚’ç†è§£ã—ã€
	      è‡ªåˆ†ã§å®Ÿè£…ã—ã¦ã¿ã‚‹
	    </li>
	    <li>ã„ãšã‚Œã®ãƒ¢ãƒ‡ãƒ«ã‚‚ã€æ¨è«–ç”¨ã« C ç‰ˆã‚’æ›¸ã„ã¦ã¿ã‚‹</li>

	    <li>ä¸Šã§è¿°ã¹ãŸ RWKV ã¨ã‹ RetNet ã¨ã‹ã€å®Ÿè£…ã—ã¦ã‚‚é¢ç™½ãã†</li>
	  </ul>
	</li><!-- éŠã³æ–¹ï¼ˆä»Šå›ã¯æ™‚é–“ãŒãªã‹ã£ãŸã®ã§ã€ã§ããªã‹ã£ãŸã“ã¨ï¼‰ -->

      </ul>
    </li><!-- llama2.c by karpathy -->

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-3-1">
    <div style="font-size: 40px; font-weight: bolder;">
      ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›ã«ã¤ã„ã¦
    </div>
    <br /><br />
  </center>

  <ul>
    <li>ã˜ã‚ƒãã€
      <center>
	<br />
	<div style="font-size: 40px; font-weight: bolder;">
	  ä»Šæ—¥ã¯ãªã«ã‚’ã‚„ã£ãŸã®ã‹ï¼Ÿ
	</div>
	<br /><br />
      </center>
      ãã‚Œã¯ï¼ˆä¸Šã«ã¡ã‚‡ã“ã£ã¨è¨€åŠã—ãŸï¼‰
      pytorch ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›ã«ã¤ã„ã¦ã€
      ã¡ã‚‡ã£ã¨å®Ÿé¨“ã—ã¦ã¿ãŸ
      <ul>
	<li>ã‚„ã‚ã†ã¨ã—ãŸã“ã¨ã¯ã€
	  å¤‰æ›ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚‚ï¼ˆpython ã‚’ä½¿ã‚ãšï¼‰
	  C ã§æ›¸ã“ã†ã£ã¦ã“ã¨
	</li>
	<li>ã§ã€ã„ã‚ã„ã‚èª¿ã¹ãŸçµæœã€
	  ã¾ãã€ python ã§æ›¸ãæ–¹ãŒç„¡é›£ã ã­ã€
	  ã¨ã„ã†çµè«–ã«è½ã¡ç€ã„ãŸã€ã¨
	</li>
      </ul>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-3-1a">
    <div style="font-size: 40px; font-weight: bolder;">
      ï¼ˆï¼ï¼‰ llama2.c ã®å¤‰æ›ãƒ—ãƒ­ã‚°ãƒ©ãƒ 
    </div>
    <br /><br />
  </center>
  <ul>
    <li>llama2.c ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«
      Meta ã® Llama2 ãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
      (export_meta_llama_bin.py) ãŒè¿½åŠ ã•ã‚ŒãŸï¼
    </li>
    <li>ã¤ã¾ã‚Šã€æœ¬ç‰©ã® Llama2 ãŒ CPU ã§å‹•ãï¼
      <ul>
	<li>ï¼ˆã¾ãã€ä¸Šã§è¦‹ãŸé€šã‚Š llaMA.cpp ã§ã€å‹•ãã®ã¯æ—¢ã«å‹•ãã‚“ã ã‘ã©ï¼‰</li>
      </ul>
    </li>
    <li>ã—ã‹ã— llama2.c ã§ä½¿ã†ãŸã‚ã«ã¯ã€
      ï¼ˆãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚’éµå®ˆã™ã‚‹å ´åˆã¯ã€ãªã®ã‹ãªï¼Ÿï¼‰
      å„è‡ªãŒå…ƒã® pytorch ã® weight ã‚’ã€Œllama2.c ã®ãƒã‚¤ãƒŠãƒªãƒ¼ã€å½¢å¼
      ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
      <ul>
	<li>ãã®ãŸã‚ã® python script ãŒè¿½åŠ ã•ã‚ŒãŸã€ã¨</li>
      </ul>
    </li>
    <li>ã—ã‹ã—ï¼
      <ul>
	<li>è²§ä¹äººã®ãƒ‘ã‚½ã‚³ãƒ³ç’°å¢ƒã¯ã€ä»Šã€ã¾ã¨ã‚‚ãª python ãŒãªã„
	  <ul>
	    <li>ãã‚Œã«ã€ä¾å­˜æ€§è¦‹ã‚‹ã¨ torch ãŒè¦æ±‚ã•ã‚Œã¦ã„ã‚‹â€¦â€¦</li>
	  </ul>
	</li>
	<li>ãã‚‚ãã‚‚ã€ãªã‚“ã§ llama2.c ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«
	  python script ãŒå…¥ã£ã¦ã‚‹ã‚“ã ï¼Ÿ
	  <ul>
	    <li>ï¼ˆC ãªã‚‰ã€åŸºæœ¬ã€ä½•ã§ã‚‚æ›¸ã‘ã‚‹ã—ã€
	      ãªã‚“ãªã‚‰ python ã ã£ã¦ C ã§æ›¸ã‹ã‚Œã¦ã„ã‚‹ã€ã‚ˆã­ï¼‰
	    </li>
	  </ul>
	</li>
      </ul>
    </li><!-- ã—ã‹ã—ï¼ -->

    <li>ã¨ã„ã†ã“ã¨ã§ã€ã—ã°ã‚‰ãï¼ˆåŠæ—¥ãã‚‰ã„ï¼‰
      pytorch ã® weight ãƒ•ã‚¡ã‚¤ãƒ« pth ã‚’
      C ã§é–‹ããŸã‚ã«ã¯ã©ã†ã—ãŸã‚‰ã„ã„ã‹ã€
      ã¡ã‚‡ã£ã¨èª¿ã¹ã¦ã¿ãŸ
    </li>
  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-3-1b">
    <div style="font-size: 40px; font-weight: bolder;">
      ï¼ˆï¼‘ï¼‰ pth ã‚’ C ã§é–‹ãã«ã¯ï¼Ÿ
    </div>
    <br /><br />
  </center>
  <ul>
    <li>æœ¬å®¶ã®æƒ…å ±ã«ã‚ˆã‚‹ã¨ã€
      å­¦ç¿’ã¯ python ç’°å¢ƒã§ã‚„ã‚‹ãŒã€
      æ¨è«–ãªã© production ã§ã®è¨ˆç®—ã§ã¯ python ã«ä¾å­˜ã—ãªã„ç’°å¢ƒã§ä½¿ã„ãŸã„ã€
      ã¨ã„ã†ãƒ‹ãƒ¼ã‚ºãŒã‚ã‚‹ã‚ˆã†ã§ã€
      ãã®ãŸã‚ã® workflow ãŒæº–å‚™ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã 
    </li>
    <li>TorchScript
      <ul>
	<li>...</li>
      </ul>
    </li>
    <li>ã§ã‚‚ã€ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€åº¦ python ã®ç’°å¢ƒã§ TorchScript å½¢å¼ï¼ˆï¼Ÿï¼‰ã«ã—ã¦ã€
      ãã‚Œã‚’ C++ ãªã©ã§ä½¿ã†ã‚ˆã†ãªå½¢ã‚‰ã—ã„
      <ul>
	<li>ãã‚Œã¯ã€ã‚ªãƒ¬ã®æ¬²ã—ã„ã‚‚ã®ã§ã¯ãªã„</li>
      </ul>
    </li>
  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-3-1c">
    <div style="font-size: 40px; font-weight: bolder;">
      ï¼ˆï¼’ï¼‰ ãã‚‚ãã‚‚ pth ãƒ•ã‚¡ã‚¤ãƒ«ã£ã¦ä½•ï¼Ÿ
    </div>
    <br /><br />
  </center>
  <ul>
    <li>llama.cpp ã«ã‚ã‚‹å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ convert.py ã‚’èª­ã‚“ã§ã¿ã‚‹ã¨
      <ul>
	<li>ã¡ãªã¿ã«ã€ã“ã„ã¤ã¯ã€ torch ã«ã¯ä¾å­˜ã—ã¦ãªã‹ã£ãŸã®ã§ã€
	  Mac ã® native ç’°å¢ƒï¼ˆmacportsï¼‰ã« python38 ã‚’æº–å‚™ã—ã¦ã¿ãŸ</li>
      </ul>
    </li>

    <li>ã™ã‚‹ã¨ã€ pth ãƒ•ã‚¡ã‚¤ãƒ«ã¯ zip åœ§ç¸®ã•ã‚Œã¦ãŸ zip ãƒ•ã‚¡ã‚¤ãƒ«</li>

    <li>ä¾‹ãˆã° Llama2 ã® 7B-Chat ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹ã™ã‚‹ã¨
      consolidated ã¨ã„ã†ãƒ•ã‚©ãƒ«ãƒ€ä¸‹ã«
      <pre>
$ ll consolidated/
total 96
drwxr-xr-x    5 ichiki  staff    170 Jul 29 11:41 ./
drwxr-xr-x   16 ichiki  staff    544 Jul 29 11:41 ../
drwxr-xr-x  294 ichiki  staff   9996 Jul 29 11:41 data/
-rw-rw-r--    1 ichiki  staff  34124 Nov 30  1979 data.pkl
-rw-rw-r--    1 ichiki  staff      2 Nov 30  1979 version
      </pre>
      ã¨ã„ã†ãƒ•ã‚¡ã‚¤ãƒ«ã€ data ä¸‹ã«ã‚‚ã„ã£ã±ã„ãƒ•ã‚¡ã‚¤ãƒ«
      <pre>
$ ll consolidated/data
total 26321952
drwxr-xr-x  294 ichiki  staff       9996 Jul 29 11:41 ./
drwxr-xr-x    5 ichiki  staff        170 Jul 29 11:41 ../
-rw-rw-r--    1 ichiki  staff  262144000 Nov 30  1979 0
-rw-rw-r--    1 ichiki  staff       8192 Nov 30  1979 1
-rw-rw-r--    1 ichiki  staff  262144000 Nov 30  1979 2
-rw-rw-r--    1 ichiki  staff   33554432 Nov 30  1979 3
-rw-rw-r--    1 ichiki  staff   33554432 Nov 30  1979 4

...

-rw-rw-r--    1 ichiki  staff   90177536 Nov 30  1979 286
-rw-rw-r--    1 ichiki  staff   90177536 Nov 30  1979 287
-rw-rw-r--    1 ichiki  staff   90177536 Nov 30  1979 288
-rw-rw-r--    1 ichiki  staff       8192 Nov 30  1979 289
-rw-rw-r--    1 ichiki  staff       8192 Nov 30  1979 290
-rw-rw-r--    1 ichiki  staff        128 Nov 30  1979 291
      </pre>
    </li>

    <li>å¤§äº‹ãªã®ã¯ pickle ãƒ•ã‚¡ã‚¤ãƒ«ã€ python ã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¶ã§ã™ãª
      ï¼ˆä¸­èº«ã¯ã‚ˆãçŸ¥ã‚‰ãªã„ã‘ã‚Œã©â€¦â€¦ï¼‰
    </li>

    <li>pickle ã‚’ python ã‚’ä½¿ã‚ãšã« C ã ã‘ã§å–ã‚Šæ‰±ã†æ–¹æ³•ã¯ï¼Ÿ
      <ul>
	<li>stackoverflow ã•ã‚“ã¨ã‹æ›°ãã€
	  ç´ ç›´ã« python ä½¿ãˆã€
	  ãªã‚“ã§ python ä½¿ã‚ãªã„ã®ï¼Ÿ
	  ã¿ãŸã„ãªçŠ¶æ³
	</li>
	<li>ã¾ã€ã„ã‚ã„ã‚ãªçŠ¶æ³ã«å¯¾ã™ã‚‹ã‚µãƒãƒ¼ãƒˆã‚„ã€
	  æ§˜ã€…ãªãƒ•ã‚§ã‚¤ãƒ«ã‚»ãƒ¼ãƒ•ãªã©ã€
	  ã‚­ãƒƒãƒãƒ³ã‚·ã‚¯çš„ã«ãã®éƒ¨åˆ†ã«æŠ¼ã—è¾¼ã¾ã‚Œã¦ã¦ã€<br />
	  å…¥ã‚Šå£ï¼ˆã®ãƒ‡ãƒ¼ã‚¿ï¼‰ã¨å‡ºå£ï¼ˆã®ãƒ‡ãƒ¼ã‚¿ï¼‰ã®
	  ä¸­ç«‹æ€§ã‚’æ‹…ä¿ã—ã¦ã„ã‚‹ãŒæ•…ã€ãªã‚“ã ã‚ã†ãª
	</li>
      </ul>
    </li>

  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-3-1d">
    <div style="font-size: 40px; font-weight: bolder;">
      çµè«–ï¼š pth ãƒ•ã‚¡ã‚¤ãƒ«ã¯ python ã§æ‰±ã†ã®ãŒç¾å®Ÿçš„
    </div>
    <br /><br />
  </center>
  <ul>
    <li>è€ƒãˆã‚Œã°ã€ llama.cpp ã‚‚ llama2.c ã‚‚ã€<br />
      python ã§æ›¸ã„ã¦ã„ã‚‹ã«ã¯ã€ãã‚Œã ã‘ã®ç†ç”±ãŒã‚ã‚‹ã‚ã‘ã§
    </li>
    <li>ã„ã„å‹‰å¼·ã«ãªã‚Šã¾ã—ãŸã€‚ï¼ˆã‚ªãƒ¬ã®åŠæ—¥ã¯â€¦â€¦ï¼‰</li>
  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-3-2">
    <div style="font-size: 40px; font-weight: bolder;">
      ãƒ­ãƒ¼ã‚«ãƒ«ã§ python ã®å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å‹•ã‹ã™
    </div>
    <br /><br />
  </center>
  <ul>
    <li>ï¼ˆãªã‚“ã‹ã€æœ€åˆè¨€ã£ã¦ãŸã“ã¨ã¨ï¼‘ï¼˜ï¼åº¦åå¯¾ã®ã“ã¨ã ã‘ã©â€¦â€¦ï¼‰</li>

    <br />

    <li>ã•ã£ãæº–å‚™ã—ã‹ã‘ãŸ macports ã® python38 ç’°å¢ƒã« torch ã‚‚å…¥ã‚Œã¦ã—ã¾ã†
      <ul>
	<li>macports ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã‚¹ã‚¿ã‚¤ãƒ«
	  <ul>
	    <li>ï¼ˆpip ã‚‚ macports ã‹ã‚‰å…¥ã‚Œã‚Œã°ã€
	      pip ã§è¡Œã‘ãŸã®ã‹ã‚‚ã—ã‚Œãªã„ãŒï¼‰</li>
	  </ul>
	</li>
	<li>ã‚ã¨ sentencepiece ã‚‚å…¥ã‚Œã‚‹å¿…è¦ãŒã‚ã£ãŸ</li>
	<li>ã§ã‚‚ã€ãã‚Œã ã‘ã§ export_meta_llama_bin.py ã¯é€šã£ãŸ</li>

	<li>7B ã¨ 7B-Chat ã‚’å¤‰æ›ã—ã¦ãŠã
	  <pre>
$ ll *.bin
-rw-r--r--  1 ichiki  staff  26954711068 Jul 29 13:29 llama-2-7b-chat.bin
-rw-r--r--  1 ichiki  staff  26954711068 Jul 29 14:37 llama-2-7b.bin
-rw-r--r--  1 ichiki  staff       432717 Jul 29 12:53 tokenizer.bin
	  </pre>
	</li>

      </ul>
    </li><!-- ã•ã£ãæº–å‚™ã—ã‹ã‘ãŸ macports ã® python38 ç’°å¢ƒã« ... -->
  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="part2-3-3">
    <div style="font-size: 40px; font-weight: bolder;">
      llama2.c ã§ Llama2 ãƒ¢ãƒ‡ãƒ«ã‚’å‹•ã‹ã™
    </div>
    <br /><br />
  </center>

  <ul>
    <li>ä»Šã€å¤‰æ›ã—ãŸ 7B ãƒ¢ãƒ‡ãƒ«ã‚’å‹•ã‹ã—ã¦ã¿ã‚ˆã†ï¼
      <pre>
Kengos-MacBook-Pro:llama2.c ichiki$ ./run llama-2-7b.bin 0 64 "Hello! How are you doing today?"
&lt;s&gt;
Hello! How are you doing today??
I hope you are doing well.
I am doing well.
I am happy to be here with you.
I am happy to be here with you.
I am happy to be here with
      </pre>
      ãªã‚“ã‹ã€ãƒãƒã£ã¨ã‚‹ãªâ€¦â€¦
    </li>
    <li>ãã‚Œã«ã€ã‚ã¡ã‚ƒãã¡ã‚ƒé…ã„â€¦â€¦
      <ul>
	<li>fp32 ã®ã¾ã¾ã€ã¨ã„ã†ã®ãŒã€ã‚„ã£ã±ã‚Šé‡ãŸã„åŸå› ã‹ãª</li>
	<li>ï¼ˆLlaMA.cpp ã® 7B-Chat ã¯ llama-2-7b-chat.ggmlv3.q4_K_M.bin ã ã£ãŸï¼‰</li>
      </ul>
    </li>

  </ul>

  <center>
    <div style="font-size: 40px; font-weight: bolder;">
      æ¬¡ã¾ã§ã«ã€ RetNet ãƒã‚¹ã‚¿ãƒ¼ã™ã‚‹ããƒ¼ï¼
    </div>
    <br /><br />
  </center>

  <br /><br />
  <div align="right">
    ï¼ˆ<a href="#toc">ãƒˆãƒƒãƒ—ã«æˆ»ã‚‹</a>ã€<a href="#detailed-toc">è©³ç´°ç›®æ¬¡ã¸</a>ï¼‰
  </div>

  <hr />

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <center id="epilogue">
    <div style="font-size: 50px; font-weight: bolder;">
      ä»Šæ—¥ã®ãŠã‚ã‚Šã«
    </div>
  </center>

  <p>â€¦â€¦</p>

  <h3>ä»Šå¾Œã®äºˆå®š</h3>
  <ul>
    <li>æ¬¡å›ã€Œã“ã‚“ã«ã¡ã‚ï¼ AI FORUMã€ã¯
      <center>
	<div style="font-size: 40px; font-weight: bolder;">
	  <br />
	  2023 å¹´ 8 æœˆ 26 æ—¥ï¼ˆåœŸæ›œæ—¥ï¼‰<br />
	  é–‹å‚¬ã®äºˆå®šã§ã™ï¼
	  <br /><br />
	</div>
      </center>
      <ul>
	<li>ã”æ„è¦‹ã€ã”å¸Œæœ›ãªã©ã€ãŠæ°—è»½ã«ï¼</li>
      </ul>
    </li>
    <li>ãƒ•ã‚©ãƒ¼ãƒ©ãƒ è¬›æ¼”è€…ã€ã‚µãƒ¼ã‚¯ãƒ«åŒäººèªŒæ´»å‹•ã¸ã®åŸ·ç­†è€…ã€çµ¶è³›ã€å¤§å‹Ÿé›†ä¸­ã§ã™ï¼<br />
      ãŠæ°—è»½ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ï¼</li>
  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

  <hr />
  <hr />

  <h2 id="detailed-toc">ç·åˆç›®æ¬¡</h2>
  <ul>
    <li><b>å‰åº§</b>
      <a href="#part0">2023 å¹´å‰åŠã®æŒ¯ã‚Šè¿”ã‚Š</a>
      <ul>
	<li><a href="#part0-1">ãƒ”ã‚¢ãƒ</a></li>
	<li><a href="#part0-2">ã€Œã“ã‚“ã«ã¡ã‚ï¼ AI FORUM ã®ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã€</a></li>
	<li><a href="#part0-3">ã€ŒéŸ³æ¥½ã¨æ•°ç† ğŸ¼ â™¾ ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã€</a></li>
	<li><a href="#part0-4">è‹±èªã®ï¼ˆç´™ã®ï¼‰æœ¬ã‚’ã‚¢ãƒã‚¾ãƒ³ã§ä¸–ç•Œã«å‘ã‘ã¦å£²ã‚‹</a></li>
	<li><a href="#part0-5">ã¾ã¨ã‚</a></li>
      </ul>
    </li>

    <li><b>ãƒ‘ãƒ¼ãƒˆï¼‘</b>
      <a href="#part1">AI ã®æœªæ¥</a>
      <ul>
	<li><a href="#part1-1">Jeremy Howard ã®ã€ŒDelightenmentã€</a></li>
	<li><a href="#part1-2">æœ€è¿‘ã® AI æ¥­ç•Œã®å‹•ã</a></li>
	<li><a href="#part1-3">The Frontier Model Forum</a></li>
      </ul>
    </li>

    <li><b>ãƒ‘ãƒ¼ãƒˆï¼’</b>
      <a href="#part2">æœ€è¿‘ã® LLMs</a>
      <ul>
	<li><a href="#part2-0">ãƒã‚¹ãƒˆ Transformer æ™‚ä»£ã® LLMs</a>
	  <ul>
	    <li><a href="#part2-0-1">RWKV (Receptance Weighted Key Value)</a></li>
	    <li><a href="#part2-0-2">FlashAttention-2</a></li>
	    <li><a href="#part2-0-3">Retentive Network (RetNet)</a></li>
	    <li><a href="#part2-0-4">phi-1 / ã€ŒTextbooks Are All You Needã€è«–æ–‡</a></li>
	  </ul>
	</li>
	<li><a href="#part2-1">Llama 2 ç™ºè¡¨</a>
	  <ul>
	    <li><a href="#part2-1-1">ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a></li>
	  </ul>
	</li>
	<li><a href="#part2-2">LlaMA.cpp ã§ Llama 2</a></li>
	<li><a href="#part2-3">Andrej Karpathy ã® llama2.c</a>
	  <ul>
	    <li><a href="#part2-3-1">ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›ã«ã¤ã„ã¦</a>
	      <ul>
		<li><a href="#part2-3-1a">ï¼ˆï¼ï¼‰ llama2.c ã®å¤‰æ›ãƒ—ãƒ­ã‚°ãƒ©ãƒ </a></li>
		<li><a href="#part2-3-1b">ï¼ˆï¼‘ï¼‰ pth ã‚’ C ã§é–‹ãã«ã¯ï¼Ÿ</a></li>
		<li><a href="#part2-3-1c">ï¼ˆï¼’ï¼‰ ãã‚‚ãã‚‚ pth ãƒ•ã‚¡ã‚¤ãƒ«ã£ã¦ä½•ï¼Ÿ</a></li>
		<li><a href="#part2-3-1d">çµè«–ï¼š pth ãƒ•ã‚¡ã‚¤ãƒ«ã¯ python ã§æ‰±ã†ã®ãŒç¾å®Ÿçš„</a></li>
	      </ul>
	    </li>
	    <li><a href="#part2-3-2">ãƒ­ãƒ¼ã‚«ãƒ«ã§ python ã®å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å‹•ã‹ã™</a></li>
	    <li><a href="#part2-3-3">llama2.c ã§ Llama2 ãƒ¢ãƒ‡ãƒ«ã‚’å‹•ã‹ã™</a></li>
	  </ul>
	</li>
      </ul>
    </li>

    <li><a href="#epilogue">ä»Šæ—¥ã®ãŠã‚ã‚Šã«</a></li>
  </ul>

  <br /><br /><br /><center>...â™¦...</center><br /><br /><br />

</section>

</article>

</body>           
</html>
