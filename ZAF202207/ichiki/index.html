<!doctype html>
<html>
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta charset="UTF-8" />
    <title>ZENKEI AI FORUM (2022/07/27)</title>
    <link href="https://fonts.googleapis.com/css?family=M+PLUS+1p:100,400,700&display=swap&subset=japanese" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="../../bright-M_PLUS_1p.css" />

    <link rel="stylesheet"
	  href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.2.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.2.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    <script type="text/javascript" id="MathJax-script" async
	    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  </head>

<body style="font-size: 20px;">

<header>
<center><h1>ZENKEI AI FORUM 2022/07/27</h1></center>
</header>

<article>

<section id="main">

  <center>
    <a href="ZENKEI_AI_FORUM_zoom_20220727-2488x1400.jpg"><!-- 2488x1400 -->
      <img src="ZENKEI_AI_FORUM_zoom_20220727-2488x1400_thumb.jpg" width="800" height="450" style="border: 2px #ccc solid;" /></a>
  </center>

  <br /><br /><br /><center>...♦...</center><br /><br /><br />

  <center>
    <div style="font-size: 60px; font-weight: bold;">
      ZAF ２０２２年７月２７日
    </div>
    <div style="font-size: 40px;">＜本日のテーマ＞</div>
    <div style="font-size: 80px;">
      ぼちぼちと、今日も一歩
    </div>
  </center>

  <br /><br /><br /><center>...♦...</center><br /><br /><br />

  <hr />

  <h2>目次</h2>
  <ul>
    <li>[6:30 - 7:00]
      <b>前座</b>
      <ul>
	<li><a href="#part0">みなさま、この一月、いかがお過ごしでしたでしょうか？</a></li>
      </ul>
    </li>

    <li>[7:00 - 8:00]
      <b>パート１</b>
      <ul>
	<li><a href="#part1">この１ヶ月の AI の話題から</a></li>
      </ul>
    </li>

    <li>[8:00 - 9:00]
      <b>パート２</b>
      <ul>
	<li><a href="#part2">技術書典１３企画会議！第２回</a></li>
      </ul>
    </li>

    <li><a href="#epilogue">今日のおわりに</a></li>

    <li><a href="#detailed-toc">総合目次</a></li>
  </ul>

  <hr />

  <center>
    <br />
    <div style="font-size: 30px;">
      YouTube のアーカイブ・ビデオはこちら
    </div>
    (<a href="https://youtube.com/live/f8r-4HZs02c">
      https://youtube.com/live/f8r-4HZs02c</a>)
    <br /><br />
    <a href="https://youtube.com/live/f8r-4HZs02c">
      <img src="Screen Shot 2023-03-31 at 10.46.47_thumb.jpg" width="500" height="283" style="border: 2px #ccc solid;" /></a>
    <br /><br />
  </center>

  <br /><br /><br /><center>...♦...</center><br /><br /><br />

  <hr />

  <center id="part0">
    <div style="font-size: 50px; font-weight: bolder;">
      （前座）
      <br />
      さて、みなさま、<br />
      この一月、いかがお過ごしでしたでしょうか？
    </div>
  </center>

  <br /><br /><br />

  <ul>
    <li>ぼくは、いろいろ、大変だったです。</li>
    <li>今日の前座は、この一月を、ちょっと振り返ってみようかなと思います。
      <ul>
	<li>この大変な状況から、<br />
	  それでも何か学びとることがあれば、きちんと学びとって、<br />
	  これからに生かしたい、と</li>
      </ul>
    </li>

    <li>始める前に、有名な作家の有名な一言を、引用しておこうと思います。</li>
  </ul>

  <center id="part0">
    <div style="font-size: 50px; font-weight: bolder;">
      Courage is grace under pressure
      <br /><br />
      勇気とは、困難な状況化における気高さである
    </div>
  </center>

  <br /><br /><br />

  <ul>
    <li>さて質問です。これはだれの言葉でしょうか？</li>
  </ul>

  <br /><br /><br /><br /><br /><br />

  <center id="part0">
    <div style="font-size: 40px; font-weight: bolder;">
      正解は、
    </div>
    <br /><br />
    <div style="font-size: 50px; font-weight: bolder;">
      Ernest Hemingway<br />
      アーネスト・ヘミングウェイ
    </div>
  </center>

  <br /><br /><br />

  <ul>
    <li>ぼくがこの言葉を知ったのは、ツイッターでした（だめだこりゃ）
      <center>
	<a href="Screen Shot 2022-07-27 at 18.06.30.png"><!-- 1497x296 -->
	  <img src="Screen Shot 2022-07-27 at 18.06.30_thumb.jpg" width="800" height="158" style="border: 2px #ccc solid;" /></a>
      </center>
      (<a href="https://twitter.com/rkmt/status/1198526456847953920">https://twitter.com/rkmt/status/1198526456847953920</a>)
      <center>
	<a href="Screen Shot 2022-07-27 at 18.11.59.png"><!-- 1360x776 -->
	  <img src="Screen Shot 2022-07-27 at 18.11.59_thumb.jpg" width="600" height="342" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>

    <li>ということで、ぼくの、この一月を、振り返ってみたいと思います。</li>
  </ul>


  <br /><br /><br /><center>...♦...</center><br /><br /><br />

  <ul>
    <li>ZENKEI AI ポッドキャスト<br />
      (<a href="https://zenkei.seesaa.net/">https://zenkei.seesaa.net/</a>)
      <center>
	<a href="Screen Shot 2022-07-24 at 17.30.53.png"><!-- 2790x1346 -->
	  <img src="Screen Shot 2022-07-24 at 17.30.53_thumb.jpg" width="1000" height="482" style="border: 2px #ccc solid;" /></a>
      </center>
      <ul>
	<li>粛々と、週１ペースを堅持！</li>
      </ul>
    </li>

    <li>Twitch
      (<a href="https://www.twitch.tv/kengoichiki">twitch.tv/kengoichiki</a>)
      <center>
	<a href="Screen Shot 2022-07-24 at 17.19.22.png"><!-- 2216x834 -->
	  <img src="Screen Shot 2022-07-24 at 17.19.22_thumb.jpg" width="1000" height="376" style="border: 2px #ccc solid;" /></a>
      </center>
      <ul>
	<li>「エコー問題」解決！</li>
      </ul>
    </li>

    <li>音楽と数理 🎼 ♾ ポッドキャスト
      (<a href="https://anchor.fm/music-and-math">anchor.fm/music-and-math</a>)
      <center>
	<a href="Screen Shot 2022-07-24 at 17.16.06.png"><!-- 2785x1263 -->
	  <img src="Screen Shot 2022-07-24 at 17.16.06_thumb.jpg" width="1000" height="454" style="border: 2px #ccc solid;" /></a>
      </center>
      <ul>
	<li>ペースダウン気味（それでも週１でがんばってる）</li>
	<li>WordPress ページ
	  (<a href="https://music0math.wordpress.com/">music0math.wordpress.com</a>)
	  <center>
	    <a href="Screen Shot 2022-07-24 at 17.34.23.png"><!-- 2791x1254 -->
	      <img src="Screen Shot 2022-07-24 at 17.34.23_thumb.jpg" width="1000" height="449" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-07-24 at 17.35.07.png"><!-- 2787x1231 -->
	      <img src="Screen Shot 2022-07-24 at 17.35.07_thumb.jpg" width="1000" height="442" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>

      </ul>
    </li>

  </ul>

  <br /><br /><br /><center>...♦...</center><br /><br /><br />

  <ul>
    <li>つまり、前回の ZAF2206 開催（2022年6月29日）から
      今日（2022年7月27日）までの間のことですが
      <ul>
	<li>6/30 (Thu) RX8 買った<br />
	  (<a href="https://twitter.com/ichiki_k/status/1542310683362361344">https://twitter.com/ichiki_k/status/1542310683362361344</a>
	  <center>
	    <a href="Screen Shot 2022-07-27 at 14.56.01.png"><!-- 1275x1334 -->
	      <img src="Screen Shot 2022-07-27 at 14.56.01_thumb.jpg" width="600" height="317" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li>7/6 (Wed) 仙台の悪いニュースその１<br />
	  (<a href="https://twitter.com/ichiki_k/status/1544625208157384704">https://twitter.com/ichiki_k/status/1544625208157384704</a>)
	  <center>
	    <a href="Screen Shot 2022-07-27 at 14.57.13.png"><!-- 1281x636 -->
	      <img src="Screen Shot 2022-07-27 at 14.57.13_thumb.jpg" width="600" height="298" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-07-27 at 14.57.17.png"><!-- 1254x1215 -->
	      <img src="Screen Shot 2022-07-27 at 14.57.17_thumb.jpg" width="600" height="289" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li>7/7 (Thu) 仙台の悪いニュースその２<br />
	  (<a href="https://twitter.com/ichiki_k/status/1544869272866148352">https://twitter.com/ichiki_k/status/1544869272866148352</a>)
	  <center>
	    <a href="Screen Shot 2022-07-27 at 14.54.41.png"><!-- 1292x486 -->
	      <img src="Screen Shot 2022-07-27 at 14.54.41_thumb.jpg" width="600" height="226" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-07-27 at 14.54.46.png"><!-- 1288x1094 -->
	      <img src="Screen Shot 2022-07-27 at 14.54.46_thumb.jpg" width="600" height="202" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li>での、 7/8 (Fri)
	  <ul>
	    <li>朝は、コロナ増えてきてるぞっと思ってて<br />
	      (<a href="https://twitter.com/ichiki_k/status/1545227087564271617">https://twitter.com/ichiki_k/status/1545227087564271617</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 14.59.19.png"><!-- 1260x610 -->
		  <img src="Screen Shot 2022-07-27 at 14.59.19_thumb.jpg" width="600" height="290" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	    <li>お昼にニュースを目にして<br />
	      (<a href="https://twitter.com/ichiki_k/status/1545248696266137601">https://twitter.com/ichiki_k/status/1545248696266137601</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 15.00.11.png"><!-- 1261x542 -->
		  <img src="Screen Shot 2022-07-27 at 15.00.11_thumb.jpg" width="600" height="258" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	    <li>かなり動揺しているが、シブがき隊を口ずさみながら正気を保とうとする<br />
	      (<a href="https://twitter.com/ichiki_k/status/1545344405694869504">https://twitter.com/ichiki_k/status/1545344405694869504</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 15.01.00.png"><!-- 1267x709 -->
		  <img src="Screen Shot 2022-07-27 at 15.01.00_thumb.jpg" width="600" height="336" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	  </ul>
	</li>
	<li>7/10 (Sun) は、そうした中での選挙だが…<br />
	  (<a href="https://twitter.com/ichiki_k/status/1546092105046839296">https://twitter.com/ichiki_k/status/1546092105046839296</a>)
	  <center>
	    <a href="Screen Shot 2022-07-27 at 15.02.19.png"><!-- 1266x595 -->
	      <img src="Screen Shot 2022-07-27 at 15.02.19_thumb.jpg" width="600" height="282" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li>7/11 (Mon) 小さな、よいニュース<br />
	  (<a href="https://twitter.com/ichiki_k/status/1546341889854836736">https://twitter.com/ichiki_k/status/1546341889854836736</a>)
	  <center>
	    <a href="Screen Shot 2022-07-27 at 15.03.35.png"><!-- 1276x1087 -->
	      <img src="Screen Shot 2022-07-27 at 15.03.35_thumb.jpg" width="600" height="511" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-07-27 at 16.13.58.png"><!-- 901x882 -->
	      <img src="Screen Shot 2022-07-27 at 16.13.58_thumb.jpg" width="400" height="392" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-07-27 at 15.03.42.png"><!-- 1313x647 -->
	      <img src="Screen Shot 2022-07-27 at 15.03.42_thumb.jpg" width="600" height="296" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <ul>
	    <li><a href="https://en.wikipedia.org/wiki/Vulcan_salute">https://en.wikipedia.org/wiki/Vulcan_salute</a>
	    </li>
	  </ul>
	</li>
	<li>7/12 (Tue) は、音楽に救いを求めたのかな
	  <ul>
	    <li>Piano Jazz に Robert Glasper<br />
	      (<a href="https://twitter.com/ichiki_k/status/1546826365680644096">https://twitter.com/ichiki_k/status/1546826365680644096</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 15.05.11.png"><!-- 1260x771 -->
		  <img src="Screen Shot 2022-07-27 at 15.05.11_thumb.jpg" width="600" height="367" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	    <li>Piano Legends を YouTube に見つけた<br />
	      (<a href="https://twitter.com/ichiki_k/status/1546827012597514241">https://twitter.com/ichiki_k/status/1546827012597514241</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 15.05.46.png"><!-- 1263x880 -->
		  <img src="Screen Shot 2022-07-27 at 15.05.46_thumb.jpg" width="600" height="418" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	  </ul>
	</li>
	<li>7/13 (Wed) これ、知ってた？<br />
	  (<a href="https://twitter.com/ichiki_k/status/1547105650890932224">https://twitter.com/ichiki_k/status/1547105650890932224</a>)
	  <center>
	    <a href="Screen Shot 2022-07-27 at 15.07.05.png"><!-- 1278x596 -->
	      <img src="Screen Shot 2022-07-27 at 15.07.05_thumb.jpg" width="600" height="280" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <ul>
	    <li>ドヤ？<br />
	      <audio preload="metadata" controls>
		<source src="20220722-03.wav" type="audio/wav" />
	      </audio>
	    </li>
	  </ul>
	</li>

	<li>7/15 (Fri) には
	  <ul>
	    <li>しばらく注視してた stopcovid サイトが再び真っ黒に<br />
	      (<a href="https://twitter.com/ichiki_k/status/1547747482004000768">https://twitter.com/ichiki_k/status/1547747482004000768</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 15.09.04.png"><!-- 1279x1146 -->
		  <img src="Screen Shot 2022-07-27 at 15.09.04_thumb.jpg" width="600" height="538" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	    <li>今回の出来事から、教訓を学びとろうとしたり<br />
	      (<a href="https://twitter.com/ichiki_k/status/1547789669420924928">https://twitter.com/ichiki_k/status/1547789669420924928</a>,<br />
	      <a href="https://twitter.com/ichiki_k/status/1547790081481932802">https://twitter.com/ichiki_k/status/1547790081481932802</a>,<br />
	      <a href="https://twitter.com/ichiki_k/status/1547792270908600321">https://twitter.com/ichiki_k/status/1547792270908600321</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 15.09.43.png"><!-- 1262x556 -->
		  <img src="Screen Shot 2022-07-27 at 15.09.43_thumb.jpg" width="600" height="264" style="border: 2px #ccc solid;" /></a>
		<a href="Screen Shot 2022-07-27 at 15.09.54.png"><!-- 1259x598 -->
		  <img src="Screen Shot 2022-07-27 at 15.09.54_thumb.jpg" width="600" height="285" style="border: 2px #ccc solid;" /></a>
		<a href="Screen Shot 2022-07-27 at 15.10.27.png"><!-- 1264x651 -->
		  <img src="Screen Shot 2022-07-27 at 15.10.27_thumb.jpg" width="600" height="309" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	    <li>あと、いつも言ってる「追悼版ビジネス」嫌いのコメント<br />
	      (<a href="https://twitter.com/ichiki_k/status/1547873191561170944">https://twitter.com/ichiki_k/status/1547873191561170944</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 16.31.01.png"><!-- 1278x657 -->
		  <img src="Screen Shot 2022-07-27 at 16.31.01_thumb.jpg" width="600" height="308" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	  </ul>
	</li>

	<li>7/16 (Sat) がんばって Twitch したぜ<br />
	  (<a href="https://twitter.com/ichiki_k/status/1548170571258929152">https://twitter.com/ichiki_k/status/1548170571258929152</a>)
	  <center>
	    <a href="Screen Shot 2022-07-27 at 16.33.35.png"><!-- 1297x658 -->
	      <img src="Screen Shot 2022-07-27 at 16.33.35_thumb.jpg" width="600" height="304" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-07-27 at 15.12.36.png"><!-- 1273x920 -->
	      <img src="Screen Shot 2022-07-27 at 15.12.36_thumb.jpg" width="600" height="434" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>

	<li>7/18 (Mon)
	  <ul>
	    <li>現状を分析（するともなく）してみたり<br />
	      (<a href="https://twitter.com/ichiki_k/status/1548843417178112000">https://twitter.com/ichiki_k/status/1548843417178112000</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 15.14.18.png"><!-- 1255x1014 -->
		  <img src="Screen Shot 2022-07-27 at 15.14.18_thumb.jpg" width="600" height="485" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	    <li>みんな、基本、冷たいよね、と
	      （世の中、後出しジャンケン野郎ばっかだよねぇ）<br />
	      (<a href="https://twitter.com/ichiki_k/status/1548843988819804160">https://twitter.com/ichiki_k/status/1548843988819804160</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 15.14.34.png"><!-- 1267x596 -->
		  <img src="Screen Shot 2022-07-27 at 15.14.34_thumb.jpg" width="600" height="282" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	    <li>なにができるか、と考えたり<br />
	      (<a href="https://twitter.com/ichiki_k/status/1548917688856346624">https://twitter.com/ichiki_k/status/1548917688856346624</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 15.15.59.png"><!-- 1273x596 -->
		  <img src="Screen Shot 2022-07-27 at 15.15.59_thumb.jpg" width="600" height="281" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	  </ul>
	</li>

	<li>7/20 (Wed)
	  <ul>
	    <li>アナーキーな宗教（？）<br />
	      （ポッドキャストでもしゃべったとおり、ぼくは今年に入ったくらいから仏教ブームが来てる）<br />
	      (<a href="https://twitter.com/ichiki_k/status/1549599666647445504">https://twitter.com/ichiki_k/status/1549599666647445504</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 15.17.24.png"><!-- 1285x660 -->
		  <img src="Screen Shot 2022-07-27 at 15.17.24_thumb.jpg" width="600" height="308" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	    <li>なにがヤバいのか、振り返りつつ<br />
	      (<a href="https://twitter.com/ichiki_k/status/1549623803487014912">https://twitter.com/ichiki_k/status/1549623803487014912</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 15.18.15.png"><!-- 1269x954 -->
		  <img src="Screen Shot 2022-07-27 at 15.18.15_thumb.jpg" width="600" height="451" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	  </ul>
	</li>

	<li>7/21 (Thu)
	  絶対予定不調和（あれね、即興的人生というか、セレンディピティというか）<br />
	  (<a href="https://twitter.com/ichiki_k/status/1550024553866620928">https://twitter.com/ichiki_k/status/1550024553866620928</a>)
	  <center>
	    <a href="Screen Shot 2022-07-27 at 15.19.53.png"><!-- 1282x827 -->
	      <img src="Screen Shot 2022-07-27 at 15.19.53_thumb.jpg" width="600" height="387" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-07-27 at 15.20.00.png"><!-- 1291x1311 -->
	      <img src="Screen Shot 2022-07-27 at 15.20.00_thumb.jpg" width="591" height="600" style="border: 2px #ccc solid;" /></a>
	    <a href="Screen Shot 2022-07-27 at 15.20.07.png"><!-- 1309x273 -->
	      <img src="Screen Shot 2022-07-27 at 15.20.07_thumb.jpg" width="600" height="125" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>

	<li>7/23 (Sat)
	  <ul>
	    <li>金沢経済新聞<br />
	      (<a href="https://twitter.com/ichiki_k/status/1550641535305551872">https://twitter.com/ichiki_k/status/1550641535305551872</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 15.22.53.png"><!-- 1282x831 -->
		  <img src="Screen Shot 2022-07-27 at 15.22.53_thumb.jpg" width="600" height="389" style="border: 2px #ccc solid;" /></a>
		<a href="https://x.zenkei.biz/0383rfQfnFLg-c5M1">
		  <img src="Screen Shot 2022-07-27 at 16.52.08_thumb.jpg" width="1000" height="277" style="border: 2px #ccc solid;" /></a>
	      </center>
	      <ul>
		<li>これ、ツイッターで話題になってましたよね<br />
		  (<a href="https://twitter.com/FurattoKanazawa/status/1550085957004578817">https://twitter.com/FurattoKanazawa/status/1550085957004578817</a>)
		  <center>
		    <a href="Screen Shot 2022-07-27 at 16.49.19.png"><!-- 1311x1223 -->
		      <img src="Screen Shot 2022-07-27 at 16.49.19_thumb.jpg" width="600" height="560" style="border: 2px #ccc solid;" /></a>
		  </center>
		</li>
	      </ul>
	    </li>
	    <li>当社比的に、前回のピークをかる〜く超えて行った<br />
	      (<a href="https://twitter.com/ichiki_k/status/1550643415721070592">https://twitter.com/ichiki_k/status/1550643415721070592</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 15.23.41.png"><!-- 1265x1096 -->
		  <img src="Screen Shot 2022-07-27 at 15.23.41_thumb.jpg" width="600" height="520" style="border: 2px #ccc solid;" /></a>
		<a href="Screen Shot 2022-07-27 at 15.23.47.png"><!-- 2124x1091 -->
		  <img src="Screen Shot 2022-07-27 at 15.23.47_thumb.jpg" width="600" height="308" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	    <li>「正語」「正語」と唱えたり<br />
	      (<a href="https://twitter.com/ichiki_k/status/1550678305866940416">https://twitter.com/ichiki_k/status/1550678305866940416</a>)
	      <center>
		<a href="Screen Shot 2022-07-27 at 15.24.11.png"><!-- 1274x698 -->
		  <img src="Screen Shot 2022-07-27 at 15.24.11_thumb.jpg" width="600" height="329" style="border: 2px #ccc solid;" /></a>
	      </center>
	    </li>
	  </ul>
	</li>

	<li>7/24 (Sun)
	  この一月を振り返ったり<br />
	  (<a href="https://twitter.com/ichiki_k/status/1551146220357582848">https://twitter.com/ichiki_k/status/1551146220357582848</a>)
	  <center>
	    <a href="Screen Shot 2022-07-27 at 15.25.49.png"><!-- 1272x650 -->
	      <img src="Screen Shot 2022-07-27 at 15.25.49_thumb.jpg" width="600" height="307" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>

      </ul>
    </li>

  </ul>

  <br /><br /><br /><center>...♦...</center><br /><br /><br />

  <center>
    <div style="font-size: 50px; font-weight: bolder;">
      結局、今ここでオレは、何が言いたいのか？
    </div>
  </center>

  <br /><br /><br /><br /><br /><br />

  <center>
    <div style="font-size: 40px; font-weight: bolder;">
      世の中には、分業していいことと、悪いことがある
      <br />
      ということを改めて言いたい。
    </div>
  </center>

  <ul>
    <li>ぼくの日記のまとめのページ<br />
      (<a href="https://kichiki.github.io/diary/summaries.html">https://kichiki.github.io/diary/summaries.html</a>)<br />
      そのなかの「教育について」<br />
      (<a href="https://kichiki.github.io/diary/summaries.html#education">https://kichiki.github.io/diary/summaries.html#education</a>)
      <center>
	<a href="Screen Shot 2022-07-27 at 16.58.28.png"><!-- 1742x1434 -->
	  <img src="Screen Shot 2022-07-27 at 16.58.28_thumb.jpg" width="600" height="494" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-07-27 at 15.29.03.png"><!-- 1582x886 -->
	  <img src="Screen Shot 2022-07-27 at 15.29.03_thumb.jpg" width="600" height="336" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>
    <li>そのなかのエントリーとして
      「<a href="https://kichiki.github.io/diary/diary2003_06.html#d3-bibou">6/3/2003: 分業してはいけないもの</a>」
      <center>
	<a href="Screen Shot 2022-07-27 at 15.31.37.png"><!-- 1866x460 -->
	  <img src="Screen Shot 2022-07-27 at 15.31.37_thumb.jpg" width="1000" height="247" style="border: 2px #ccc solid;" /></a>
      </center>
      <ul>
	<li>（引用）</li>
	<li>分業してはいけないものは、あると思う。
	  <ul>
	    <li>考えること (ってのは一般的すぎるが) とか、 教育とか</li>
	    <li>本当の意味で考えることを学ぶ高等教育について、
	      その高等教育のプロってのはダメなんではないだろうか</li>
	    <li>政治のプロってのも、何か間違っている気がするが、どうなのかな
	      <ul>
		<li>食べるために政治をしては、やっぱりいけない気がする</li>
	      </ul>
	    </li>
	  </ul>
	</li>
      </ul>
    </li>

  </ul>

  <center>
    <div style="font-size: 40px; font-weight: bolder;">
      （結論）
      <br />
      自分の人生に、手を抜くな
      <br />
      ということかな
    </div>
  </center>

  <br /><br /><br /><br /><br /><br />

  <center>
    <div style="font-size: 30px; font-weight: bolder;">
      オレは、オレの人生に、手を抜いて無いか？
    </div>
    <br />
    <div style="font-size: 28px;">
      （自問自答 - つまり、ブーメランってやつね）
    </div>
  </center>

  <br /><br /><br /><br /><br /><br />

  <center>
    <div style="font-size: 30px; font-weight: bolder;">
      そんなこといっても、<br />
      面倒じゃない？
    </div>
    <br /><br />
    <div style="font-size: 40px; font-weight: bolder;">
      そりゃ、もちろん、面倒だよ、ね
    </div>
  </center>

  <ul>
    <li>実際問題、
      <ul>
	<li><b>カルト</b>とか、<b>マルチ</b>とか、詐欺とか、あれやこれや、
	  いちいち気にしながら生きていくのは</li>
	<li>音楽聴くにも、例えば、チックのこと考えると
	  <b>サイエントロジ</b>のこと考えるし
	  <ul>
	    <li>どこまで関わってたのか？とか</li>
	    <li>そういえば、その昔の音楽雑誌『Jazz Life』には
	      サイエントロジの宣伝載ってたからね</li>
	    <li>（チックは、しかし、何考えてたんだろうな？）</li>
	    <li>この間も Lee Konitz の自伝読んでたら、
	      彼もときどきサイエントロジのセミナー受けてたとかあったり</li>
	    <li>キースはグルジェフで、ハービーとウェインは池田大作でしょ、
	      あー面倒くさい</li>
	  </ul>
	</li>
      </ul>
    </li>
    <li>金沢に来て１０年以上なるけど、
      <ul>
	<li>その間、大人のサークル活動みたいな感じで
	  「<b>英会話サークル</b>」やってきた。</li>
	<li>貸し会議室とか借りてた頃、
	  <ul>
	    <li>隣でやってる集まりが、<b>宗教関係の人たち</b>が（そうとは言わずに）
	      <b>交流会</b>みたいなのやってたり、</li>
	    <li>お堅いところに勤めてる若い子が、
	      <b>副業</b>とかいって<b>マルチ</b>やってたり、</li>
	  </ul>
	  なんかね、下を見ればキリがない
	</li>
      </ul>
    </li><!-- 面倒だよ -->
  </ul>

  <br /><br /><br /><center>...♦...</center><br /><br /><br />

  <center>
    <div style="font-size: 30px; font-weight: bolder;">
      ならば、どうするか？
    </div>
    <br /><br />
    <div style="font-size: 40px; font-weight: bolder;">
      「自分で考える」というスキルは大事
    </div>
  </center>

  <ul>
    <li><b>科学的視点</b>や<b>科学的方法</b>は、
      やっぱり、なんだかんだ言って、大事だと思う
      <ul>
	<li><b>いまの日本の、要所要所に、一番欠けているところだと思う</b></li>
      </ul>
    </li>
    <li><b>科学的視点</b>や<b>科学的方法</b>とは、何か？</li>
    <li>結局のところは「<b>再現性</b>」に拠っているところかな
      <ul>
	<li>誰でも（<b>素人でも</b>）手順通り行えば、
	  <b>同じことができる</b>という情報の蓄積</li>
	<li>「魔法」とか「アート」とかいうものと、言ってみれば逆のもの
	  <ul>
	    <li>エンジニアの人には、「属人化」と言えば、何が悪か、分かると思う</li>
	  </ul>
	</li>
      </ul>
    </li>
    <li>ここから必然的に（自然に）
      <ul>
	<li><b>情報の公開、共有</b>
	  （再現性を確認するには、その手順が分からないとできない）</li>
	<li><b>判断基準の明確化</b>
	  （威張ることで黙らせる「権威」の排除）</li>
      </ul>
      が出てくる
      <ul>
	<li>この辺が、<b>いまの日本の、要所要所に、一番欠けているところだと思う</b>
	  （パート２）</li>
      </ul>
    </li><!-- 「自分で考える」というスキルは大事 -->
  </ul>

  <center>
    <div style="font-size: 40px; font-weight: bolder;">
      （結論）<br />
      いまの日本には
    </div>
    <br /><br />
    <div style="font-size: 50px; font-weight: bolder;">
      科学的視点　や　科学的方法
    </div>
    <br /><br />
    <div style="font-size: 40px; font-weight: bolder;">
      が求められている！
    </div>
  </center>

  <br /><br /><br /><br /><br /><br />

  <center>
    <div style="font-size: 40px; font-weight: bolder;">
      つまり
    </div>
    <br /><br />
    <div style="font-size: 60px; font-weight: bolder;">
      ZENKEI AI FORUM
    </div>
    <br /><br />
    <div style="font-size: 40px; font-weight: bolder;">
      が求められている！
    </div>
  </center>

  <ul>
    <li>はい、我田引水でした。</li>
    <li>とはいえ、半分以上は本気で言ってます。</li>
  </ul>

  <br /><br /><br /><center>...♦...</center><br /><br /><br />

  <center>
    <div style="font-size: 40px; font-weight: bolder;">
      前座を終わる前に、<br />
      ひとことだけ
    </div>
  </center>

  <ul>
    <li>コミュニティ志向に関して
      <ul>
	<li>「ファンダム・エコノミー」とか、
	  最近、フォーラムでも取り上げているトピック</li>
      </ul>
    </li>
    <li>高須正和さん翻訳の本『遠くへ行きたければ、みんなで行け』
      <center>
	<a href="Screen Shot 2022-07-27 at 15.47.46.png"><!-- 1724x782 -->
	  <img src="Screen Shot 2022-07-27 at 15.47.46_thumb.jpg" width="600" height="272" style="border: 2px #ccc solid;" /></a>
      </center>
      <ul>
	<li>この本の原題は "People Powered"
	  <ul>
	    <li>力を持った人々、
	      人々に力を、と言った感じのニュアンス</li>
	  </ul>
	</li>
	<li>この本の最初の部分で明確に、
	  <center>
	    <div style="font-size: 40px; font-weight: bolder;">
	      このテクニック（スキル）は、<br />
	      カルト的な集団においても利用されうるもの
	    </div>
	  </center>
	  との注意があった。
	</li>
	<li>今の状況を考えると、肝に銘じておきたいポイントです。</li>

      </ul>
    </li><!-- コミュニティ志向に関して -->

    <li>しかし、人の弱みに付け込む集団の活動ってのは、なんとかならんかなぁ
      <ul>
	<li>多様性を尊重する（個人的要素の強い人々）が、
	  どうやって集団になってかかってくる相手に、対抗していけば、
	  いいんでしょうね？</li>
	<li>脳内実験的に、 SF を考えたりしますが、<br />
	  スタートレックというのは、そういう環境を提供してくれていると思う。</li>
	<li>新作のピカードでもテーマになった「ボーグ」が、
	  なんかやっぱりいつも頭によぎる。名案はない。</li>
      </ul>
    </li>

  </ul>

  <br /><br /><br /><center>...♦...</center><br /><br /><br />

  <hr />

  <center id="part1">
    <div style="font-size: 50px; font-weight: bolder;">
      <br />
      パート１
      この１ヶ月の AI の話題から
    </div>
  </center>

  <p>人事的な話</p>
  <ul>
    <li><a href="https://twitter.com/shinya_elix/status/1547423905912356864">https://twitter.com/shinya_elix/status/1547423905912356864</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.25.15.png"><!-- 1182x812 -->
	  <img src="Screen Shot 2022-07-24 at 18.25.15_thumb.jpg" width="400" height="275" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Andrej Karpathyがテスラを退社か〜。具体的に次に何をするかは特に決まっていないとのこと。
      </pre>
    </li>

    <li><a href="https://twitter.com/goodfellow_ian/status/1544638709039091717">https://twitter.com/goodfellow_ian/status/1544638709039091717</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.46.06.png"><!-- 1177x166 -->
	  <img src="Screen Shot 2022-07-24 at 18.46.06_thumb.jpg" width="1000" height="141" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
I'm excited to announce that I've joined DeepMind! 
I'll be a research scientist in @OriolVinyalsML  's Deep Learning team.
      </pre>
    </li>

  </ul>

  <p>DALLE 関係</p>

  <ul>
    <li><a href="https://twitter.com/wayama_ryousuke/status/1549911872513589248">https://twitter.com/wayama_ryousuke/status/1549911872513589248</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.07.46.png"><!-- 1182x891 -->
	  <img src="Screen Shot 2022-07-24 at 18.07.46_thumb.jpg" width="400" height="302" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
dalle2有償ベータ公開。最初の月だけ50回、その後毎月15回まで無料クレジットで生成できるように。
1クレジットで1回（生成で4枚、バリエーションで3枚）。15ドルで115クレジット購入できる。
無料、有料問わず商用利用可能。プロンプト探索がはかどりそう

https://openai.com/blog/dall-e-now-available-in-beta/
      </pre>
      <ul>
	<li><a href="https://openai.com/blog/dall-e-now-available-in-beta/">https://openai.com/blog/dall-e-now-available-in-beta/</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.08.33.png"><!-- 2786x646 -->
	      <img src="Screen Shot 2022-07-24 at 18.08.33_thumb.jpg" width="1000" height="232" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/VictoriaCarr_/status/1549428789951741955">https://twitter.com/VictoriaCarr_/status/1549428789951741955</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 21.33.06.png"><!-- 1189x958 -->
	  <img src="Screen Shot 2022-07-24 at 21.33.06_thumb.jpg" width="400" height="322" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Found a tool that converts any scientific jargon to plain English built on GPT-3.

Having a play around and it's pretty good! 

https://explainjargon.com
      </pre>
      <ul>
	<li><a href="https://explainjargon.com">https://explainjargon.com</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.09.53.png"><!-- 2761x551 -->
	      <img src="Screen Shot 2022-07-24 at 18.09.53_thumb.jpg" width="1000" height="200" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/fladdict/status/1548297398715580418">https://twitter.com/fladdict/status/1548297398715580418</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.19.51.png"><!-- 1183x1017 -->
	  <img src="Screen Shot 2022-07-24 at 18.19.51_thumb.jpg" width="700" height="602" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
AIに描かせたポスターの比較。すでに構図やリズムを理解しつつある。5年後にはどうなってしまうのか。

・スイスモダンのネコ
・ダッチモダンのネコ
・ドイツ構成主義のネコ
・ロシア構成主義のネコ

#dalle2
      </pre>
    </li>

    <li><a href="https://twitter.com/gijigae/status/1546295641583718401">https://twitter.com/gijigae/status/1546295641583718401</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.31.42.png"><!-- 1188x544 -->
	  <img src="Screen Shot 2022-07-24 at 18.31.42_thumb.jpg" width="400" height="183" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
GPT-3を利用して正規表現を書いてくれるサービス（👉https://autoregex.xyz/home）が登場😮。
いくつか試してみたけどかなり優秀👏。
これで正規表現を書くハードルも格段と下がる。無料で使えますのでぜひ！
      </pre>
      <ul>
	<li><a href="https://autoregex.xyz/home">https://autoregex.xyz/home</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.32.03.png"><!-- 2789x1083 -->
	      <img src="Screen Shot 2022-07-24 at 18.32.03_thumb.jpg" width="1000" height="388" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>


    <li><a href="https://twitter.com/masafumi/status/1544693645080956928">https://twitter.com/masafumi/status/1544693645080956928</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.41.14.png"><!-- 1192x502 -->
	  <img src="Screen Shot 2022-07-24 at 18.41.14_thumb.jpg" width="400" height="168" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Facebook AI Researchからえらいもんきたなぁ。

No Language Left Behind: Scaling Human-Centered Machine Translation
https://research.facebook.com/publications/no-language-left-behind/

Code
https://github.com/facebookresearch/fairseq/tree/nllb
      </pre>
      <ul>
	<li><a href="https://research.facebook.com/publications/no-language-left-behind/">https://research.facebook.com/publications/no-language-left-behind/</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.41.57.png"><!-- 2786x712 -->
	      <img src="Screen Shot 2022-07-24 at 18.41.57_thumb.jpg" width="1000" height="256" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/AntoineBordes/status/1544739329590845441">https://twitter.com/AntoineBordes/status/1544739329590845441</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.44.20.png"><!-- 1183x720 -->
	  <img src="Screen Shot 2022-07-24 at 18.44.20_thumb.jpg" width="400" height="243" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Today we open-source No Language Left Behind: 
a single model that translates 200 languages.
Game changer for people that could not access information
because of language barrier. Part of the AI system already powering
25 billion translations every day across @meta platforms!
      </pre>
    </li>


    <li><a href="https://twitter.com/MetaAI/status/1544730979964784643">https://twitter.com/MetaAI/status/1544730979964784643</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.47.11.png"><!-- 1182x203 -->
	  <img src="Screen Shot 2022-07-24 at 18.47.11_thumb.jpg" width="400" height="69" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
(1/4) Results from our No Language Left Behind (NLLB) project
are not only advancing state-of-the-art in machine translations,
but also enabling us to help improve translation systems
inside and outside of Meta. Here’s how:
      </pre>
    </li>

    <li><a href="https://twitter.com/MetaAI/status/1544670269469507585">https://twitter.com/MetaAI/status/1544670269469507585</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.48.23.png"><!-- 1177x207 -->
	  <img src="Screen Shot 2022-07-24 at 18.48.23_thumb.jpg" width="400" height="70" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Check out our latest breakthrough in machine translation that
Mark Zuckerberg just announced. We built and open sourced
a state-of-the-art AI model that now translates
between 200 different languages.
      </pre>
    </li>


    <li><a href="https://twitter.com/jaguring1/status/1544154692028354560">https://twitter.com/jaguring1/status/1544154692028354560</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.52.06.png"><!-- 1191x858 -->
	  <img src="Screen Shot 2022-07-24 at 18.52.06_thumb.jpg" width="400" height="288" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
AIは汎用性が高まり始めてます（今月はPaLMをベースにMinervaも登場）

AI開発の新たなパラダイム「基盤モデル」とは
https://blog.recruit.co.jp/data/articles/foundation_models/
『基盤モデルとは「大量・多様なデータから高い汎化性能を獲得したAI」のことで、
2021年にスタンフォード大学のワーキンググループによって命名されました』
      </pre>
      <ul>
	<li><a href="https://blog.recruit.co.jp/data/articles/foundation_models/">https://blog.recruit.co.jp/data/articles/foundation_models/</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.52.27.png"><!-- 2791x1087 -->
	      <img src="Screen Shot 2022-07-24 at 18.52.27_thumb.jpg" width="1000" height="389" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>

	<li><a href="https://twitter.com/shion_honda/status/1543843594691551232">https://twitter.com/shion_honda/status/1543843594691551232</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.54.06.png"><!-- 1184x378 -->
	      <img src="Screen Shot 2022-07-24 at 18.54.06_thumb.jpg" width="400" height="128" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <pre>
GPT-3やDALL-Eなどで近年注目を集めている「基盤モデル」について、
現時点でわかっている性質や代表的なモデル、課題と将来の展望をまとめました
（@kaggle_araisan さんとの共同執筆）。
できる限り専門用語を排して書いたので、多くの人に届くと嬉しいです。

https://blog.recruit.co.jp/data/articles/foundation_models/
	  </pre>
	</li>

      </ul>
    </li>

  </ul>

  <p>未整理</p>

  <ul>
    <li><a href="https://twitter.com/_akhaliq/status/1550865091771465728">https://twitter.com/_akhaliq/status/1550865091771465728</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.00.48.png"><!-- 1196x603 -->
	  <img src="Screen Shot 2022-07-24 at 18.00.48_thumb.jpg" width="400" height="202" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Omni3D: A Large Benchmark and Model for 3D Object Detection in the Wild
abs: https://arxiv.org/abs/2207.10660
github: https://github.com/facebookresearch/omni3d
project page: https://garrickbrazil.com/omni3d/
      </pre>
      <ul>
	<li><a href="https://garrickbrazil.com/omni3d/">https://garrickbrazil.com/omni3d/</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.01.44.png"><!-- 2791x1044 -->
	      <img src="Screen Shot 2022-07-24 at 18.01.44_thumb.jpg" width="1000" height="374" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>


    <li><a href="https://twitter.com/elepiech/status/1550123962301960192">https://twitter.com/elepiech/status/1550123962301960192</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.02.41.png"><!-- 1183x823 -->
	  <img src="Screen Shot 2022-07-24 at 18.02.41_thumb.jpg" width="400" height="278" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Three words: Markerless Motion Capture 🤯 

This is a 9-person #mocap test, all WITHOUT suits!

Happy I have the chance to experiment with tools like <a href="http://Move.ai">http://Move.ai</a>.
I'm even more excited to see how these tools can be used
to democratize 3D content creation.
      </pre>
    </li>

    <li><a href="https://twitter.com/_akhaliq/status/1550454957161201669">https://twitter.com/_akhaliq/status/1550454957161201669</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.03.22.png"><!-- 1177x793 -->
	  <img src="Screen Shot 2022-07-24 at 18.03.22_thumb.jpg" width="400" height="269" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
a @Gradio Demo for CogVideo: Large-scale Pretraining for
Text-to-Video Generation via Transformers is now on 
@huggingface Spaces by https://huggingface.co/hysts

demo: https://huggingface.co/spaces/THUDM/CogVideo

https://huggingface.co/spaces/THUDM/CogVideo
      </pre>
      <ul>
	<li><a href="https://huggingface.co/spaces/THUDM/CogVideo">https://huggingface.co/spaces/THUDM/CogVideo</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.03.55.png"><!-- 2781x1221 -->
	      <img src="Screen Shot 2022-07-24 at 18.03.55_thumb.jpg" width="1000" height="439" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/psyth91/status/1550466746301177856">https://twitter.com/psyth91/status/1550466746301177856</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.04.09.png"><!-- 1177x700 -->
	  <img src="Screen Shot 2022-07-24 at 18.04.09_thumb.jpg" width="400" height="238" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
📢Looking for real-time drivable volumetric avatars? 
Check out out #SIGGRAPH 2022 paper, DVA!!

We extend Mixture of Volumetric Primitives [Lombardi+ 2021] 
to articulated human bodies to enable real-time/high-fidelity 
rendering of clothed human!
PDF: https://arxiv.org/abs/2207.09774
      </pre>
    </li>

    <li><a href="https://twitter.com/shiropen2/status/1550264836852174848">https://twitter.com/shiropen2/status/1550264836852174848</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.05.00.png"><!-- 1187x574 -->
	  <img src="Screen Shot 2022-07-24 at 18.05.00_thumb.jpg" width="400" height="193" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
手書きした絵コンテの人物画を3Dキャラクターに自動変換する「Sketch2Pose」　
不自然なポーズも自動修正 https://levtech.jp/media/article/column/detail_105/ 
手書きスケッチの2D人物画から3Dキャラクタポーズを再構築する。
身体部位の長さや関節位置がおかしいなどのバランスが取れていない絵でも
自然なポーズに補正し再現する。

https://levtech.jp/media/article/column/detail_105/

http://www-labs.iro.umontreal.ca/~bmpix/sketch2pose/
      </pre>
      <ul>
	<li><a href="https://levtech.jp/media/article/column/detail_105/">https://levtech.jp/media/article/column/detail_105/</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.06.14.png"><!-- 2794x1093 -->
	      <img src="Screen Shot 2022-07-24 at 18.06.14_thumb.jpg" width="1000" height="391" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li><a href="http://www-labs.iro.umontreal.ca/~bmpix/sketch2pose/">http://www-labs.iro.umontreal.ca/~bmpix/sketch2pose/</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.06.26.png"><!-- 2775x685 -->
	      <img src="Screen Shot 2022-07-24 at 18.06.26_thumb.jpg" width="1000" height="247" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/ogawa_yutaro_22/status/1549858278699663360">https://twitter.com/ogawa_yutaro_22/status/1549858278699663360</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.10.28.png"><!-- 1186x471 -->
	  <img src="Screen Shot 2022-07-24 at 18.10.28_thumb.jpg" width="400" height="159" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
DeepMindより。
Transformerについて、丁寧に解説し直したサマリーペーパーです
分かりやすい構成でした

Formal Algorithms for Transformers

https://arxiv.org/abs/2207.09238

Formal Algorithms for Transformers
Mary Phuong, Marcus Hutter


      </pre>
      <ul>
	<li><a href="https://arxiv.org/abs/2207.09238">https://arxiv.org/abs/2207.09238</a> (<a href="arxiv-2207.09238-FormalAlgorithmsForTransformers.pdf">local copy</a>)
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.11.23.png"><!-- 2181x551 -->
	      <img src="Screen Shot 2022-07-24 at 18.11.23_thumb.jpg" width="1000" height="253" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/luisenp/status/1549781249652310016">https://twitter.com/luisenp/status/1549781249652310016</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.11.55.png"><!-- 1191x574 -->
	  <img src="Screen Shot 2022-07-24 at 18.11.55_thumb.jpg" width="400" height="193" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-07-24 at 18.11.59.png"><!-- 1172x580 -->
	  <img src="Screen Shot 2022-07-24 at 18.11.59_thumb.jpg" width="400" height="198" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Happy to release Theseus today, the result of months of effort
with an amazing team of collaborators!
https://sites.google.com/view/theseus-ai/

Theseus makes it easy to include structured optimization problems and
second order optimizers as differentiable layers in your end-to-end
architectures.

https://sites.google.com/view/theseus-ai/

https://twitter.com/mhmukadam/status/1549773856738615297

Thrilled to release Theseus, a library to build custom nonlinear
optimization layers in PyTorch.

https://sites.google.com/view/theseus-ai

Nonlinear least squares is at the heart of many robotics and vision problems.
Now we can add such structures in our end-to-end architectures.
      </pre>
      <ul>
	<li><a href="https://sites.google.com/view/theseus-ai/">https://sites.google.com/view/theseus-ai/</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.12.25.png"><!-- 2762x707 -->
	      <img src="Screen Shot 2022-07-24 at 18.12.25_thumb.jpg" width="1000" height="256" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/_akhaliq/status/1549841365814632452">https://twitter.com/_akhaliq/status/1549841365814632452</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.13.16.png"><!-- 1178x671 -->
	  <img src="Screen Shot 2022-07-24 at 18.13.16_thumb.jpg" width="400" height="228" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Highly Accurate Dichotomous Image Segmentation
abs: https://arxiv.org/abs/2203.03041
project page: https://xuebinqin.github.io/dis/index.html
Gradio Demo: https://huggingface.co/spaces/ECCV2022/dis-background-removal

https://huggingface.co/spaces/ECCV2022/dis-background-removal
      </pre>
      <ul>
	<li><a href="https://huggingface.co/spaces/ECCV2022/dis-background-removal">https://huggingface.co/spaces/ECCV2022/dis-background-removal</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.13.38.png"><!-- 2790x985 -->
	      <img src="Screen Shot 2022-07-24 at 18.13.38_thumb.jpg" width="1000" height="353" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/SergeyTulyakov/status/1549227157120880640">https://twitter.com/SergeyTulyakov/status/1549227157120880640</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.14.34.png"><!-- 1191x543 -->
	  <img src="Screen Shot 2022-07-24 at 18.14.34_thumb.jpg" width="400" height="182" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Wondering how to run NeRF fast? Convert them to light fields!

In our #ECCV2022 paper, R2L, we train a student network that evaluates
the whole ray once, and thus avoids costly sampling, making it 30x faster.
Besides it also shows better fidelity that the teacher network.
      </pre>
    </li>

    <li><a href="https://twitter.com/eozakharov/status/1549110914754007041">https://twitter.com/eozakharov/status/1549110914754007041</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.14.58.png"><!-- 1191x858 -->
	  <img src="Screen Shot 2022-07-24 at 18.14.58_thumb.jpg" width="400" height="288" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Am very excited to share our new work on realistic avatars,
which was recently accepted to ACM Multimedia! 😊 
Huge props and congratulations to Nikita @NikDrob23 ,
you did an amazing job!  More results on our project
page: http://bit.ly/3yR6w2p

https://samsunglabs.github.io/MegaPortraits/
      </pre>
      <ul>
	<li><a href="https://samsunglabs.github.io/MegaPortraits/">https://samsunglabs.github.io/MegaPortraits/</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.15.25.png"><!-- 2766x1194 -->
	      <img src="Screen Shot 2022-07-24 at 18.15.25_thumb.jpg" width="1000" height="432" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
	<li><a href="https://twitter.com/_akhaliq/status/1548952855800946689">https://twitter.com/_akhaliq/status/1548952855800946689</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.17.18.png"><!-- 1196x541 -->
	      <img src="Screen Shot 2022-07-24 at 18.17.18_thumb.jpg" width="400" height="181" style="border: 2px #ccc solid;" /></a>
	  </center>
	  <pre>
MegaPortraits: One-shot Megapixel Neural Head Avatars
abs: https://arxiv.org/abs/2207.07621
	  </pre>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/Maxwell_110/status/1548106389012336640">https://twitter.com/Maxwell_110/status/1548106389012336640</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.21.11.png"><!-- 1180x951 -->
	  <img src="Screen Shot 2022-07-24 at 18.21.11_thumb.jpg" width="400" height="322" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
今週末は時間を確保して YOLOv7 の論文を読みたい 📝

YOLO は一種のブランドのようになっちゃっていて，海賊版みたいなのが横行している状況

でも，どうやら今回は official っぽい

https://github.com/WongKinYiu/yolov7

Redmon が引退した今，何をもって official と判断するのかはよく分からないけど
      </pre>
    </li>

    <li><a href="https://twitter.com/radamar/status/1548108083015979009">https://twitter.com/radamar/status/1548108083015979009</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.21.50.png"><!-- 1184x993 -->
	  <img src="Screen Shot 2022-07-24 at 18.21.50_thumb.jpg" width="400" height="335" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Here's an experimental drawing tool I made to interact with 
the Text2Human generative model capable of generating humans
with clothes and textures. Playing with it and pretending
to be a fashion designer is fun. by @Jiang_Yuming et al. @huggingface

https://huggingface.co/spaces/CVPR/drawings-to-human
      </pre>
      <ul>
	<li><a href="https://huggingface.co/spaces/CVPR/drawings-to-human">https://huggingface.co/spaces/CVPR/drawings-to-human</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.22.13.png"><!-- 2781x1164 -->
	      <img src="Screen Shot 2022-07-24 at 18.22.13_thumb.jpg" width="1000" height="419" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/_akhaliq/status/1547762012050010116">https://twitter.com/_akhaliq/status/1547762012050010116</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.22.30.png"><!-- 1188x654 -->
	  <img src="Screen Shot 2022-07-24 at 18.22.30_thumb.jpg" width="400" height="220" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
i-Sim2Real: Reinforcement Learning of Robotic Policies in Tight Human-Robot Interaction Loops
abs: https://arxiv.org/abs/2207.06572
project page: https://sites.google.com/view/is2r
      </pre>
    </li>

    <li><a href="https://twitter.com/liuziwei7/status/1547790220547870721">https://twitter.com/liuziwei7/status/1547790220547870721</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.23.30.png"><!-- 1188x999 -->
	  <img src="Screen Shot 2022-07-24 at 18.23.30_thumb.jpg" width="400" height="336" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
#ECCV2022 We propose Relighting4D, which enables free-pose and
free-viewpoint relighting from only monocular videos
under unknown illuminations.

Code and models: https://github.com/FrozenBurning/Relighting4D
      </pre>
    </li>

    <li><a href="https://twitter.com/hardmaru/status/1547758643155980288">https://twitter.com/hardmaru/status/1547758643155980288</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.24.25.png"><!-- 1184x1286 -->
	  <img src="Screen Shot 2022-07-24 at 18.24.25_thumb.jpg" width="552" height="600" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Can your ML agent trained to play normal chess, also play this variation of
“Chess on a really big board” without any retraining?
      </pre>
    </li>

    <li><a href="https://twitter.com/80Level/status/1547196647972691971">https://twitter.com/80Level/status/1547196647972691971</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.26.13.png"><!-- 1183x812 -->
	  <img src="Screen Shot 2022-07-24 at 18.26.13_thumb.jpg" width="400" height="275" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Meta presented Dressing Avatars – photorealistic appearance for
physically simulated clothing. The clothes show both realistic
clothing dynamics and photorealistic appearance learned from real-world data:

https://80.lv/articles/meta-presented-photorealistic-clothing-for-avatars

#meta #art #3dart #research
      </pre>
      <ul>
	<li><a href="https://80.lv/articles/meta-presented-photorealistic-clothing-for-avatars">https://80.lv/articles/meta-presented-photorealistic-clothing-for-avatars</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.26.40.png"><!-- 2778x897 -->
	      <img src="Screen Shot 2022-07-24 at 18.26.40_thumb.jpg" width="1000" height="323" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/_akhaliq/status/1546504056709042176">https://twitter.com/_akhaliq/status/1546504056709042176</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.29.32.png"><!-- 1187x539 -->
	  <img src="Screen Shot 2022-07-24 at 18.29.32_thumb.jpg" width="1000" height="454" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
cool @Gradio Demo for CVPR 2022 papers on @huggingface Spaces by 
https://huggingface.co/hysts
demo: https://huggingface.co/spaces/hysts/CVPR2022_papers
      </pre>
      <ul>
	<li><a href="https://huggingface.co/spaces/hysts/CVPR2022_papers">https://huggingface.co/spaces/hysts/CVPR2022_papers</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.30.06.png"><!-- 2781x1384 -->
	      <img src="Screen Shot 2022-07-24 at 18.30.06_thumb.jpg" width="1000" height="498" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/ImAI_Eruel/status/1546462423426932736">https://twitter.com/ImAI_Eruel/status/1546462423426932736</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.31.05.png"><!-- 1182x588 -->
	  <img src="Screen Shot 2022-07-24 at 18.31.05_thumb.jpg" width="400" height="199" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
スタンフォード大の教授らが書いた意思決定アルゴリズムに関する700ページの書籍が公開されています
https://algorithmsbook.com
著者は私の研究分野（強化学習）でも有名な方だったので，期待して読んでみたところ，まさにこれだ！という内容でした
ベイズ，強化学習，探索，ゲーム理論等全部詰めです
      </pre>
      <ul>
	<li><a href="https://algorithmsbook.com">https://algorithmsbook.com</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.31.29.png"><!-- 2771x1001 -->
	      <img src="Screen Shot 2022-07-24 at 18.31.29_thumb.jpg" width="1000" height="361" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/twominutepapers/status/1546156393371209729">https://twitter.com/twominutepapers/status/1546156393371209729</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.32.40.png"><!-- 1184x638 -->
	  <img src="Screen Shot 2022-07-24 at 18.32.40_thumb.jpg" width="400" height="216" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Watch This Chair Grow Out Of Nothing! 🐲
▶️Full video (ours): https://youtu.be/19gzG-AsBNU
📜Source paper: http://rgl.epfl.ch/publications/Vicini2022SDF
      </pre>
    </li>

    <li><a href="https://twitter.com/wayne_wu_0503/status/1546366934937006080">https://twitter.com/wayne_wu_0503/status/1546366934937006080</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.33.09.png"><!-- 1181x902 -->
	  <img src="Screen Shot 2022-07-24 at 18.33.09_thumb.jpg" width="400" height="306" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
We have released the code of Generalizable Neural Performer! 
Check out the code here: https://github.com/generalizable-neural-performer/gnr
      </pre>
      <ul>
	<li><a href="https://github.com/generalizable-neural-performer/gnr">https://github.com/generalizable-neural-performer/gnr</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.33.39.png"><!-- 2784x819 -->
	      <img src="Screen Shot 2022-07-24 at 18.33.39_thumb.jpg" width="1000" height="294" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/_akhaliq/status/1546298507631284228">https://twitter.com/_akhaliq/status/1546298507631284228</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.34.59.png"><!-- 1190x707 -->
	  <img src="Screen Shot 2022-07-24 at 18.34.59_thumb.jpg" width="400" height="238" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
More ConvNets in the 2020s: Scaling up Kernels Beyond 51 × 51 using Sparsity
abs: https://arxiv.org/abs/2207.03620
github: https://github.com/VITA-Group/SLaK

pure ConvNet model, smoothly scales up the kernel size beyond 51×51,
while achieving better performance than Swin Transformer and ConvNeXt
      </pre>
    </li>

    <li><a href="https://twitter.com/hila_chefer/status/1545740385615486976">https://twitter.com/hila_chefer/status/1545740385615486976</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.36.12.png"><!-- 1177x1099 -->
	  <img src="Screen Shot 2022-07-24 at 18.36.12_thumb.jpg" width="400" height="373" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
[1/n] 
@eccvconf
 #ECCV2022 paper thread!

1. Image-based CLIP-Guided Essence Transfer (TargetCLIP)- we extract
the essence of a target while preserving realism and source identity.

2. No Token Left Behind- we use explainability to stabilize
the unreliable CLIP similarity scores.

https://twitter.com/_akhaliq/status/1452809465313603584
Image-Based CLIP-Guided Essence Transfer
abs: https://arxiv.org/abs/2110.12427
github: https://github.com/hila-chefer/TargetCLIP

new method creates a blending operator that is optimized to be
simultaneously additive in both latent spaces
      </pre>
    </li>

    <li><a href="https://twitter.com/fffiloni/status/1545381857797226496">https://twitter.com/fffiloni/status/1545381857797226496</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.37.24.png"><!-- 1187x849 -->
	  <img src="Screen Shot 2022-07-24 at 18.37.24_thumb.jpg" width="400" height="286" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Thanks to the help of @abidlabs , i made my first @gradio demo and
my first @huggingface space forked from the FILM: 
Frame Interpolation for Large Scene Motion demo by @_akhaliq
 
It uses SKETCHES as inputs instead of pictures 🤗

try it : https://huggingface.co/spaces/fffiloni/sketch_frame_interpolation
      </pre>
      <ul>
	<li><a href="https://huggingface.co/spaces/fffiloni/sketch_frame_interpolation">https://huggingface.co/spaces/fffiloni/sketch_frame_interpolation</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.37.49.png"><!-- 2790x743 -->
	      <img src="Screen Shot 2022-07-24 at 18.37.49_thumb.jpg" width="1000" height="266" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/liuziwei7/status/1545422464930394112">https://twitter.com/liuziwei7/status/1545422464930394112</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.38.31.png"><!-- 1186x742 -->
	  <img src="Screen Shot 2022-07-24 at 18.38.31_thumb.jpg" width="400" height="250" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
We have released, CelebA-Dialog, a large-scale high-quality face dataset
with rich multi-modal annotations:

https://github.com/ziqihuangg/CelebA-Dialog

- 30K high-res face images with seg masks
- Fine-grained attributes (e.g. different degrees of smile)
- Textual descriptions and editing requests
      </pre>
    </li>

    <li><a href="https://twitter.com/_akhaliq/status/1545450579685687296">https://twitter.com/_akhaliq/status/1545450579685687296</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.39.11.png"><!-- 1180x1321 -->
	  <img src="Screen Shot 2022-07-24 at 18.39.11_thumb.jpg" width="715" height="800" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
The ICML 2022 organization on @huggingface is now accepting models
and datasets as well as @Gradio Demo submissions,
deadline to submit is July 31st, 2022 (AOE Time Zone)

Join the ICML 2022 organization here to get started:
https://huggingface.co/organizations/ICML2022/share/BpynfJtfsOTktlmXYoKNqqCnyufKLFXuay
      </pre>
    </li>

    <li><a href="https://twitter.com/marko_mih/status/1545290974359961601">https://twitter.com/marko_mih/status/1545290974359961601</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.39.59.png"><!-- 1183x802 -->
	  <img src="Screen Shot 2022-07-24 at 18.39.59_thumb.jpg" width="400" height="271" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
🥳Excited that our KeypointNeRF is accepted @eccvconf!  #ECCV2022

KeypointNeRF reconstructs unseen volumetric avatars from 2-3 images
without retraining and generalizes to in-the-wild captures. 

More info https://markomih.github.io/KeypointNeRF
w @aayushbansal @MZollhoefer @SiyuTang3 @psyth91
      </pre>
    </li>

    <li><a href="https://twitter.com/naotokui/status/1544897167235895296">https://twitter.com/naotokui/status/1544897167235895296</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.42.34.png"><!-- 1188x198 -->
	  <img src="Screen Shot 2022-07-24 at 18.42.34_thumb.jpg" width="400" height="67" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
MITの講義、Deep Learning for Art, Aesthetics, and Creativity が
オンラインで見れる！素晴らしいゲスト講師陣。僕も勉強させてもらおう。
https://ali-design.github.io/deepcreativity/
      </pre>
      <ul>
	<li><a href="https://ali-design.github.io/deepcreativity/">https://ali-design.github.io/deepcreativity/</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.42.54.png"><!-- 2779x636 -->
	      <img src="Screen Shot 2022-07-24 at 18.42.54_thumb.jpg" width="1000" height="229" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/ibaiGorordo/status/1544910517760069632">https://twitter.com/ibaiGorordo/status/1544910517760069632</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.43.19.png"><!-- 1173x718 -->
	  <img src="Screen Shot 2022-07-24 at 18.43.19_thumb.jpg" width="400" height="245" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
YOLOv7 ONNX Conversion (Google Colab)
https://colab.research.google.com/drive/1733xwaETLhAJguRKDqhjgPWf7a2NaOro?usp=sharing

⚠️Not tested⚠️
It uses the u5 branch (yolov5 compatible) for the conversion.
      </pre>
    </li>

    <li><a href="https://twitter.com/_akhaliq/status/1544894929331261440">https://twitter.com/_akhaliq/status/1544894929331261440</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.43.49.png"><!-- 1178x548 -->
	  <img src="Screen Shot 2022-07-24 at 18.43.49_thumb.jpg" width="400" height="186" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
DCT-Net: Domain-Calibrated Translation for Portrait Stylization
abs: https://arxiv.org/abs/2207.02426
project page: https://menyifang.github.io/projects/DCTNet/DCTNet.html
      </pre>
    </li>

    <li><a href="https://twitter.com/_akhaliq/status/1544844431752298498">https://twitter.com/_akhaliq/status/1544844431752298498</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.45.30.png"><!-- 1185x683 -->
	  <img src="Screen Shot 2022-07-24 at 18.45.30_thumb.jpg" width="400" height="231" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
SNeRF: Stylized Neural Implicit Representations for 3D Scenes
abs: https://arxiv.org/abs/2207.02363
project page: https://research.facebook.com/publications/snerf-stylized-neural-implicit-representations-for-3d-scenes/
      </pre>
      <ul>
	<li><a href="https://research.facebook.com/publications/snerf-stylized-neural-implicit-representations-for-3d-scenes/">https://research.facebook.com/publications/snerf-stylized-neural-implicit-representations-for-3d-scenes/</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.45.46.png"><!-- 2776x712 -->
	      <img src="Screen Shot 2022-07-24 at 18.45.46_thumb.jpg" width="1000" height="256" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/jun40vn/status/1544607084129398785">https://twitter.com/jun40vn/status/1544607084129398785</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.47.41.png"><!-- 1181x1184 -->
	  <img src="Screen Shot 2022-07-24 at 18.47.41_thumb.jpg" width="399" height="400" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Liquid Warping GAN with Attention は、３つのGeneratorと３つのDiscriminatorから
構成されるネットワークを使って体全体のモーション転送を行う技術です。
　これは、PSYの「That That」の動画に合わせて、西郷さんの銅像にダンスを
させているところです。

ブログ：http://cedro3.com/ai/ipercore/
      </pre>
      <ul>
	<li><a href="http://cedro3.com/ai/ipercore/">http://cedro3.com/ai/ipercore/</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.48.03.png"><!-- 2786x808 -->
	      <img src="Screen Shot 2022-07-24 at 18.48.03_thumb.jpg" width="1000" height="290" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/paperswithcode/status/1544303944402436099">https://twitter.com/paperswithcode/status/1544303944402436099</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.49.39.png"><!-- 1190x758 -->
	  <img src="Screen Shot 2022-07-24 at 18.49.39_thumb.jpg" width="800" height="510" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
🔥Top Trending ML Papers of the Month

Here is a thread to catchup on the top 10 trending papers of June on 
@paperswithcode. ↓
      </pre>
    </li>

    <li><a href="https://twitter.com/jaguring1/status/1544257946963820545">https://twitter.com/jaguring1/status/1544257946963820545</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.50.13.png"><!-- 1183x461 -->
	  <img src="Screen Shot 2022-07-24 at 18.50.13_thumb.jpg" width="400" height="156" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
DeepMindのAI研究（DeepNash）

今まで数多くの研究者がゲームを攻略するAIを探求することで，
汎用人工知能へ至ろうとする方針で頑張ってきた。
今回は、複雑な不完全情報ゲームである「Stratego」でゼロから人間のトップレベルまで到達。
囲碁よりも10^175倍も巨大なゲーム木

https://arxiv.org/abs/2206.15378
      </pre>
      <ul>
	<li><a href="https://arxiv.org/abs/2206.15378">https://arxiv.org/abs/2206.15378</a> (<a href="arxiv-2206.15378-mastering-the-game-of-stratego.pdf">local copy</a>)
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.51.08.png"><!-- 2167x690 -->
	      <img src="Screen Shot 2022-07-24 at 18.51.08_thumb.jpg" width="1000" height="318" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>


    <li><a href="https://twitter.com/shiropen2/status/1543740223217369088">https://twitter.com/shiropen2/status/1543740223217369088</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.55.40.png"><!-- 1182x612 -->
	  <img src="Screen Shot 2022-07-24 at 18.55.40_thumb.jpg" width="800" height="414" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
文章から「3Dアバター」と「動き」を自動作成するAI　シンガポールと中国のチームが開発 
https://itmedia.co.jp/news/articles/2207/04/news036.html 
例[座る太った力士]の文章から力士の静的3Dモデルと座る動きをOpanAIの
CLIPベースモデルAvatarCLIPでゼロショット生成。
[腕を振り上げる痩せた忍者][議論する背が高く痩せた女性兵士]等
      </pre>
      <ul>
	<li><a href="https://itmedia.co.jp/news/articles/2207/04/news036.html">https://itmedia.co.jp/news/articles/2207/04/news036.html</a>
	  <center>
	    <a href="Screen Shot 2022-07-24 at 18.56.00.png"><!-- 1751x333 -->
	      <img src="Screen Shot 2022-07-24 at 18.56.00_thumb.jpg" width="1000" height="190" style="border: 2px #ccc solid;" /></a>
	  </center>
	</li>
      </ul>
    </li>

    <li><a href="https://twitter.com/liuziwei7/status/1543610523400503296">https://twitter.com/liuziwei7/status/1543610523400503296</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.56.27.png"><!-- 1186x709 -->
	  <img src="Screen Shot 2022-07-24 at 18.56.27_thumb.jpg" width="800" height="478" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
We have released, DeepFashion-MultiModal, a large-scale high-quality 
human dataset with rich multi-modal annotations:

https://github.com/yumingj/DeepFashion-MultiModal

- 40K high-resolution human images
- Human parsing, keypoints and DensePose annotations
- Attribute and textual description annotations
      </pre>
    </li>

    <li><a href="https://twitter.com/_akhaliq/status/1542711108028567552">https://twitter.com/_akhaliq/status/1542711108028567552</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.58.07.png"><!-- 1188x497 -->
	  <img src="Screen Shot 2022-07-24 at 18.58.07_thumb.jpg" width="800" height="335" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Dressing Avatars: Deep Photorealistic Appearance for Physically Simulated Clothing
abs: https://arxiv.org/abs/2206.15470
      </pre>
    </li>

    <li><a href="https://twitter.com/_akhaliq/status/1542708209689001984">https://twitter.com/_akhaliq/status/1542708209689001984</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.58.50.png"><!-- 1179x816 -->
	  <img src="Screen Shot 2022-07-24 at 18.58.50_thumb.jpg" width="600" height="415" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D Camera
abs: https://arxiv.org/abs/2206.15255
project page: https://ustc3dv.github.io/ndr/

TL;DR: a template-free method to recover high-fidelity geometry,
motions and appearance of a dynamic scene from a monocular RGB-D camera
      </pre>
    </li>

    <li><a href="https://twitter.com/AlexRichardCS/status/1542174886260506624">https://twitter.com/AlexRichardCS/status/1542174886260506624</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 19.00.04.png"><!-- 1185x718 -->
	  <img src="Screen Shot 2022-07-24 at 19.00.04_thumb.jpg" width="600" height="364" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Photorealistic 3D avatars for everyone?! Check out this exciting work
from our lab in Pittsburgh!
https://tinyurl.com/4xk25spe
      </pre>
    </li>

  </ul>

  <p>室内画像とな</p>

  <ul>

    <li><a href="https://twitter.com/_akhaliq/status/1544160253100564480">https://twitter.com/_akhaliq/status/1544160253100564480</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.52.43.png"><!-- 1179x754 -->
	  <img src="Screen Shot 2022-07-24 at 18.52.43_thumb.jpg" width="800" height="512" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
PhotoScene: Photorealistic Material and Lighting Transfer for Indoor Scenes
abs: https://arxiv.org/abs/2207.00757
github: https://github.com/ViLab-UCSD/photoscene
      </pre>
    </li>

    <li><a href="https://twitter.com/_akhaliq/status/1544124952332439552">https://twitter.com/_akhaliq/status/1544124952332439552</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.53.10.png"><!-- 1174x826 -->
	  <img src="Screen Shot 2022-07-24 at 18.53.10_thumb.jpg" width="600" height="422" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Aug-NeRF: Training Stronger Neural Radiance Fields with
Triple-Level Physically-Grounded Augmentations
abs: https://arxiv.org/abs/2207.01164

Aug-NeRF effectively boosts NeRF performance in both novel view synthesis
(up to 1.5dB PSNR gain) and underlying geometry reconstruction
      </pre>
    </li>

    <li><a href="https://twitter.com/_akhaliq/status/1543755632565706754">https://twitter.com/_akhaliq/status/1543755632565706754</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 18.55.19.png"><!-- 1181x724 -->
	  <img src="Screen Shot 2022-07-24 at 18.55.19_thumb.jpg" width="800" height="490" style="border: 2px #ccc solid;" /></a>
      </center>
      <pre>
Semantic Image Synthesis via Diffusion Models
abs: https://arxiv.org/abs/2207.00050

experiments on three benchmark datasets demonstrate the effectiveness
of proposed method, achieving sota performance in terms of
fidelity(FID) and diversity (LPIPS)
      </pre>
    </li>


  </ul>

  <br /><br /><br /><center>...♦...</center><br /><br /><br />

  <hr />

  <center id="part2">
    <div style="font-size: 50px; font-weight: bolder;">
      パート２
      技術書典１３企画会議！第２回
    </div>
  </center>

  <ul>
    <li><a href="https://forum.ai.zenkei.com/t/topic/465">「技術書典１３」スレッド</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 17.42.29.png"><!-- 2794x1257 -->
	  <img src="Screen Shot 2022-07-24 at 17.42.29_thumb.jpg" width="1000" height="450" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-07-24 at 17.42.43.png"><!-- 2073x449 -->
	  <img src="Screen Shot 2022-07-24 at 17.42.43_thumb.jpg" width="1000" height="217" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-07-24 at 17.42.51.png"><!-- 2078x554 -->
	  <img src="Screen Shot 2022-07-24 at 17.42.51_thumb.jpg" width="1000" height="267" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-07-24 at 17.42.57.png"><!-- 2084x809 -->
	  <img src="Screen Shot 2022-07-24 at 17.42.57_thumb.jpg" width="1000" height="388" style="border: 2px #ccc solid;" /></a>
	<a href="Screen Shot 2022-07-24 at 17.43.02.png"><!-- 2071x852 -->
	  <img src="Screen Shot 2022-07-24 at 17.43.02_thumb.jpg" width="1000" height="411" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>

    <li><a href="https://forum.ai.zenkei.com/t/topic/468">「AI小説」スレッド</a>
      <center>
	<a href="Screen Shot 2022-07-24 at 17.45.55.png"><!-- 2053x996 -->
	  <img src="Screen Shot 2022-07-24 at 17.45.55_thumb.jpg" width="1000" height="485" style="border: 2px #ccc solid;" /></a>
      </center>
    </li>

  </ul>


  <br /><br /><br /><center>...♦...</center><br /><br /><br />

  <center id="epilogue">
    <div style="font-size: 50px; font-weight: bolder;">
      今日のおわりに
    </div>
  </center>

  <p>……</p>

  <h3>今後の予定</h3>
  <ul>
    <li>次回 ZAF は 2022 年８月３１日開催の予定です。</li>
    <li>ZAF 講演者、 ZAM 執筆者、絶賛、大募集中です！<br />
      お気軽にお問い合わせください！</li>
  </ul>

  <br /><br /><br /><center>...♦...</center><br /><br /><br />

  <hr />
  <hr />

  <h2 id="detailed-toc">総合目次</h2>
  <ul>
    <li><b>前座</b>
      <ul>
	<li>...</li>

      </ul>
    </li>

    <li><b>第１部</b>
      <a href="#part1">...</a>
      <ul>
	<li>...</li>

      </ul>
    </li>

    <li><b>第２部</b>
      <a href="#part2">技術書典１３企画会議！第２回</a>
      <ul>
	<li>...</li>

      </ul>
    </li>

    <li><a href="#epilogue">今日のおわりに</a></li>
  </ul>

  <br /><br /><br /><center>...♦...</center><br /><br /><br />

</section>

</body>           
</html>
